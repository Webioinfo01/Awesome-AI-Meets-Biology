# Research Paper Report for 2025-09-01 to 2025-09-15

## Overall Summary

Between September 1 and September 15, 2025, the corpus spans four thematic categories—ai-agents, reviews, benchmarks, and foundation-models—encompassing 15 papers that reflect significant advances in applying large language models (LLMs) and multi-agent frameworks across medical, biological, and computational domains. A dominant theme is the integration of LLMs with domain-specific logic or heuristics to improve interpretability and decision support. For instance, ArgTumour [1] fuses LLM outputs with formal argumentation structures, extracting 159 arguments from NICE guidelines and achieving 77% faithfulness via the IBM Granite Guardian 8B. HypoGeneAgent [4] similarly embeds LLM-generated gene-set hypotheses into a quantitative resolution scoring system using sentence embeddings and cosine similarity, demonstrating superior cluster coherence on a K562 Perturb-seq dataset compared to classical metrics like silhouette score.

Another interdisciplinary trend is the fusion of LLMs with statistical normalization and bioinformatics pipelines, as in CLAW-MRM [5], which automates lipidomics workflows across 1,500 MRM transitions and employs TMM normalization and LIGER integration to reveal Alzheimer’s metabolic pathways. Similarly, agentic AI frameworks are leveraged for broad drug discovery pipelines [6], synthesizing genomics, proteomics, chemical libraries, and adaptive clinical trial designs, thus pushing toward personalized medicine guided by predictive modeling.

Methodological innovations include three-tier evaluation frameworks for mental health chatbots [7], combining bench testing, feasibility, and clinical efficacy, while systematic reviews of ethical issues [9] and DDI analysis [10] highlight limitations in validation rigor (only 16% of LLM chatbots reached efficacy testing [7]) and inconsistent performance (public LLMs show variable DDI detection accuracy [10]). Best practices in radiology [8] emphasize regulatory, privacy, and bias mitigation, pointing to the need for standardized benchmarks.

Benchmark studies reveal that LLMs remain imperfect proxies for expert panels: sarcoma treatment recommendations align with tumor boards only 20–60% of the time [11], and while DeepSeek-R1 attains 73% accuracy on China’s anesthesiology board exam [13], it still commits high-risk logical and informational errors. Educational technology research [12] uses structural equation modeling to extend TAM frameworks, identifying subjective norms as the strongest predictor of LLM adoption among teacher-education students.

Foundation models are also pushing domain boundaries. PlantCAD2 [15], a 676M-parameter DNA LM with an 8 kb context window, outperforms larger models in cross-species functional annotation, improving maize AUPRC from 0.587 to 0.711. Meanwhile, the CURE AI foundation model [14] aims at pan-cancer immunotherapy response prediction, though details remain sparse.

Collectively, these works underscore a shift from purely generative LLM functionalities toward hybrid architectures combining logic, embeddings, normalization, and human-expert feedback. Emerging trends prioritize explainability, faithfulness, and robust evaluation metrics, while limitations persist in high-stakes clinical reliability, standardization of evaluation frameworks, and the need for dedicated, domain-tuned LLMs.

## Table of Contents

- [ai-agents](#ai-agents)  
- [reviews](#reviews)  
- [benchmarks](#benchmarks)  
- [foundation-models](#foundation-models)  

## ai-agents

Category Summary  
The ai-agents category comprises six studies exploring the deployment of LLMs and multi-agent collaborations in clinical decision support, drug development, genomics, lipidomics, and bioPharma R&D. ArgTumour [1] integrates LLM-extracted treatment options from NICE guidelines with formal argumentation, generating 159 pro/con arguments and evaluating faithfulness (77%) via IBM Granite Guardian 8B. Healthcare agent [2] aims to harness LLM conversational capabilities for medical consultations, though its technical specifications and evaluation remain unspecified. P03-04 [3] leverages multi-agent systems to extract rationales behind drug development discontinuations; details on agent coordination and data sources were not provided. HypoGeneAgent [4] transforms cluster annotation into a quantitatively optimizable task by having an LLM propose GO-based hypotheses with confidence scores, embedding them for pairwise cosine similarity calculations, and deriving a resolution score emphasizing intra-cluster agreement and inter-cluster separation. CLAW-MRM [5] automates multiple reaction monitoring lipidomics workflows, employing TMM normalization, 1,500 MRM transitions across 11 lipid classes, and LIGER integration to map lipid-gene associations, while offering a natural language interface powered by LLMs. Accelerating Drug Discovery [6] outlines an agentic AI and multi-agent collaboration pipeline for genomics, proteomics, virtual screening, and adaptive clinical trial optimization, arguing for personalized medicine driven by predictive modeling. Collectively, these works demonstrate a trend toward combining LLM reasoning with domain-specific pipelines—argumentation frameworks, clustering metrics, normalization methods, and collaborative AI architectures—while highlighting the need for thorough evaluation of faithfulness, clinical reliability, and scalability.

| Index | Title                                                                                                                                                                              | Domain                                             | Venue                                                            | Team                      | DOI                                   | affiliation        | paperUrl                                                   |
|-------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------|------------------------------------------------------------------|---------------------------|---------------------------------------|--------------------|------------------------------------------------------------|
| 1     | ARGTUMOUR: INTEGRATING LARGE LANGUAGE MODELS AND COMPUTATIONAL ARGUMENTATION TO DISCUSS TREATMENT OPTIONS FOR HIGH-GRADE GLIOMA                                                   | Glioblastoma treatment argumentation               | Neuro-Oncology                                                   | Matt Williams            | 10.1093/neuonc/noaf185.104           |                    | [Link](https://www.semanticscholar.org/paper/b6df41a78e7327265ab7c85c2df1979704d9f51e) |
| 2     | Healthcare agent: eliciting the power of large language models for medical consultation                                                                                           | Medical consultation AI agent                      | npj Artificial Intelligence                                      | D. Tao                    | 10.1038/s44387-025-00021-x           |                    | [Link](https://www.semanticscholar.org/paper/97412aeab5443a278258ef4269ed7224e08c9a3a) |
| 3     | P03-04 Leveraging Large Language Models and Multi-Agent Systems to Extract Discontinuation Rationales in Drug Development                                                           | Drug development discontinuation rationales        | Toxicology Letters                                               | T. Doktorova              | 10.1016/j.toxlet.2025.07.199         |                    | [Link](https://www.semanticscholar.org/paper/417e2443ea0f32703e6f8df54f7f990e09b51c96) |
| 4     | HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets                                                                    | Gene-set cluster annotation agent                  | ArXiv                                                            | Vladimir Ermakov          | 10.48550/arXiv.2509.09740            |                    | [Link](https://www.semanticscholar.org/paper/2c36c003302fef3f77cef4b96a723f880ac2d65b) |
| 5     | CLAW-MRM: Comprehensive Lipidomics Automation Workflow for Multiple Reaction Monitoring Using Large Language Models.                                                               | Automated lipidomics workflow                      | Analytical chemistry                                             | Gaurav Chopra             | 10.1021/acs.analchem.4c05039         |                    | [Link](https://www.semanticscholar.org/paper/a375b66187f36ef48b373433c2416185ee70dd41) |
| 6     | Accelerating Drug Discovery: How Agentic AI and Multi-Agent Collaboration Transform BioPharma R&D                                                                                  | Agentic AI in drug discovery                       | Journal of Information Systems Engineering and Management         | Amandeep Singh Saini      | 10.52783/jisem.v10i59s.12898         |                    | [Link](https://www.semanticscholar.org/paper/f3e39e1591865352c99d55fa30798d6fe89859da) |

## reviews

Category Summary  
The reviews category (papers [7]–[10]) systematically examines the evolution, safety, and ethical dimensions of LLM and generative AI deployment in healthcare contexts. Torous et al. [7] conduct a systematic review of 160 mental health chatbot studies (2020–2024), proposing a three-tier framework—bench testing, pilot feasibility, and clinical efficacy—and revealing that LLM-based systems comprised 45% of new studies in 2024 but only 16% advanced to efficacy testing. Parekh [8] outlines best practices for safe radiology integration of LLMs and generative AI, focusing on regulatory compliance, data privacy safeguards, and bias mitigation, calling for vendor transparency and failure-mode analyses. Zhang et al. [9] apply PRISMA guidelines across eight databases to identify six ethical challenges—trust, equity, privacy, transparency, nonmaleficence, and accountability—in oncology LLM applications, summarizing emerging technical solutions and evaluation metrics. Biri [10] performs a PRISMA-compliant mapping review of nine studies (2023–2025) on public LLM chatbots (ChatGPT, Bing AI, Google Bard) for drug-drug interaction detection, finding inconsistent and partial effectiveness and recommending dedicated, standardized DDI chatbots. Collectively, these reviews highlight the gap between generative AI promise and rigorous validation, emphasizing the need for standardized benchmarking, transparent architecture reporting, and ethical frameworks tailored to high-stakes medical domains.

| Index | Title                                                                                                                                                              | Domain                                    | Venue                                    | Team                 | DOI                                    | affiliation | paperUrl                                                   |
|-------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------|------------------------------------------|----------------------|----------------------------------------|-------------|------------------------------------------------------------|
| 7     | Charting the evolution of artificial intelligence mental health chatbots from rule-based systems to large language models: a systematic review                       | Mental health chatbot architectures       | World Psychiatry                         | J. Torous            | 10.1002/wps.21352                     |             | [Link](https://www.semanticscholar.org/paper/8b6e4d0874844057237a5fd53e2e03a3c2c52e20) |
| 8     | Best Practices for the Safe Use of Large Language Models and Other Generative AI in Radiology.                                                                     | Generative AI best practices in radiology | Radiology                                | Vishwa S. Parekh     | 10.1148/radiol.241516                 |             | [Link](https://www.semanticscholar.org/paper/2dc8ce06575136b64ac13b32567e200653dbb8b0) |
| 9     | Mitigating Ethical Issues for Large Language Models in Oncology: A Systematic Review.                                                                              | Ethical issues of LLMs in oncology        | JCO clinical cancer informatics          | Rui Zhang            | 10.1200/CCI-25-00076                  |             | [Link](https://www.semanticscholar.org/paper/008014c0fe9c31dfa58c4329d4f9d5307fd80016) |
| 10    | A systematic mapping review on the capability of large language models in drug-drug interaction analysis                                                           | LLMs for drug-drug interaction analysis   | Expert Review of Clinical Pharmacology   | S. Biri              | 10.1080/17512433.2025.2568090         |             | [Link](https://www.semanticscholar.org/paper/2a3c4c175bcb3842a4a52dda33a3a4f9e5a970d1) |

## benchmarks

Category Summary  
The benchmarks category ([11]–[13]) assesses LLM performance against established human and educational benchmarks. Yang et al. [11] simulate multidisciplinary tumor boards (MTBs) for 21 sarcoma centers using four LLMs (Llama 3.2-vision, Claude 3.5 Sonnet, DeepSeek-R1, OpenAI-o1) over five ring-trial cases, each model queried 21 times. Results show only 20% inter-model consistency and 20–60% alignment with human consensus, with LLM rationale citing German S3 guidelines in just 24.8–55.2% of outputs and occasional harmful recommendations. Lin [12] extends the Technology Acceptance Model (TAM) via structural equation modeling on 552 teacher-education students, integrating variables like learning motivation, perceived risk, self-efficacy, and usage experience; subjective norms are the strongest predictor of LLM adoption, while perceived time and privacy risks negatively impact usefulness and ease of use. Yuan et al. [13] conduct a cross-sectional evaluation of GPT-3.5, GPT-4, DeepSeek-V3, and DeepSeek-R1 on 5,647 Chinese anesthesiology board exam questions, using diverse querying strategies; DeepSeek-R1 (70.6–73.4%) and GPT-4 (68.6–70.3%) outperform older models but still exhibit high-risk logical and informational errors (>70% of errors), with model role prompting improving accuracy. These studies highlight that while LLMs can approach expert-level reasoning in specific tasks, their inconsistency and risk of harmful outputs underscore the need for continued refinement and human oversight.

| Index | Title                                                                                                                                                                            | Domain                                          | Venue                                                      | Team                | DOI                                    | affiliation | paperUrl                                                   |
|-------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|------------------------------------------------------------|---------------------|----------------------------------------|-------------|------------------------------------------------------------|
| 11    | The imitation game: large language models versus multidisciplinary tumor boards: benchmarking AI against 21 sarcoma centers from the ring trial                                  | Sarcoma treatment recommendation comparison     | Journal of Cancer Research and Clinical Oncology           | Cui Yang            | 10.1007/s00432-025-06304-9            |             | [Link](https://www.semanticscholar.org/paper/d9cb979f15f584f231076a9c36e898c9599244b5) |
| 12    | Modeling teacher education students’ adoption of large language models through an extended technology acceptance framework                                                       | Technology adoption in education                | Scientific Reports                                        | Jiaxin Lin          | 10.1038/s41598-025-03298-9            |             | [Link](https://www.semanticscholar.org/paper/7e108e82231a4581d61b466119c8f68c008355a1) |
| 13    | From algorithms to operating room: can large language models master China's attending anesthesiology exam? a cross-sectional evaluation.                                         | Anesthesiology board exam performance           | International journal of surgery                          | Jiuhong Yuan        | 10.1097/JS9.0000000000003406          |             | [Link](https://www.semanticscholar.org/paper/97de7f17b404aa7b484062f252576902358fe0aa) |

## foundation-models

Category Summary  
The foundation‐models category presents large pretrained models addressing oncology and plant genomics. Pfister et al. [14] introduce CURE AI, a clinicogenomic foundation model targeting pan-cancer immunotherapy response prediction. Although details on architecture, training data volume, and benchmark metrics are not provided in the abstract, publication in Annals of Oncology underscores its clinical significance. Buckler et al. [15] present PlantCAD2, a 676 million parameter DNA language model pretrained on 65 angiosperm genomes with an 8 kb context window. Comprehensive zero-shot evaluation demonstrates that PlantCAD2 surpasses the 7-billion-parameter Evo2 model on 10 of 12 conservation and functional annotation tasks, and outperforms the 1-billion-parameter AgroNT across seven cross-species tasks. Notably, PlantCAD2 improves accessible chromatin prediction in maize (AUPRC from 0.587 to 0.711), highlighting the importance of long-range context modeling in large genomes. These foundation models reflect a trend toward domain-specific pretraining and efficient parameter scaling, yet the absence of detailed methodological disclosure in [14] suggests a need for transparent reporting of training regimes, fine-tuning strategies, and evaluation benchmarks.

| Index | Title                                                                                                                                                 | Domain                                       | Venue                    | Team           | DOI                               | affiliation       | paperUrl                                                        |
|-------|-------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------|--------------------------|----------------|------------------------------------|-------------------|-----------------------------------------------------------------|
| 14    | 202eP Generalizable pan-cancer immunotherapy response prediction using the CURE AI large clinicogenomic foundation model                               | Pan-cancer immunotherapy response prediction | Annals of Oncology       | N.B. Pfister    | 10.1016/j.annonc.2025.08.635      |                   | [Link](https://www.semanticscholar.org/paper/05c6b1020a1d8018530f3a56702a00703d7170a0) |
| 15    | PlantCAD2: A Long-Context DNA Language Model for Cross-Species Functional Annotation in Angiosperms                                                     | Plant genomics DNA language model            | bioRxiv                  | E. Buckler      | 10.1101/2025.08.27.672609         | Cornell University | [Link](https://www.semanticscholar.org/paper/da44248c3ced760711c56032ca91d9f400ecea38)  |

