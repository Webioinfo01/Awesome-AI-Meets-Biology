{
    "ai-agents": [
        {
            "year": "2025.09",
            "title": "ARGTUMOUR: INTEGRATING LARGE LANGUAGE MODELS AND COMPUTATIONAL ARGUMENTATION TO DISCUSS TREATMENT OPTIONS FOR HIGH-GRADE GLIOMA",
            "team": "Matt Williams",
            "team website": "",
            "affiliation": "",
            "domain": "Glioblastoma treatment argumentation",
            "abstract": "\n \n \n High-grade gliomas are aggressive brain tumours with poor prognosis, and patients diagnosed with such tu- mours often face di\ufb03cult treatment decisions. While medical guidelines can provide information on the available treatment options, they cannot address individual concerns or offer personalised recommendations. Large-language models can provide AI-based language interpretation; Argumentation is a logic-based technique that provides explainability. In this study, we introduce ArgTumour, an interactive, explainable AI system that combines large language models (LLMs) and argumentation to support patient decision-making through sum- marising treatment options for glioblastoma (GBM) and their justi\ufb01cations.\n \n \n \n We extracted information on GBM management from NICE guidelines, evidence reviews, and a patient infor- mation document, using LLMs to identify treatment options and generate structured arguments for and against them. These arguments were evaluated for faithfulness using the IBM Granite Guardian 8B model, which as- sesses alignment with the original sources. A clinical expert reviewed the argument structures, and system performance was assessed by comparing con\ufb01dence scores for NICE-supported vs. non-supported treatments. We have also started some early qualitative evaluation of the system through preliminary patient and public engagement sessions.\n \n \n \n Our system identi\ufb01ed 14 main treatment options for GBM, extracting 159 supporting and opposing arguments. The Granite Guardian model found 77% of arguments to be well-supported by the used sources, indicating good overall faithfulness. Among the 14 options, 6 aligned with NICE guidelines, with an average system con\ufb01dence in these options of 73%, while non-NICE-supported options all received a con\ufb01dence score of 0%.\n \n \n \n Our \ufb01ndings highlight the potential for using LLM-based argumentation systems in medical decision support, providing more personalized and explainable recommendations. This approach allows us to mine medical guidelines to produce explainable arguments for and against different treatment options, where NICE recom- mended options are scored much more highly than those that are not.\n",
            "venue": "Neuro-Oncology",
            "paperUrl": "https://www.semanticscholar.org/paper/b6df41a78e7327265ab7c85c2df1979704d9f51e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1093/neuonc/noaf185.104",
            "reason_for_inclusion": "High quality: Published in Neuro-Oncology, a top-tier journal."
        },
        {
            "year": "2025.09",
            "title": "Healthcare agent: eliciting the power of large language models for medical consultation",
            "team": "D. Tao",
            "team website": "",
            "affiliation": "",
            "domain": "Medical consultation AI agent",
            "abstract": "",
            "venue": "npj Artificial Intelligence",
            "paperUrl": "https://www.semanticscholar.org/paper/97412aeab5443a278258ef4269ed7224e08c9a3a",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s44387-025-00021-x",
            "reason_for_inclusion": "High quality: Published in npj Artificial Intelligence, a top-tier journal."
        },
        {
            "year": "2025.09",
            "title": "P03-04 Leveraging Large Language Models and Multi-Agent Systems to Extract Discontinuation Rationales in Drug Development",
            "team": "T. Doktorova",
            "team website": "",
            "affiliation": "",
            "domain": "Drug development discontinuation rationales",
            "abstract": "",
            "venue": "Toxicology Letters",
            "paperUrl": "https://www.semanticscholar.org/paper/417e2443ea0f32703e6f8df54f7f990e09b51c96",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1016/j.toxlet.2025.07.199",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.09",
            "title": "HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets",
            "team": "Vladimir Ermakov",
            "team website": "",
            "affiliation": "",
            "domain": "Gene-set cluster annotation agent",
            "abstract": "Large-scale single-cell and Perturb-seq investigations routinely involve clustering cells and subsequently annotating each cluster with Gene-Ontology (GO) terms to elucidate the underlying biological programs. However, both stages, resolution selection and functional annotation, are inherently subjective, relying on heuristics and expert curation. We present HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming cluster annotation into a quantitatively optimizable task. Initially, an LLM functioning as a gene-set analyst analyzes the content of each gene program or perturbation module and generates a ranked list of GO-based hypotheses, accompanied by calibrated confidence scores. Subsequently, we embed every predicted description with a sentence-embedding model, compute pair-wise cosine similarities, and let the agent referee panel score (i) the internal consistency of the predictions, high average similarity within the same cluster, termed intra-cluster agreement (ii) their external distinctiveness, low similarity between clusters, termed inter-cluster separation. These two quantities are combined to produce an agent-derived resolution score, which is maximized when clusters exhibit simultaneous coherence and mutual exclusivity. When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary test, our Resolution Score selects clustering granularities that exhibit alignment with known pathway compared to classical metrics such silhouette score, modularity score for gene functional enrichment summary. These findings establish LLM agents as objective adjudicators of cluster resolution and functional annotation, thereby paving the way for fully automated, context-aware interpretation pipelines in single-cell multi-omics studies.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/2c36c003302fef3f77cef4b96a723f880ac2d65b",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2509.09740",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.09",
            "title": "CLAW-MRM: Comprehensive Lipidomics Automation Workflow for Multiple Reaction Monitoring Using Large Language Models.",
            "team": "Gaurav Chopra",
            "team website": "",
            "affiliation": "",
            "domain": "Automated lipidomics workflow",
            "abstract": "Lipidomic profiling generates vast datasets, making manual annotation and trend interpretation complex and time-intensive. The structural and chemical diversity of the lipidome further complicates the analysis. While existing tools support targeted lipid identification, they often lack automated workflows and seamless integration with statistical and bioinformatics tools. Here, we introduce the comprehensive lipidomics automated workflow for multiple reaction monitoring (CLAW-MRM), a platform designed to automate lipid annotation, statistical analysis, and data parsing using custom multiple reaction monitoring (MRM) precursor product ion transitions. CLAW-MRM employs trimmed mean of m-value (TMM) normalization to account for lipid load differences, enabling robust cross-sample comparisons. To evaluate CLAW-MRM's performance, we analyzed lipid profiles in liver tissues of Alzheimer's disease (AD) mice and age-matched wild-type controls under conditions of constant and variable tissue mass, assessing the impact of normalization strategies on TMM-normalized lipidomic outcomes. Additionally, we isolated and profiled lipid droplets from individual brain regions of 18- to 24-month-old AD male mice and controls, leveraging nearly 1,500 MRM transitions across 11 lipid classes. Enhancing biological relevance, CLAW-MRM integrates LIGER (lipidome gene enrichment reactions), linking lipid expression with gene activation and suppression patterns. Through CLAW-MRM-based LIGER, we identified metabolic pathways enriched in differentially expressed lipids, offering insights into altered lipid metabolism in AD. To improve usability, CLAW-MRM incorporates a natural language interface powered by large language models, enabling artificial intelligence (AI)-driven user interaction for statistical and bioinformatics analyses. By automating lipid structural identification and integrating AI-assisted bioinformatics, CLAW-MRM provides an end-to-end workflow from data acquisition to interpretation, streamlining high-throughput lipidomics.",
            "venue": "Analytical chemistry",
            "paperUrl": "https://www.semanticscholar.org/paper/a375b66187f36ef48b373433c2416185ee70dd41",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1021/acs.analchem.4c05039",
            "reason_for_inclusion": "High quality: Published in Analytical Chemistry, a top-tier journal."
        },
        {
            "year": "2025.09",
            "title": "Accelerating Drug Discovery: How Agentic AI and Multi-Agent Collaboration Transform BioPharma R&D",
            "team": "Amandeep Singh Saini",
            "team website": "",
            "affiliation": "",
            "domain": "Agentic AI in drug discovery",
            "abstract": "The pharmaceutical sector is undergoing unprecedented change with the incorporation of agentic artificial intelligence and multi-agent collaborative platforms into drug development and discovery procedures. Traditional pharmaceutical improvement is grappling with large setbacks, which include prolonged timelines, soaring costs, and high failures that create a need for groundbreaking technological interventions. Agentic AI systems illustrate independent choice-making ability throughout the continuum of drug discovery, from goal identity to clinical trial optimization, primarily based on thorough datasets including genomics, proteomics, chemical libraries, and scientific repositories. Multi-agent collaboration structures permit specialist AI sellers to act as synchronized virtual teams, each bringing domain-specific information while ensuring effortless workflow synchronization. These systems are best suited to high-throughput virtual screening uses, handling enormous chemical libraries while also assessing molecular properties, toxicities, and pharmacokinetic characteristics. Clinical trial optimization is greatly aided by artificial intelligence-based adaptive trial designs that permit real-time protocol adjustment, better patient stratification, and more efficient recruitment tactics. The move towards personalized medicine is a paradigm shift where individual genomic profiles of patients, biomarker data, and life habits influence therapeutic intervention. Sophisticated predictive modeling techniques decrease drug side effects while enhancing therapeutic effectiveness in various patient populations, making agentic AI a revolutionary driving force for pharmaceutical development and healthcare delivery systems globally.",
            "venue": "Journal of Information Systems Engineering and Management",
            "paperUrl": "https://www.semanticscholar.org/paper/f3e39e1591865352c99d55fa30798d6fe89859da",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.52783/jisem.v10i59s.12898",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        }
    ],
    "reviews": [
        {
            "year": "2025.09",
            "title": "Charting the evolution of artificial intelligence mental health chatbots from rule\u2010based systems to large language models: a systematic review",
            "team": "J. Torous",
            "team website": "",
            "affiliation": "",
            "domain": "Mental health chatbot architectures",
            "abstract": "The rapid evolution of artificial intelligence (AI) chatbots in mental health care presents a fragmented landscape with variable clinical evidence and evaluation rigor. This systematic review of 160 studies (2020\u20102024) classifies chatbot architectures \u2013 rule\u2010based, machine learning\u2010based, and large language model (LLM)\u2010based \u2013 and proposes a three\u2010tier evaluation framework: foundational bench testing (technical validation), pilot feasibility testing (user engagement), and clinical efficacy testing (symptom reduction). While rule\u2010based systems dominated until 2023, LLM\u2010based chatbots surged to 45% of new studies in 2024. However, only 16% of LLM studies underwent clinical efficacy testing, with most (77%) still in early validation. Overall, only 47% of studies focused on clinical efficacy testing, exposing a critical gap in robust validation of therapeutic benefit. Discrepancies emerged between marketed claims (\u201cAI\u2010powered\u201d) and actual AI architectures, with many interventions relying on simple rule\u2010based scripts. LLM\u2010based chatbots are increasingly studied for emotional support and psychoeducation, yet they pose unique ethical concerns, including incorrect responses, privacy risks, and unverified therapeutic effects. Despite their generative capabilities, LLMs remain largely untested in high\u2010stakes mental health contexts. This paper emphasizes the need for standardized evaluation and benchmarking aligned with medical AI certification to ensure safe, transparent and ethical deployment. The proposed framework enables clearer distinctions between technical novelty and clinical efficacy, offering clinicians, researchers and regulators ordered steps to guide future standards and benchmarks. To ensure that AI chatbots enhance mental health care, future research must prioritize rigorous clinical efficacy trials, transparent architecture reporting, and evaluations that reflect real\u2010world impact rather than the well\u2010known potential.",
            "venue": "World Psychiatry",
            "paperUrl": "https://www.semanticscholar.org/paper/8b6e4d0874844057237a5fd53e2e03a3c2c52e20",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1002/wps.21352",
            "reason_for_inclusion": "High quality: Published in World Psychiatry, a top-tier journal."
        },
        {
            "year": "2025.09",
            "title": "Best Practices for the Safe Use of Large Language Models and Other Generative AI in Radiology.",
            "team": "Vishwa S. Parekh",
            "team website": "",
            "affiliation": "",
            "domain": "Generative AI best practices in radiology",
            "abstract": "As large language models (LLMs) and other generative artificial intelligence (AI) models are rapidly integrated into radiology workflows, unique pitfalls threatening their safe use have emerged. Problems with AI are often identified only after public release, highlighting the need for preventive measures to mitigate negative impacts and ensure safe, effective deployment into clinical settings. This article summarizes best practices for the safe use of LLMs and other generative AI models in radiology, focusing on three key areas that can lead to pitfalls if overlooked: regulatory issues, data privacy, and bias. To address these areas and minimize risk to patients, radiologists must examine all potential failure modes and ensure vendor transparency. These best practices are based on the best available evidence and the experiences of leaders in the field. Ultimately, this article provides actionable guidelines for radiologists, radiology departments, and vendors using and integrating generative AI into radiology workflows, offering a framework to prevent these problems.",
            "venue": "Radiology",
            "paperUrl": "https://www.semanticscholar.org/paper/2dc8ce06575136b64ac13b32567e200653dbb8b0",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1148/radiol.241516",
            "reason_for_inclusion": "High quality: Published in Radiology, a top-tier journal in medical imaging."
        },
        {
            "year": "2025.09",
            "title": "Mitigating Ethical Issues for Large Language Models in Oncology: A Systematic Review.",
            "team": "Rui Zhang",
            "team website": "",
            "affiliation": "",
            "domain": "Ethical issues of LLMs in oncology",
            "abstract": "PURPOSE\nLarge language models (LLMs) have demonstrated remarkable versatility in oncology applications, such as cancer staging and survival analysis. Despite their potential, ethical concerns such as data privacy breaches, bias in training data, lack of transparency, and risks associated with erroneous outputs pose significant challenges to their adoption in high-stakes oncology settings. Therefore, we aim to explore the ethical challenges associated with LLM-based applications in oncology and evaluate emerging techniques designed to address these issues.\n\n\nMETHODS\nFollowing the Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework, a systematic review was conducted to evaluate publications related to ethical issues of LLMs in oncology across eight academic databases (eg, PubMed, Web of Science, and Embase) between January 1, 2019, and December 31, 2024.\n\n\nRESULTS\nThe search retrieved 4,319 published articles, of which 65 publications were preserved and included in our analysis. We identified six prevalent ethical challenges in oncology, including trust, equity, privacy, transparency, nonmaleficence, and accountability. We then evaluated emerging technical solutions to mitigate ethical challenges and summarized evaluation metrics used to assess these solutions' effectiveness.\n\n\nCONCLUSION\nThis review provides actionable recommendations for responsibly deploying LLMs in oncology, ensuring adherence to ethical guidelines, and fostering improved patient outcomes. By bridging technical and clinical perspectives, this review offers a foundational framework for advancing ethical artificial intelligence applications in oncology and highlights areas for future research.",
            "venue": "JCO clinical cancer informatics",
            "paperUrl": "https://www.semanticscholar.org/paper/008014c0fe9c31dfa58c4329d4f9d5307fd80016",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1200/CCI-25-00076",
            "reason_for_inclusion": "High quality: Published in JCO Clinical Cancer Informatics, a prestigious clinical journal."
        },
        {
            "year": "2025.09",
            "title": "A systematic mapping review on the capability of large language models in drug-drug interaction analysis",
            "team": "S. Biri",
            "team website": "",
            "affiliation": "",
            "domain": "LLMs for drug-drug interaction analysis",
            "abstract": "ABSTRACT Background Drug-drug interaction (DDI) is a global health concern affecting patient safety and treatment outcomes. Large language models (LLMs), such as ChatGPT, offer accessible alternatives; however, their effectiveness in DDI analysis remains unclear. This review evaluates the current evidence on the performance of LLM-based chatbots in identifying DDIs. Methods A PRISMA-compliant systematic review (PROSPERO: CRD420251020360) was conducted using PubMed, Scopus, and Web of Science (studies published between 1 January 2015, and 31 March 2025). Eligible studies included those using publicly accessible LLM chatbots for DDI detection. Results Nine studies (2023\u20132025) evaluated publicly accessible LLM chatbots, including ChatGPT, Bing AI, and Google Bard, for DDI identification. Methods varied from patient-level polypharmacy screening to single-drug checks and case vignettes. Chatbot performance was inconsistent: ChatGPT identified many potential DDIs, with ChatGPT-4.0 generally identifying more potential DDIs, but with variable accuracy, while Bing AI and Google Bard were less reliable. Conclusion Publicly accessible LLM chatbots demonstrate variable and partial effectiveness in detecting DDIs. There is a clear need to develop dedicated, freely available chatbots designed specifically for DDI identification. Future research should focus on standardizing evaluation methods and expanding access to improve medication safety in clinical practice. Prospero CRD420251020360 Plain Language Summary Taking many medicines at once (polypharmacy) can lead to drug-drug interactions (DDIs), where one drug affects how another works, causing side effects or reducing treatment success. Detecting DDIs is important, but it often relies on costly tools or expert knowledge, which may not be readily available in all settings. This study looked at how well public AI chatbots like ChatGPT, Bing AI, and Google Bard identify DDIs. Their performance was inconsistent across different chatbots and not reliable enough for medical use. Further research is needed to comment on their safety and accuracy.",
            "venue": "Expert Review of Clinical Pharmacology",
            "paperUrl": "https://www.semanticscholar.org/paper/2a3c4c175bcb3842a4a52dda33a3a4f9e5a970d1",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1080/17512433.2025.2568090",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        }
    ],
    "benchmarks": [
        {
            "year": "2025.09",
            "title": "The imitation game: large language models versus multidisciplinary tumor boards: benchmarking AI against 21 sarcoma centers from the ring trial",
            "team": "Cui Yang",
            "team website": "",
            "affiliation": "",
            "domain": "Sarcoma treatment recommendation comparison",
            "abstract": "The study aims to compare the treatment recommendations generated by four leading large language models (LLMs) with those from 21 sarcoma centers\u2019 multidisciplinary tumor boards (MTBs) of the sarcoma ring trial in managing complex soft tissue sarcoma (STS) cases. We simulated STS-MTBs using four LLMs\u2013Llama 3.2-vison: 90b, Claude 3.5 Sonnet, DeepSeek-R1, and OpenAI-o1 across five anonymized STS cases from the sarcoma ring trial. Each model was queried 21 times per case using a standardized prompt, and the responses were compared with human MTBs in terms of intra-model consistency, treatment recommendation alignment, alternative recommendations, and source citation. LLMs demonstrated high inter-model and intra-model consistency in only 20% of cases, and their recommendations aligned with human consensus in only 20\u201360% of cases. The model with the highest concordance with the most common MTB recommendation, Claude 3.5 Sonnet, aligned with experts in only 60% of cases. Notably, the recommendations across MTBs were highly heterogenous, contextualizing the variable LLM performance. Discrepancies were particularly notable, where common human recommendations were often absent in LLM outputs. Additionally, the sources for the recommendation rationale of LLMs were clearly derived from the German S3 sarcoma guidelines in only 24.8% to 55.2% of the responses. LLMs occasionally suggested potentially harmful information were also observed in alternative recommendations. Despite the considerable heterogeneity observed in MTB recommendations, the significant discrepancies and potentially harmful recommendations highlight current AI tools\u2019 limitations, underscoring that referral to high-volume sarcoma centers remains essential for optimal patient care. At the same time, LLMs could serve as an excellent tool to prepare for MDT discussions.",
            "venue": "Journal of Cancer Research and Clinical Oncology",
            "paperUrl": "https://www.semanticscholar.org/paper/d9cb979f15f584f231076a9c36e898c9599244b5",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1007/s00432-025-06304-9",
            "reason_for_inclusion": "High quality: Published in Journal of Cancer Research and Clinical Oncology, a reputable Q1 journal."
        },
        {
            "year": "2025.09",
            "title": "Modeling teacher education students\u2019 adoption of large language models through an extended technology acceptance framework",
            "team": "Jiaxin Lin",
            "team website": "",
            "affiliation": "",
            "domain": "Technology adoption in education",
            "abstract": "With the deepening integration of artificial intelligence (AI) technologies in the education sector, large language models (LLMs) have become essential tools for supporting writing tasks. As the future backbone of the teaching profession, the acceptance of these technologies by teacher education students not only influences their professional development but also plays a critical role in the digital transformation of future educational practices. However, existing research has yet to fully uncover the underlying mechanisms and influencing factors driving technology adoption behaviors within this group. This study extends the Technology Acceptance Model (TAM) by incorporating key variables such as learning motivation, perceived risks, self-efficacy, and usage experience. Using structural equation modeling (SEM), we analyzed survey data from 552 fourth-year teacher education students in China to test the proposed hypotheses. The empirical findings reveal that subjective norms are the strongest predictor of behavioral intention, while perceived ease of use significantly and positively influences attitudes toward using LLMs. Among the risk dimensions, perceived time risk exerts a significant negative effect on perceived usefulness, whereas perceived privacy risk negatively impacts perceived ease of use. Additionally, usage experience fosters technology adoption behaviors by enhancing learning motivation. These findings not only extend the application boundaries of the TAM within the field of educational technology but also provide empirical evidence for educational institutions to design technology training programs and for model developers to optimize user experiences. Furthermore, they offer a theoretical framework for building digital literacy training systems for teacher education students.",
            "venue": "Scientific Reports",
            "paperUrl": "https://www.semanticscholar.org/paper/7e108e82231a4581d61b466119c8f68c008355a1",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41598-025-03298-9",
            "reason_for_inclusion": "High quality: Published in Scientific Reports, a reputable open-access journal by Nature."
        },
        {
            "year": "2025.09",
            "title": "From algorithms to operating room: can large language models master China's attending anesthesiology exam? a cross-sectional evaluation.",
            "team": "Jiuhong Yuan",
            "team website": "",
            "affiliation": "",
            "domain": "Anesthesiology board exam performance",
            "abstract": "OBJECTIVE\nThe performance of large language models (LLMs) in complex clinical reasoning tasks is not well established. This study compares ChatGPT (GPT-3.5, GPT-4) and DeepSeek (DeepSeek-V3, DeepSeek-R1) in the Chinese anesthesiology attending physician examination (CAAPE), aiming to set AI benchmarks in medical assessments and enhance AI-driven medical education.\n\n\nMETHODS\nThis cross-sectional study assessed four iterations of two major LLMs on the 2025 CAAPE question bank (5,647 questions). Testing employed diverse querying strategies and languages, with subgroup analyses by subspecialty, knowledge type, and question format. The focus was on LLM performance in clinical and logical reasoning tasks, measuring accuracy, error types, and response times.\n\n\nRESULTS\nDeepSeek-R1 (70.6%-73.4%) and GPT-4 (68.6%-70.3%) outperformed DeepSeek-V3 (53.1%-55.5%) and GPT-3.5 (52.2%-55.7%) across all strategies. System role (SR) improved performance, while joint response degraded it. DeepSeek-R1 outperformed GPT-4 in complex subspecialties, reaching peak accuracy (73.4%) under SR combined initial response. GPT models performed better with English than Chinese queries. All models excelled in basic knowledge and Type A1 questions but struggled with clinical scenarios and advanced reasoning. Despite DeepSeek-R1's stronger performance, its response time was longer. Errors were primarily logical and informational (over 70%), with more than half being high-risk clinical errors.\n\n\nCONCLUSION\nLLMs show promise in complex clinical reasoning but risk critical errors in high-risk settings. While useful for education and decision support, their error potential must be carefully assessed in high-stakes environments.",
            "venue": "International journal of surgery",
            "paperUrl": "https://www.semanticscholar.org/paper/97de7f17b404aa7b484062f252576902358fe0aa",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1097/JS9.0000000000003406",
            "reason_for_inclusion": "High quality: Published in International Journal of Surgery, a high-impact surgical journal."
        }
    ],
    "foundation-models": [
        {
            "year": "2025.09",
            "title": "202eP Generalizable pan-cancer immunotherapy response prediction using the CURE AI large clinicogenomic foundation model",
            "team": "N.B. Pfister",
            "team website": "",
            "affiliation": "",
            "domain": "Pan-cancer immunotherapy response prediction",
            "abstract": "",
            "venue": "Annals of Oncology",
            "paperUrl": "https://www.semanticscholar.org/paper/05c6b1020a1d8018530f3a56702a00703d7170a0",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1016/j.annonc.2025.08.635",
            "reason_for_inclusion": "High quality: Published in Annals of Oncology, a top-tier journal."
        },
        {
            "year": "2025.09",
            "title": "PlantCAD2: A Long-Context DNA Language Model for Cross-Species Functional Annotation in Angiosperms",
            "team": "E. Buckler",
            "team website": "",
            "affiliation": "Cornell University",
            "domain": "Plant genomics DNA language model",
            "abstract": "Understanding how DNA sequence encodes biological function remains a fundamental challenge in biology. Flowering plants (angiosperms), the dominant terrestrial clade, exhibit maximal biochemical complexity, extraordinary species diversity (over 100,000 species), relatively recent origins (\u223c160 million years), \u223c200-fold variation in genome size and relative compact coding regions compared with other eukaryotes. These features present both a unique challenge and opportunity for pre-training DNA language models to understand plant-specific evolutionary conservation, regulatory architectures and genomic functions. Here, we introduce PlantCAD2, a long-context, plant-specific DNA language model with single-nucleotide resolution, pre-trained on 65 angiosperm genomes, together with a series of public benchmarks for evaluation. Comprehensive zero-shot testing shows that PlantCAD2 (676 million parameters) efficiently captures evolutionary conservation, surpassing the 7-billion-parameter Evo2 model in 10 of 12 tasks. With parameter-efficient fine-tuning, PlantCAD2 also outperforms the 1-billion-parameter AgroNT across seven cross-species tasks. Moreover, its 8 kb context window substantially improves accessible chromatin prediction in large genomes such as maize (AUPRC increasing from 0.587 to 0.711), underscoring the importance of long-range context for modeling distal regulation. Together, these results establish PlantCAD2 as a powerful, efficient, and versatile foundation model for plant genomics, enabling accurate genome annotation across diverse species.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/da44248c3ced760711c56032ca91d9f400ecea38",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.08.27.672609",
            "reason_for_inclusion": "High quality: Preprint affiliated with a renowned institution (Cornell University)."
        }
    ]
}