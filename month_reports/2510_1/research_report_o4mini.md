# Research Paper Report for 2025-10-01 to 2025-10-15

## Overall Summary

Between October 1 and October 15, 2025, research on large language models (LLMs) and agentic frameworks has accelerated across clinical applications, methodological innovations, foundational architectures, benchmarking studies, and dataset curation. A major theme is the deployment of LLM-based agents in healthcare settings: motivational interviewing in emergency departments [1], Crohn’s disease progression prediction [2], and hypertension management via a Cascade Framework integrating ChatGPT variants and DeepSeek-V3 showed substantial gains in classification accuracy (up to 95.3%) and decision support performance surpassing physicians [4]. Systematic review workflows have been revolutionized by retrieval-augmented generation (RAG) and human-in-the-loop orchestration, achieving screening and extraction accuracies between 61% and 99% in narrative analysis of 21 studies and proposing a modular SRMA framework [3]. Outside direct clinical care, personalized dialogues with LLMs effectively reduced conspiracy beliefs irrespective of perceived messenger identity [5].

Comprehensive surveys have synthesized the state of biomedical LLM agents [6], LLM effectiveness in antimicrobial resistance education comparing ChatGPT, Claude, and Gemini (performance gradient from Gemini to ChatGPT 3.5) [7], and language-driven intelligence in single-cell biology (LLM4Cell categorizing 58 models across multi-omic and spatial modalities) [8]. Foundational model research introduced Life2Vec embeddings for temporal patient histories, boosting FOH hospitalization prediction AUC-PR from 0.053 to 0.083 [9], and MC-CLIP, a multimodal vision-language model pretrained on 2.4 million image-text pairs, outperformed senior endoscopists in H. pylori infection detection (up to 91.4% sensitivity) [10].

Benchmarking studies revealed significant variability among free LLMs on scientific Q&A, with Claude 3.5 Sonnet leading, and demonstrated that LLM-based Delphi simulations can exceed human expert consensus rates (93.3% vs. 81.5%), although commercial platform opacity limits reproducibility [11, 13]. Community efforts have produced specialized datasets for headache diagnosis in neurology [14] and a large-scale RadGenome-Chest CT resource with 1.2 million grounded VQA pairs and 197 organ-level segmentation masks to advance multimodal medical foundation models [15].

Emerging trends include RAG to mitigate hallucinations, agent-based orchestration for complex workflows, masked language modeling for temporal health data, and multimodal fusion of vision and text. Technical innovations such as the Cascade Framework and MC-CLIP showcase end-to-end system integration, while methodological advancements stress human oversight to preserve rigour. Significant breakthroughs—ranging from diagnostic accuracy gains to consensus-building capabilities—are tempered by limitations in real-world deployment validation, dataset biases, and the need for standardized evaluation metrics. Future research should prioritize empirical validations, open benchmarks, regulatory frameworks, and ethical governance to translate these technical advances into trustworthy, clinically deployable AI systems.

## Table of Contents

- [AI Agents](#ai-agents)  
- [Reviews](#reviews)  
- [Foundation Models](#foundation-models)  
- [Benchmarks](#benchmarks)  
- [Databases](#databases)  

## AI Agents

The AI Agents category (papers [1]–[5]) examines the design, evaluation, and deployment of LLM-based conversational frameworks and predictive agents in clinical and behavioral health contexts. Motivational interviewing in emergency care was explored by Vanessa Pitre [1], illustrating feasibility and acceptability but lacking detailed metrics. In parallel, Xuehua Li’s multicenter retrospective study [2] applied human-knowledge enhanced LLMs to predict Crohn’s disease progression, though methodological details remain undisclosed. Jinge Wu’s narrative review [3] analyzed 21 SRMA studies, reporting LLM screening and extraction accuracies from 61% to 99%, and proposed a modular RAG- and agent-based framework with human-in-the-loop oversight to tackle hallucinations and bias. Jun Wang’s investigation [4] introduced the Cascade Framework on the Dify platform, benchmarking six LLM configurations (ChatGPT-4o, ‑4oMini, DeepSeek-V3) with and without Cascade enhancement; results demonstrated significant improvements in educational metrics (e.g., credibility P < 0.001) and blood pressure classification accuracy rising from 62.5% to 87.0%. Gordon Pennycook’s randomized experiment [5] (N=955) showed that fact-based dialogues with LLMs reduce conspiracy and epistemically unwarranted beliefs, independent of whether the agent was framed as AI or human and regardless of conversational tone. Collectively, these works showcase methodological diversity—from narrative reviews and retrospective studies to randomized trials—highlighting innovations in RAG integration, multi-model benchmarking, and behavioral interventions. Limitations include sparse transparency in some predictive pipelines [2], the need for empirical real-world trials [3], and variable user perceptions of AI agents. Future directions should integrate longitudinal outcome tracking, transparent parameter reporting, and domain-specific fine-tuning to optimize clinical and psychological interventions.

| Index | Title                                                                                                            | Domain                                                           | Venue                                | Team             | DOI                                        | affiliation | paperUrl                                           |
|-------|------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|--------------------------------------|------------------|--------------------------------------------|-------------|----------------------------------------------------|
| 1     | Feasibility and Acceptability of a Large Language Model-Based Motivational Interviewing Agent in the Emergency Department. | Motivational interviewing LLM agent in emergency care            | Annals of emergency medicine         | Vanessa Pitre    | 10.1016/j.annemergmed.2025.08.021         |             | [Link](https://www.semanticscholar.org/paper/949ace206622c4aa82bdb95d722f4fe365bda11d) |
| 2     | Human knowledge-enhanced large language model agent for prediction of intestinal disease progression in patients with Crohn’s disease: A multicenter retrospective study | Crohn’s disease progression prediction with LLM agent            | Meta-Radiology                       | Xuehua Li        | 10.1016/j.metrad.2025.100186              |             | [Link](https://www.semanticscholar.org/paper/6b3ade2ee392a3da6a6071177044201128b35b9c) |
| 3     | Large language model enhanced framework for systematic reviews and meta-analyses                                | LLM-enhanced framework for systematic reviews and meta-analyses  | BMJ Digital Health & AI              | Jinge Wu         | 10.1136/bmjdhai-2025-000017               |             | [Link](https://www.semanticscholar.org/paper/7543c4368d844cf0a9320e43630cd26b502b6ad1) |
| 4     | Large Language Model Agent for Managing Patients With Suspected Hypertension.                                     | Hypertension management LLM agent                                | Hypertension                         | Jun Wang         | 10.1161/HYPERTENSIONAHA.125.25305         |             | [Link](https://www.semanticscholar.org/paper/52f1b628bd6246106058a359604bcfebad30ecc6)   |
| 5     | Dialogues with large language models reduce conspiracy beliefs even when the AI is perceived as human           | LLM dialogues for reducing conspiracy beliefs                    | PNAS Nexus                           | Gordon Pennycook | 10.1093/pnasnexus/pgaf325                |             | [Link](https://www.semanticscholar.org/paper/7d909a8b3c49ecf6962b80d686d790b5dbe257b4) |

## Reviews

The Reviews section (papers [6]–[8]) offers comprehensive surveys of LLM and agentic methodologies across biomedical domains, antimicrobial resistance education, and single-cell biology. Ravi Sankar’s review [6] dissects core architectures of biomedical LLM agents, detailing reasoning, planning, memory, and tool integration, and surveys use cases in decision support and patient simulation; it evaluates emerging interactive benchmarks and outlines challenges in hallucinations, interpretability, and regulation, advocating for federated adaptation and robust multi-agent coordination. L. Villani’s comparative study [7] prompts ChatGPT 3.5, ChatGPT 4.0, Claude 2.0, and Gemini 1.0 in English and Italian, applies computational text analysis (readability, lexical diversity, sentiment) and expert DISCERN ratings to assess AMR content quality, finding a performance gradient from Gemini to ChatGPT 3.5 with impact on AMR scoring low across models; limitations include self-interruption by Gemini and lack of domain-specific calibration. Liqing Zhang’s LLM4Cell survey [8] catalogs 58 models in single-cell research, classifies them into foundation, text-bridge, spatial, multimodal, epigenomic, and agentic families, and maps eight tasks (annotation, trajectory modeling, drug response) across 40+ datasets; evaluation covers biological grounding, multi-omics alignment, fairness, privacy, and explainability. Comparative analysis reveals fragmentation in modality coverage and evaluation standards. Collectively, these reviews underscore the need for standardized benchmarks, ethical frameworks, and integrated datasets to advance trustworthy, scalable, and clinically deployable LLM agents.

| Index | Title                                                                                                                  | Domain                                                                       | Venue                                          | Team             | DOI                                | affiliation | paperUrl                                           |
|-------|------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------|------------------------------------------------|------------------|------------------------------------|-------------|----------------------------------------------------|
| 6     | Large Language Model Agents for Biomedicine: A Comprehensive Review of Methods, Evaluations, Challenges, and Future Directions | Comprehensive review of biomedical LLM agents                                | Information                                    | Ravi Sankar      | 10.3390/info16100894               |             | [Link](https://www.semanticscholar.org/paper/aa3da305318799a02ab371318bd01678187ef080) |
| 7     | Large language models to reduce antimicrobial resistance: ChatGPT, Claude and Gemini comparison                         | Survey of user trust in healthcare LLMs in Saudi Arabia                      | The European Journal of Public Health          | L. Villani       | 10.1093/eurpub/ckaf161.316         |             | [Link](https://www.semanticscholar.org/paper/014a5845cf9a0c2cc2ed6d0c800a67a540094b80) |
| 8     | LLM4Cell: A Survey of Large Language and Agentic Models for Single-Cell Biology                                       | Survey of LLM and agentic models for single-cell biology                     | ArXiv                                          | Liqing Zhang     | 10.48550/arXiv.2510.07793          |             | [Link](https://www.semanticscholar.org/paper/fb2c169f42adb99f8f3c37e24e2eba98df65e952) |

## Foundation Models

Foundation-model research (papers [9]–[10]) introduces novel pretraining and multimodal techniques for healthcare analytics. Bellocchio et al. [9] developed a Life2Vec architecture to pretrain on temporal hemodialysis records—transforming continuous variables into percentile-based tokens and applying masked language modeling and sequence order prediction—yielding 12-dimensional embeddings that capture inter-variable dependencies and progression context. When used with an XGBoost classifier, embeddings improved fluid overload hospitalization prediction AUC-PR from 0.053 (raw data) to 0.083 (P < 0.001), representing a ten-fold discrimination gain for a rare event (prevalence 0.8%). Hongmei Jiao’s MC-CLIP model [10] leverages 2.4 million MCCE image-text pairs for vision-language pretraining, fine-tuned on 40,695 annotated images, and autonomously selects 30 frames per case for end-to-end classification of H. pylori infection. On internal and external cohorts, MC-CLIP achieved 89.6% and 86.6% accuracies, respectively, outperforming senior endoscopists (84.3%) and demonstrating >90% specificity across categories. Both studies emphasize large-scale pretraining, rigorous multicenter validation, and embedding-driven downstream tasks. Limitations include potential overfitting to specific populations, computational overhead of large pretraining corpora, and the need for real-time inference optimization.

| Index | Title                                                                                                                               | Domain                                                                   | Venue                                  | Team            | DOI                                 | affiliation | paperUrl                                           |
|-------|-------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|----------------------------------------|-----------------|-------------------------------------|-------------|----------------------------------------------------|
| 9     | #3218 Predicting fluid overload hospitalizations in hemodialysis patients using a foundational model and large language model techniques | Fluid overload hospitalization prediction in hemodialysis with foundational LLM | Nephrology Dialysis Transplantation    | F. Bellocchio   | 10.1093/ndt/gfaf116.0786            |             | [Link](https://www.semanticscholar.org/paper/1162518e157df984005781befad5137fe322e387) |
| 10    | AI-powered three-category Helicobacter pylori diagnosis via magnetic controlled capsule endoscopy: a multicenter validation of a vision-language model | Vision-language model for H. pylori diagnosis via capsule endoscopy     | Frontiers in Microbiology              | Hongmei Jiao    | 10.3389/fmicb.2025.1687021          |             | [Link](https://www.semanticscholar.org/paper/d33e009f7804910b78436dbf1ef9c33b0b4735a0) |

## Benchmarks

Benchmarking efforts (papers [11]–[13]) systematically compare LLM capabilities in scientific QA, clinical decision scenarios, and consensus simulation. Barrajón-Catalán et al. [11] engaged 16 expert reviewers to evaluate Claude 3.5 Sonnet, Gemini, ChatGPT 4o, Mistral Large 2, and Llama 3.1 70B on depth, accuracy, relevance, clarity, and applied RAG and prompt refinement to enhance responses; Claude 3.5 Sonnet led, but ethical transparency concerns persisted. Eric Bressman’s study [12] —though lacking detailed metrics in its abstract—investigates variability in LLM recommendations for challenging inpatient management, highlighting inconsistent clinical advice across models. A. Han’s modified Delphi simulation [13] used eight LLMs over three rounds to evaluate 135 surgical consensus statements; LLMs reached 93.3% consensus versus 81.5% for human experts (Spearman’s ρ = 0.73), with LLMs showing guideline-driven conservatism but limited reproducibility due to commercial platform constraints. Comparative analysis underscores the importance of structured evaluation frameworks, ethical guideline integration, and open platform parameterization. Future work should expand domain diversity, increase sample sizes, and develop reproducible benchmarking toolkits.

| Index | Title                                                                                                            | Domain                                                                 | Venue                                   | Team              | DOI                                      | affiliation | paperUrl                                           |
|-------|------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------|-----------------------------------------|-------------------|------------------------------------------|-------------|----------------------------------------------------|
| 11    | There are significant differences among artificial intelligence large language models when answering scientific questions | Comparative evaluation of LLMs on scientific question answering         | Frontiers in Artificial Intelligence    | E. Barrajón-Catalán | 10.3389/frai.2025.1664303               |             | [Link](https://www.semanticscholar.org/paper/fb8c61c3c19c42a2ea24c9d24d8fe154a1c2ad5c) |
| 12    | Variation in Large Language Model Recommendations in Challenging Inpatient Management Scenarios.                  | Variability of LLM clinical recommendations in inpatient scenarios      | Journal of general internal medicine   | Eric Bressman     | 10.1007/s11606-025-09888-7               |             | [Link](https://www.semanticscholar.org/paper/8111d51e12be7239b1bdceb41a8a7d49364ce36f) |
| 13    | How does AI compare to the experts in a Delphi setting: simulating medical consensus with large language models.   | Simulating Delphi consensus with LLMs in medical decision-making        | International journal of surgery       | A. Han            | 10.1097/JS9.0000000000003631             |             | [Link](https://www.semanticscholar.org/paper/78f0fe0f64e3c240cb970a1a09aa3246dcf7b17d) |

## Databases

The Databases category (papers [14]–[15]) focuses on curated resources for community evaluation and foundation-model training. Dorian Zwanzig’s work [14] outlines the development of a headache diagnosis dataset aimed at community-based evaluation of LLMs in neurology, though details on case variety, annotation protocols, and evaluation splits remain pending. Yanfeng Wang’s RadGenome‐Chest CT dataset [15] provides a large-scale, region-guided 3D chest CT resource with 197 organ-level segmentation masks, 665K grounded report sentences, and 1.2 million grounded VQA pairs linked to segmentation regions. This multimodal dataset leverages universal segmentation models and LLMs to supply diverse supervision signals for medical foundation models. While [15] offers granular visual-text alignments to enable region-specific interpretation, both datasets will require open-source release, standardized annotation guidelines, and challenging evaluation benchmarks to ensure broad adoption and reproducibility.

| Index | Title                                                                                                           | Domain                                                                 | Venue                                         | Team             | DOI                               | affiliation | paperUrl                                           |
|-------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------|-----------------------------------------------|------------------|-----------------------------------|-------------|----------------------------------------------------|
| 14    | Towards Community-Based Evaluation of AI in Neurology: Development of a Headache Diagnosis Dataset for Large Language Models. | Headache diagnosis dataset for community-based LLM evaluation in neurology | Studies in health technology and informatics | Dorian Zwanzig  | 10.3233/SHTI251535                |             | [Link](https://www.semanticscholar.org/paper/16e555468e627ef481d4d175fd23ccf75b2267c6) |
| 15    | Development of a large-scale grounded vision language dataset for chest CT analysis                               | RadGenome-Chest CT: large-scale grounded vision-language dataset for chest CT | Scientific Data                              | Yanfeng Wang     | 10.1038/s41597-025-05922-9        |             | [Link](https://www.semanticscholar.org/paper/3912db2f306b51446460ca728fc328fdf05e41f5) |

