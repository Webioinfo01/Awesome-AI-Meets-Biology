# Research Paper Report for 2025-07-01 to 2025-07-15

## Overall Summary

Between July 1 and July 15, 2025, research leveraging large language models (LLMs) and foundation models advanced across multiple scientific domains, from cybersecurity and materials design to clinical imaging and bioinformatics. A key theme is the orchestration of specialized agents: tactics planning agents for cyber offense and defense [1], an evolutionary optimization agent for transition metal complex design [2], and a multiagent bioinformatics copilot that synergizes AI and human researchers for large‐scale omics analysis [3]. These works illustrate how LLMs act not only as generators but also as coordinators of sub-agents, enabling automated hypothesis generation and domain-specific decision making.

Interdisciplinary connections emerge strongly between computational chemistry and AI, with LLM‐based frameworks solving multiobjective optimization in inorganic chemistry [2] and integrating topological data analysis with semantic embeddings for drug–target interaction prediction [12]. In bioinformatics, both agent-based copilots [3] and code-generation benchmarking for reproductive health modeling [5] demonstrate the practical implications of LLMs in accelerating data analysis and democratizing access to advanced predictive pipelines.

Methodological innovations abound: retrieval-augmented generation for podcast-derived STEMM knowledge in audio-augmented LLMs [9], symmetric contrastive learning to align CT volumes with radiology reports [11], and fine-tuning large protein language models for peptide discovery [14]. Edge deployability is addressed by MiniCPM-V, an 8B-parameter multimodal LLM achieving GPT-4V-level performance on mobile devices [6]. Meanwhile, clinicogenomic foundation models like CURE AI employ proprietary deep-learning architectures for pan-cancer immunotherapy response prediction, yielding cost‐saving trial refinements [7].

Significant breakthroughs include: state-of-the-art performance in CT pulmonary angiogram report generation and survival prediction (AUROC up to 0.788–0.863) [8], human cognition simulation across millions of behavioral trials with Centaur [10], and million-scale pretraining for chemical language models supporting few-shot learning [13]. The GastroNet-5M dataset [15] sets a new standard for endoscopic AI, demonstrating self-supervised models that outperform prior systems in both accuracy and data efficiency.

Limitations surface around generalization and data bias. Many foundation models rely on proprietary datasets, raising reproducibility concerns [7,11]. Energy and computational demands, though mitigated by model compression [6], remain nontrivial. Benchmarking studies note domain-specific constraints; for example, LLM code generation excels in R over Python due to ecosystem maturity [5]. Future work must address data diversity, cross-domain transfer, explainability, and sustainable deployment, ensuring these powerful models deliver robust, transparent, and equitable advances across science and medicine.

## Table of Contents

- [ai-agents](#ai-agents)  
- [reviews](#reviews)  
- [benchmarks](#benchmarks)  
- [foundation-models](#foundation-models)  
- [databases](#databases)  

## ai-agents

The three papers categorized under ai-agents focus on leveraging LLMs as autonomous decision-making systems across cybersecurity, chemical design, and bioinformatics. Zhu et al. [1] introduce an LLM-based framework for automated tactics planning in cyber attack and defense, orchestrating AI agents to simulate adversarial strategies and countermeasures. Though the abstract is absent, the venue and domain imply a neural-network-driven approach to sequential decision planning. Duan et al. [2] present LLM-EO, which integrates a pretrained LLM into an evolutionary optimization loop for multiobjective design of transition metal complexes. LLM-EO leverages intrinsic chemical knowledge and few-shot learning to generate novel ligands, reducing sample complexity and improving accessibility through natural language instructions. Li et al. [3] propose Bio-Copilot, a multiagent system combining LLMs with human experts for large-scale omics analysis, featuring agent group management, human–agent interaction protocols, a shared interdisciplinary knowledge base, and continual learning. Evaluated against GPT-4o on diverse tasks and a human lung cell atlas construction, Bio-Copilot achieves state-of-the-art completeness and uncovers rare cell types via recursive annotation.

Comparative analysis reveals that while [1] emphasizes adversarial planning without disclosed metrics, [2] and [3] provide detailed methodology and evaluations: LLM-EO’s performance stems from evolutionary loops augmented by LLM reasoning, and Bio-Copilot showcases superior task coverage and insight generation metrics. All three illustrate a shift from passive language modeling toward active, domain-specific agent frameworks, yet limitations include the need for domain-tailored training data, transparency of decision logic, and computational overhead for multiagent coordination. Future directions involve unifying these paradigms to build hybrid systems capable of both scientific discovery and secure operational planning.

| Index | Title                                                                                           | Domain                                               | Venue                                                                        | Team            | DOI                       | affiliation | paperUrl                                                                                                     |
|-------|-------------------------------------------------------------------------------------------------|------------------------------------------------------|------------------------------------------------------------------------------|-----------------|---------------------------|-------------|--------------------------------------------------------------------------------------------------------------|
| 1     | Automated tactics planning for cyber attack and defense based on large language model agents    | LLM agents for cyber attack and defense planning     | Neural networks : the official journal of the International Neural Network Society | Hongsong Zhu    | 10.1016/j.neunet.2025.107842 |             | [Link](https://www.semanticscholar.org/paper/c79fe6c063762dd70306fd851b0a81bbdcf95852)                     |
| 2     | Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge and Reasoning Capability of Large Language Models. | Generative design of metal complexes with LLM         | Journal of the American Chemical Society                                    | Chenru Duan     | 10.1021/jacs.5c02097       |             | [Link](https://www.semanticscholar.org/paper/8df02adea0c856f729ccebd23a94cf2823c66c32)                     |
| 3     | A data-intelligence-intensive bioinformatics copilot system for large-scale omics research and scientific insights | Bioinformatics copilot for omics data analysis       | Briefings in Bioinformatics                                                 | Yixue Li        | 10.1093/bib/bbaf312        |             | [Link](https://www.semanticscholar.org/paper/c5648395711f73241870c31516b4c4898f7a18b7)                     |

## reviews

Shen-Han Lee [4] delivers a thought-provoking commentary on biomedical education in the age of LLMs, using a narrative set in 2050 to critique overreliance on AI. The paper argues that reliance on LLM outputs has eroded critical thinking, illustrated by a PhD student’s passive acceptance of AI-generated conclusions during cancer immunotherapy research. Lee highlights the cultural shift in scientific training: students lose the habit of asking “Why?” and instead defer to model outputs. The narrative culminates in a conference scenario where the student’s inability to interpret a novel biomarker exposes gaps in understanding. This work serves as both a cautionary tale and call to integrate AI literacy with foundational reasoning skills. While not empirical, the piece underscores the need for curricula that balance AI tool proficiency with scientific skepticism, pointing to future educational frameworks that embed explainability and manual hypothesis testing alongside LLM use. The limitations lie in its speculative style and lack of actionable guidelines, but its practical implication—to reform training programs to foster critical reasoning in tandem with AI adoption—resonates across disciplines.

| Index | Title                                                                                           | Domain                                         | Venue                                 | Team             | DOI                   | affiliation | paperUrl                                                                                                    |
|-------|-------------------------------------------------------------------------------------------------|------------------------------------------------|---------------------------------------|------------------|-----------------------|-------------|-------------------------------------------------------------------------------------------------------------|
| 4     | Biomedical education in the era of large language models: a paradigm shift                     | Commentary on biomedical education with LLMs     | The Journal of Clinical Investigation | Shen-Han Lee     | 10.1172/JCI196863     |             | [Link](https://www.semanticscholar.org/paper/f4c86d7eaa9d0e9a69608714389792c376de46a5)                      |

## benchmarks

Sirota et al. [5] benchmark eight LLMs on four predictive modeling tasks using standardized DREAM reproductive health datasets. They prompt models with task descriptions and data access, then evaluate R and Python code generation by running outputs and ranking success. Results show R code succeeds in 14/16 tasks versus 7/16 for Python, likely due to Bioconductor’s ecosystem. OpenAI’s o3-mini-high completes 7/8 tasks and matches or exceeds original DREAM challenge teams in test set performance. Metrics include code execution success, accuracy of predictive models on gestational age regression (gene expression and DNA methylation) and classification of preterm births from microbiome data. This study underscores LLMs’ potential to democratize exploratory analysis and accelerate pipeline development for omics predictive modeling. Limitations include domain specificity to reproductive health, reliance on public repositories, and variability across languages. Future work should extend to broader biomedical datasets, integrate pipeline orchestration beyond code generation, and evaluate sustainability of automated analysis in production environments.

| Index | Title                                                                                           | Domain                                                    | Venue   | Team     | DOI                             | affiliation                                                               | paperUrl                                                                                                     |
|-------|-------------------------------------------------------------------------------------------------|-----------------------------------------------------------|---------|----------|---------------------------------|---------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|
| 5     | Benchmarking Large Language Models for Predictive Modeling in Biomedical Research With a Focus on Reproductive Health | LLM code generation for predictive modeling in omics      | bioRxiv | M. Sirota | 10.1101/2025.07.07.663529        | Bakar Computational Health Sciences Institute, University of California, San Francisco | [Link](https://www.semanticscholar.org/paper/c74bd3e494fbaa2e2d9cb99d3887de251c815f8f)                   |

## foundation-models

This category encompasses nine foundation and specialized models that broaden LLM applications to multimodal, clinical, educational, and scientific domains. MiniCPM-V [6] is an 8B-parameter multimodal LLM optimized for edge devices via architecture and data efficiency improvements, matching GPT-4V on 11 benchmarks with robust OCR and multilingual support. CURE AI [7] is a clinicogenomic foundation model trained on hundreds of thousands of oncology patients’ multi-omics and clinical trial data; it predicts immunotherapy response across cancers, enabling >50% trial size reduction and significant cost savings. Bai et al. [8] leverage a vision-language pipeline for CT pulmonary angiography, using VLMs for detecting 32 PE abnormalities (AUROC up to 0.788) and a multimodal fusion model for survival prediction (concordance up to 0.863). PodGPT [9] uses retrieval-augmented generation on 3700 h of STEMM podcasts to improve dialogue nuanced understanding, yielding 1.82–2.43 percentage point benchmark gains and enhanced zero-shot multilingual performance.

Centaur [10] fine-tunes an LLM on Psych-101, 10 M choices dataset, to simulate human behavior across 160 experiments, achieving stronger generalization to novel tasks and alignment with neural activity. Percival [11] employs a dual-encoder transformer for 400 K CT volumes paired with reports, outperforming limited anatomical models in image-text recall and revealing latent phenotypic structures. Top-DTI [12] integrates persistent homology features from protein maps and LLM embeddings of SMILES and sequences, improving AUROC, AUPRC, sensitivity, and specificity on BioSNAP and Human DTI benchmarks, notably in cold-split settings. Schmidt et al. [13] introduce SMI-TED289M, encoder-decoder models pre-trained on 91 M PubChem SMILES; they excel in property estimation and reaction prediction, supporting few-shot tasks. Finally, BertADP [14] fine-tunes ProtBert on a curated ADP dataset (899 peptides + 67 candidates), achieving 0.955 accuracy, 1.000 sensitivity, and 0.910 specificity for anti-diabetic peptide prediction. Collectively, these works highlight trends in model compression, cross-modal alignment, topology-aware embeddings, and domain-specific fine-tuning, while underscoring challenges in data heterogeneity, reproducibility, and explainability.

| Index | Title                                                                                           | Domain                                                         | Venue                     | Team                    | DOI                                  | affiliation                                                              | paperUrl                                                                                                     |
|-------|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------|---------------------------|-------------------------|--------------------------------------|---------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|
| 6     | Efficient GPT-4V level multimodal large language model for deployment on edge devices          | Edge-deployable multimodal LLMs                                | Nature Communications     | Maosong Sun            | 10.1038/s41467-025-61040-5           |                                                                           | [Link](https://www.semanticscholar.org/paper/a0c6365a23a07e26bf90db410574cad3ff68edba)                       |
| 7     | Abstract B011: Pan-cancer immunotherapy response prediction using the CURE AI large clinicogenomic foundation model | Clinicogenomic foundation model in immunotherapy               | Clinical Cancer Research | Neil T. Pfister         | 10.1158/1557-3265.aimachine-b011     |                                                                           | [Link](https://www.semanticscholar.org/paper/5aab6696a4bf683144a6957ad7c88d2e3b7f2b44)                       |
| 8     | Vision-language model for report generation and outcome prediction in CT pulmonary angiogram   | Vision-language model for CT pulmonary angiogram               | NPJ Digital Medicine      | Harrison X. Bai         | 10.1038/s41746-025-01807-8          |                                                                           | [Link](https://www.semanticscholar.org/paper/8452c2f5cee9adc02b715fada8284367fdab100b)                       |
| 9     | PodGPT: an audio-augmented large language model for research and education                      | Audio-augmented LLM for educational podcasts                  | Npj Biomedical Innovations | V. Kolachalama          | 10.1038/s44385-025-00022-0           |                                                                           | [Link](https://www.semanticscholar.org/paper/655eb5b4ba685b7e3104e6560a63aa88a5768437)                       |
| 10    | A foundation model to predict and capture human cognition                                       | Foundation model for human cognition simulation                | Nature                    | Eric Schulz            | 10.1038/s41586-025-09215-4          |                                                                           | [Link](https://www.semanticscholar.org/paper/a4e64dee0d0f284edc160a9a8bc2b4385577249a)                       |
| 11    | A Pan-Organ Vision-Language Model for Generalizable 3D CT Representations                       | Pan-organ vision-language model for CT                        | medRxiv                   | Walter R. Witschey      | 10.1101/2025.07.03.25330654         | University of Pennsylvania                                               | [Link](https://www.semanticscholar.org/paper/b8b956b001622ede4668e052e45f274e48d45ead)                       |
| 12    | Top-DTI: integrating topological deep learning and large language models for drug–target interaction prediction | Topological deep learning and LLM for DTI prediction           | Bioinformatics            | S. Bozdag               | 10.1093/bioinformatics/btaf183       |                                                                           | [Link](https://www.semanticscholar.org/paper/ffa4bce26de7cfe69f7384c621e2387a8f0ade7d)                       |
| 13    | An open-source family of large encoder-decoder foundation models for chemistry                  | Encoder-decoder foundation models for chemistry                | Communications Chemistry  | Kristin Schmidt        | 10.1038/s42004-025-01585-0          |                                                                           | [Link](https://www.semanticscholar.org/paper/2c66c5a1591cfdb56db555074453a0ecb3efd953)                       |
| 14    | BertADP: a fine-tuned protein language model for anti-diabetic peptide prediction               | Protein language model for anti-diabetic peptide prediction     | BMC Biology               | Hao Lin                | 10.1186/s12915-025-02312-w           |                                                                           | [Link](https://www.semanticscholar.org/paper/e8b5544c2d6f942658709030a87b506bc7a5eb29)                       |

## databases

GastroNet-5M [15] presents a multi-center corpus of approximately 4.82 million anonymized endoscopic images from ~500,000 procedures across eight Dutch hospitals (2012–2020). Using self-supervised learning, the authors pretrain foundation models and compare them to existing endoscopic AI systems on 17 GI applications, evaluating classification and segmentation accuracy, data efficiency, and robustness to heterogeneity (e.g., different endoscope manufacturers). Results show GastroNet-5M-pretrained models outperform both public foundation models and specialized non-foundation systems, achieving higher task accuracy with significantly fewer fine-tuning samples. This resource addresses a critical bottleneck in medical imaging AI—scarcity of annotated data—by providing a large, diverse dataset that improves model generalization in clinical practice. Limitations include geographic-centric data and potential sampling biases. Future work should expand to diverse populations, integrate multi-modal clinical metadata, and explore privacy-preserving training protocols to maximize clinical translation.

| Index | Title                                                                                           | Domain                                             | Venue       | Team        | DOI                         | affiliation | paperUrl                                                                                                     |
|-------|-------------------------------------------------------------------------------------------------|----------------------------------------------------|-------------|-------------|-----------------------------|-------------|--------------------------------------------------------------------------------------------------------------|
| 15    | GastroNet-5M: A Multicenter Dataset for Developing Foundation Models in Gastrointestinal Endoscopy. | Gastrointestinal endoscopy image dataset           | Gastroenterology | J. Bergman | 10.1053/j.gastro.2025.07.030 |             | [Link](https://www.semanticscholar.org/paper/87e8a2c1d78996458471669cb8e707b8e3de1be7)                      |