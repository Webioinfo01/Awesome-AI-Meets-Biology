{
    "ai-agents": [
        {
            "year": "2025.07",
            "title": "Automated tactics planning for cyber attack and defense based on large language model agents",
            "team": "Hongsong Zhu",
            "team website": "",
            "affiliation": "",
            "domain": "LLM agents for cyber attack and defense planning",
            "abstract": "",
            "venue": "Neural networks : the official journal of the International Neural Network Society",
            "paperUrl": "https://www.semanticscholar.org/paper/c79fe6c063762dd70306fd851b0a81bbdcf95852",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1016/j.neunet.2025.107842",
            "reason_for_inclusion": "High quality: Published in Neural Networks, a reputable journal."
        },
        {
            "year": "2025.07",
            "title": "Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge and Reasoning Capability of Large Language Models.",
            "team": "Chenru Duan",
            "team website": "",
            "affiliation": "",
            "domain": "Generative design of metal complexes with LLM",
            "abstract": "Large language models (LLMs) have shown promise in science, such as structure-property prediction and acting as AI agents, yet their intrinsic knowledge and reasoning capability for scientific discovery remains underexplored. We introduce LLM-EO, an integration of LLMs into evolutionary optimization, and demonstrate its success in optimizing transition metal complexes (TMCs). LLM-EO demonstrates advantages in few-sample learning due to the intrinsic chemical knowledge embedded within LLMs and their ability to leverage entire historical data collected during optimizations. Through natural language instructions, LLM-EO offers enhanced accessibility for multiobjective optimizations, potentially lowering barriers for experimental chemists without extensive programming expertise. As generative models, LLM-EO possesses the capability to propose novel ligands and TMCs with unique chemical properties by amalgamating both internal knowledge and external chemistry data, thus combining the benefits of efficient optimization and generation. With advancements in LLMs, both in their capacity as pretrained foundational models and new strategies in post-training inference, we anticipate broad applications of LLM-EO in chemistry and materials design.",
            "venue": "Journal of the American Chemical Society",
            "paperUrl": "https://www.semanticscholar.org/paper/8df02adea0c856f729ccebd23a94cf2823c66c32",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1021/jacs.5c02097",
            "reason_for_inclusion": "High quality: Published in Journal of the American Chemical Society, a top-tier journal."
        },
        {
            "year": "2025.07",
            "title": "A data-intelligence-intensive bioinformatics copilot system for large-scale omics research and scientific insights",
            "team": "Yixue Li",
            "team website": "",
            "affiliation": "",
            "domain": "Bioinformatics copilot for omics data analysis",
            "abstract": "Abstract Advancements in high-throughput sequencing technologies and artificial intelligence (AI) offer unprecedented opportunities for groundbreaking discoveries in bioinformatics research. However, the challenges of exponential growth of omics data and the rapid development of AI technologies require automated big biological data analysis capability and interdisciplinary knowledge-driven scientific insight. Here, we propose a data-intelligence-intensive bioinformatics copilot (Bio-Copilot) system that synergizes AI capabilities with human researchers to facilitate hypothesis-free exploratory research and inspire novel scientific insights in large-scale omics studies. Bio-Copilot forms high-quality intensive intelligence through close collaboration between multiple agents, driven by large language models (LLMs), and human researchers. To augment the capabilities of Bio-Copilot, this study devises an agent group management strategy, an effective human\u2013agent interaction mechanism, a shared interdisciplinary knowledge database, and continuous learning strategies for the agents. We comprehensively compare Bio-Copilot against GPT-4o and several leading AI agents across diverse bioinformatics tasks, using a broad range of evaluation metrics. Bio-Copilot achieves overall state-of-the-art performance across all tasks, while showcasing exceptional task completeness. Furthermore, on application to constructing a large-scale human lung cell atlas, Bio-Copilot not only reproduces the intricate data integration process detailed in a seminal study but also introduces a recursive, multilevel annotation strategy to capture the continuous nature of cellular states and uncovers the characteristics of rare cell types, highlighting its potential to unravel hidden complexities in biological systems. Beyond the technical achievements, this study also underscores the profound implications of integrating AI capabilities with expert knowledge in accelerating impactful biological discoveries and exploring uncharted territories.",
            "venue": "Briefings in Bioinformatics",
            "paperUrl": "https://www.semanticscholar.org/paper/c5648395711f73241870c31516b4c4898f7a18b7",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1093/bib/bbaf312",
            "reason_for_inclusion": "High quality: Published in Briefings in Bioinformatics, a reputable Q1 journal."
        }
    ],
    "reviews": [
        {
            "year": "2025.07",
            "title": "Biomedical education in the era of large language models: a paradigm shift",
            "team": "Shen-Han Lee",
            "team website": "",
            "affiliation": "",
            "domain": "Commentary on biomedical education with LLMs",
            "abstract": "The year is 2050. The golden age of biomedical progress has ended. Science has lost its soul. Scientists do not ask \u201cWhy?\u201d anymore. What changed? In the early 2020s, the rise of artificial intelligence (AI) and deep learning models known as large language models (LLMs) promised to revolutionize science. Instead, the same tools created a generation of scientists who lost their ability to think critically and innovate beyond the output of their LLMs. Jonathan, a PhD student, sits in his office staring at the computer screen. He keys in data from his latest cancer immunotherapy experiments for the LLM to analyze and watches as the model generates its conclusions. He does not question the results. Several months later, at a conference question and answer session, a senior scientist challenges Jonathan: \u201cYour model predicts a novel biomarker, but how do you explain its biological relevance?\u201d Jonathan stares blankly. Flustered, he quickly types the question to the LLM on his laptop. A few elder scientists in the audience whisper to each other, \u201cRemember when we used to think for ourselves?\u201d The year is 2024. This was the year when AI was awarded two Nobel Prizes \u2013 the Physics prize for work on machine learning with artificial neural networks, the technology that powers LLMs (1); and half of the Chemistry prize, for the [\u2026]",
            "venue": "The Journal of Clinical Investigation",
            "paperUrl": "https://www.semanticscholar.org/paper/f4c86d7eaa9d0e9a69608714389792c376de46a5",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1172/JCI196863",
            "reason_for_inclusion": "High quality: Published in The Journal of Clinical Investigation, a top-tier journal."
        }
    ],
    "benchmarks": [
        {
            "year": "2025.07",
            "title": "Benchmarking Large Language Models for Predictive Modeling in Biomedical Research With a Focus on Reproductive Health",
            "team": "M. Sirota",
            "team website": "",
            "affiliation": "Bakar Computational Health Sciences Institute, University of California, San Francisco",
            "domain": "LLM code generation for predictive modeling in omics",
            "abstract": "Generative AI, particularly large language models (LLMs), is increasingly being used in computational biology to support code generation for data analysis. In this study, we evaluated the ability of LLMs to generate functional R and Python code for predictive modeling tasks, leveraging standardized molecular datasets from several recent DREAM (Dialogue for Reverse Engineering Assessments and Methods) Challenges focused on reproductive health. We assessed LLM performance across four predictive tasks derived from three DREAM challenges: gestational age regression from gene expression, gestational age regression from DNA methylation profiles, and classification of preterm birth and early preterm birth from microbiome data. LLMs were prompted with task descriptions, data locations, and target outcomes. LLM-generated code was then run to fit and apply prediction models and generate graphics, and they were ranked based on their success in completing the tasks and achieving strong test set performance. Among the eight LLMs tested, o3-mini-high, 4o, DeepseekR1 and Gemini 2.0 completed at least one task without error. Overall, R code generation was more successful (14/16 tasks) than Python (7/16), attributed to the utility of Bioconductor packages for querying Gene Expression Omnibus data. OpenAI\u2019s o3-mini-high outperformed others, completing 7/8 tasks. Test set performance of the top LLM matched or exceeded top-performing teams from the original DREAM challenges. These findings underscore the potential of LLMs to enhance exploratory analysis and democratize access to predictive modeling in omics by automating key components of analysis pipelines, and highlight the potential to increase research output when conducting analyses of standardized datasets from public repositories.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/c74bd3e494fbaa2e2d9cb99d3887de251c815f8f",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.07.07.663529",
            "reason_for_inclusion": "High quality: Preprint from University of California, San Francisco, a world-renowned research institution."
        }
    ],
    "foundation-models": [
        {
            "year": "2025.07",
            "title": "Efficient GPT-4V level multimodal large language model for deployment on edge devices",
            "team": "Maosong Sun",
            "team website": "",
            "affiliation": "",
            "domain": "Edge-deployable multimodal LLMs",
            "abstract": "Multimodal large language models have revolutionized AI research and industry, paving the way toward the next milestone. However, their large sizes and high computational costs restrict deployment to cloud servers, limiting use in mobile, offline, energy-sensitive, or privacy-critical scenarios. We present MiniCPM-V, efficient models for edge devices that integrate advancements in architecture, training, and data. The 8B model outperforms GPT-4V, Gemini Pro, and Claude 3 across 11 public benchmarks, processes high-resolution images at any aspect ratio, achieves robust optical character recognition, exhibits low hallucination rates, and supports over 30 languages while running efficiently on mobile phones. This progress reflects a broader trend: The sizes for high-performing models are rapidly decreasing alongside growing edge computation capacity, enabling advanced multimodal models to operate locally on consumer hardware. Such developments unlock applications across diverse real-world scenarios, from enhanced mobile AI to privacy-preserving solutions, marking a critical step toward democratizing powerful multimodal intelligence. Multimodal Large Language Models are energy intensive and computationally demanding. Here, the authors developed a series of lightweight Multimodal Large Language Models deployable on edge devices.",
            "venue": "Nature Communications",
            "paperUrl": "https://www.semanticscholar.org/paper/a0c6365a23a07e26bf90db410574cad3ff68edba",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41467-025-61040-5",
            "reason_for_inclusion": "High quality: Published in Nature Communications, a top-tier journal."
        },
        {
            "year": "2025.07",
            "title": "Abstract B011: Pan-cancer immunotherapy response prediction using the CURE AI large clinicogenomic foundation model",
            "team": "Neil T. Pfister",
            "team website": "",
            "affiliation": "",
            "domain": "Clinicogenomic foundation model in immunotherapy",
            "abstract": "\n \n \n We developed a machine learning platform that learns and measures the individualized benefit of a therapeutic intervention over standard of care, which we named CURE AI (Clinical trials Uncovering Real Efficacy Artificial Intelligence). CURE AI is a large clinicogenomic foundation model (LCGM) trained on clinical and multi-omics data from hundreds of thousands of oncology patients using a proprietary deep learning architecture and training schema. CURE AI calculates a counterfactual outcome for every patient, resulting in a continuous benefit prediction ranking of patients based on the most important and predictive clinical and genomic factors, which can be utilized to inform biomarker and target discovery. We have previously demonstrated that CURE AI, trained on lung cancer clinical trials (CURE Lung Cancer), could predict immunotherapy response on additional held-out lung cancer clinical trials. In this study, we evaluated how well CURE AI could perform cross-cancer immunotherapy response predictions. We applied CURE Lung Cancer to a clear cell renal cancer clinical trial (ccRCC) and predicted immunotherapy clinical response in ccRCC, which is the first cross-cancer utilization of an LCGM. We further show that CURE AI, finetuned on ccRCC immunotherapy data (CURE Renal Cancer) predicts immunotherapy response in lung cancer. In a pan-cancer TCGA analysis, CURE AI, trained on renal or lung data, successfully stratified pan-cancer patients by immunotherapy response (poor: low grade glioma, prostate, pancreas and high: melanoma, hepatocellular, leukemia and lymphoma) enabling informed indication expansion decisions. CURE AI-refined eligibility criteria allows for >50% trial size reduction while accelerating the time to trial significance by 6-18 months with calculated potential cost savings in the order of > $100M for an average phase 3 clinical trial. CURE AI has significant potential to lead to advancements in refining clinical trial eligibility and informing indication expansion decisions.\n \n \n \n Vitalay Fomin, Amit Weiss, Neil T. Pfister. Pan-cancer immunotherapy response prediction using the CURE AI large clinicogenomic foundation model [abstract]. In: Proceedings of the AACR Special Conference in Cancer Research: Artificial Intelligence and Machine Learning; 2025 Jul 10-12; Montreal, QC, Canada. Philadelphia (PA): AACR; Clin Cancer Res 2025;31(13_Suppl):Abstract nr B011.\n",
            "venue": "Clinical Cancer Research",
            "paperUrl": "https://www.semanticscholar.org/paper/5aab6696a4bf683144a6957ad7c88d2e3b7f2b44",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1158/1557-3265.aimachine-b011",
            "reason_for_inclusion": "High quality: Published in Clinical Cancer Research, a top-tier journal."
        },
        {
            "year": "2025.07",
            "title": "Vision-language model for report generation and outcome prediction in CT pulmonary angiogram",
            "team": "Harrison X. Bai",
            "team website": "",
            "affiliation": "",
            "domain": "Vision-language model for CT pulmonary angiogram",
            "abstract": "Accurate and comprehensive interpretation of pulmonary embolism (PE) from Computed Tomography Pulmonary Angiography (CTPA) scans remains a clinical challenge due to the limited specificity and structure of existing AI tools. We propose an agent-based framework that integrates Vision-Language Models (VLMs) for detecting 32 PE-related abnormalities and Large Language Models (LLMs) for structured report generation. Trained on over 69,000 CTPA studies from 24,890 patients across Brown University Health (BUH), Johns Hopkins University (JHU), and the INSPECT dataset from Stanford, the model demonstrates strong performance in abnormality classification and report generation. For abnormality classification, it achieved AUROC scores of 0.788 (BUH), 0.754 (INSPECT), and 0.710 (JHU), with corresponding BERT-F1 scores of 0.891, 0.829, and 0.842. The abnormality-guided reporting strategy consistently outperformed the organ-based and holistic captioning baselines. For survival prediction, a multimodal fusion model that incorporates imaging, clinical variables, diagnostic outputs, and generated reports achieved concordance indices of 0.863 (BUH) and 0.731 (JHU), outperforming traditional PESI scores. This framework provides a clinically meaningful and interpretable solution for end-to-end PE diagnosis, structured reporting, and outcome prediction.",
            "venue": "NPJ Digital Medicine",
            "paperUrl": "https://www.semanticscholar.org/paper/8452c2f5cee9adc02b715fada8284367fdab100b",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41746-025-01807-8",
            "reason_for_inclusion": "High quality: Published in NPJ Digital Medicine, a reputable Q1 journal."
        },
        {
            "year": "2025.07",
            "title": "PodGPT: an audio-augmented large language model for research and education",
            "team": "V. Kolachalama",
            "team website": "",
            "affiliation": "",
            "domain": "Audio-augmented LLM for educational podcasts",
            "abstract": "The proliferation of scientific podcasts has generated an extensive repository of educational content, rich in specialized terminology, diverse topics, and expert dialogues. Here, we introduce a computational framework designed to enhance large language models by leveraging this informational content from publicly accessible audio podcasts across science, technology, engineering, mathematics, and medicine (STEMM). This dataset, comprising over 3700 hours of audio content, was transcribed to generate over 42 million text tokens. Our model, PodGPT, integrates this wealth of complex dialogue found in audio podcasts to improve understanding of natural language nuances, cultural contexts, as well as scientific and medical knowledge. PodGPT also employs retrieval augmented generation (RAG) on a vector database, providing real-time access to emerging scientific literature. Evaluated on multiple benchmarks, PodGPT demonstrated an average improvement of 1.82 percentage points over standard open-source benchmarks and 2.43 percentage points when augmented with evidence from the RAG pipeline. Moreover, it showcased an average improvement of 1.18 percentage points in its zero-shot multilingual transfer ability, effectively generalizing to different linguistic contexts. By harnessing the untapped potential of podcast content, PodGPT advances natural language processing and conversational AI, offering enhanced capabilities for STEMM research and education.",
            "venue": "Npj Biomedical Innovations",
            "paperUrl": "https://www.semanticscholar.org/paper/655eb5b4ba685b7e3104e6560a63aa88a5768437",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s44385-025-00022-0",
            "reason_for_inclusion": "High quality: Published in Npj Biomedical Innovations, a reputable Q1 journal."
        },
        {
            "year": "2025.07",
            "title": "A foundation model to predict and capture human cognition",
            "team": "Eric Schulz",
            "team website": "",
            "affiliation": "",
            "domain": "Foundation model for human cognition simulation",
            "abstract": "Establishing a unified theory of cognition has been an important goal in psychology1,2. A first step towards such a theory is to create a computational model that can predict human behaviour in a wide range of settings. Here we introduce Centaur, a computational model that can predict and simulate human behaviour in any experiment expressible in natural language. We derived Centaur by fine-tuning a state-of-the-art language model on a large-scale dataset called Psych-101. Psych-101 has an unprecedented scale, covering trial-by-trial data from more than 60,000 participants performing in excess of 10,000,000 choices in 160 experiments. Centaur not only captures the behaviour of held-out participants better than existing cognitive models, but it also generalizes to previously unseen cover stories, structural task modifications and entirely new domains. Furthermore, the model\u2019s internal representations become more aligned with human neural activity after fine-tuning. Taken together, our results demonstrate that it is possible to discover computational models that capture human behaviour across a wide range of domains. We believe that such models provide tremendous potential for guiding the development of cognitive theories, and we present a case study to demonstrate this. A computational model called Centaur, developed by fine-tuning a language model on a huge dataset called Psych-101, can predict and simulate human nature in experiments expressible in natural language, even in previously unseen situations.",
            "venue": "Nature",
            "paperUrl": "https://www.semanticscholar.org/paper/a4e64dee0d0f284edc160a9a8bc2b4385577249a",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41586-025-09215-4",
            "reason_for_inclusion": "High quality: Published in Nature, a top-tier journal."
        },
        {
            "year": "2025.07",
            "title": "A Pan-Organ Vision-Language Model for Generalizable 3D CT Representations",
            "team": "Walter R. Witschey",
            "team website": "",
            "affiliation": "University of Pennsylvania",
            "domain": "Pan-organ vision-language model for CT",
            "abstract": "Generalizable foundation models for computed tomographic (CT) medical imaging data are emerging AI tools anticipated to vastly improve clinical workflow efficiency. However, existing models are typically trained within narrow imaging contexts, including limited anatomical coverage, contrast settings, and clinical indications. These constraints reduce their ability to generalize across the broad spectrum of real-world presentations encountered in volumetric CT imaging data. We introduce Percival, a vision-language foundation model trained on over 400,000 CT volumes and paired radiology reports from more than 50,000 participants enrolled in the Penn Medicine BioBank. Percival employs a dual-encoder architecture with a transformer-based image encoder and a BERT-style language encoder, aligned via symmetric contrastive learning. Percival was validated on over 20,000 participants imaging data encompassing over 100,000 CT volumes. In image-text recall tasks, Percival outperforms models trained on limited anatomical windows. To assess Percival's clinical knowledge, we evaluated the biologic, phenotypic and prognostic relevance using laboratory-wide, phenome-wide association studies and survival analyses, uncovering a rich latent structure aligned with physiological measurements and disease phenotypes.",
            "venue": "medRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/b8b956b001622ede4668e052e45f274e48d45ead",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.07.03.25330654",
            "reason_for_inclusion": "High quality: Preprint from University of Pennsylvania, a world-renowned research institution."
        },
        {
            "year": "2025.07",
            "title": "Top-DTI: integrating topological deep learning and large language models for drug\u2013target interaction prediction",
            "team": "S. Bozdag",
            "team website": "",
            "affiliation": "",
            "domain": "Topological deep learning and LLM for DTI prediction",
            "abstract": "Abstract Motivation The accurate prediction of drug\u2013target interactions (DTI) is a crucial step in drug discovery, providing a foundation for identifying novel therapeutics. Traditional drug development is both costly and time-consuming, often spanning over a decade. Computational approaches help narrow the pool of compound candidates, offering significant starting points for experimental validation. In this study, we propose a Top-DTI framework for predicting DTI by integrating topological data analysis (TDA) with large language models (LLMs). Top-DTI leverages persistent homology to extract topological features from protein contact maps and drug molecular images. Simultaneously, protein and drug LLMs generate semantically rich embeddings that capture sequential and contextual information from protein sequences and drug SMILES strings. By combining these complementary features, Top-DTI enhances predictive performance and robustness. Results Experimental results on the public BioSNAP and Human DTI benchmark datasets demonstrate that the proposed Top-DTI model outperforms state-of-the-art approaches across multiple evaluation metrics, including AUROC, AUPRC, sensitivity, and specificity. Furthermore, the Top-DTI model achieves superior performance in the challenging cold-split scenario, where the test and validation sets contain drugs or targets absent from the training set. This setting simulates real-world scenarios and highlights the robustness of the model. Notably, incorporating topological features alongside LLM embeddings significantly improves predictive performance, underscoring the value of integrating structural and sequence-based representations. Availability and implementation The data and source code of Top-DTI are available at https://github.com/bozdaglab/Top_DTI under the Creative Commons Attribution NonCommercial 4.0 International Public License.",
            "venue": "Bioinformatics",
            "paperUrl": "https://www.semanticscholar.org/paper/ffa4bce26de7cfe69f7384c621e2387a8f0ade7d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1093/bioinformatics/btaf183",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.07",
            "title": "An open-source family of large encoder-decoder foundation models for chemistry",
            "team": "Kristin Schmidt",
            "team website": "",
            "affiliation": "",
            "domain": "Encoder-decoder foundation models for chemistry",
            "abstract": "The use of foundation models has extended from natural language processing to molecular modeling. In this context, large-scale pre-training strategies have been applied to chemical language models to enable representation learning across diverse tasks. Here we introduce a family of encoder-decoder chemical foundation models pre-trained on a curated dataset of 91 million molecular sequences from PubChem. These models support a range of applications, including property estimation and reaction outcome prediction. We evaluate two model variants across several benchmark datasets and show that they match or exceed existing approaches. We also assess the structure of the learned representations and find that the embedding space supports few-shot learning and separates molecules based on chemically relevant features. This structure appears to result from the decoder-based reconstruction objective used during pre-training. These findings suggest that the proposed models can serve as general-purpose tools for molecular analysis and reasoning with minimal supervision. Pre-training data quality has been shown to be paramount to the outcome of foundation models. With that in mind, the authors present a family of molecular encoder-decoder foundation models, SMI-TED289M, which are pre-trained on a curated dataset of 91 million SMILES samples sourced from PubChem and demonstrate their performance in providing state-of-the-art results for different tasks, including reaction-yield prediction.",
            "venue": "Communications Chemistry",
            "paperUrl": "https://www.semanticscholar.org/paper/2c66c5a1591cfdb56db555074453a0ecb3efd953",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s42004-025-01585-0",
            "reason_for_inclusion": "High quality: Published in Communications Chemistry, a reputable Q1 journal."
        },
        {
            "year": "2025.07",
            "title": "BertADP: a fine-tuned protein language model for anti-diabetic peptide prediction",
            "team": "Hao Lin",
            "team website": "",
            "affiliation": "",
            "domain": "Protein language model for anti-diabetic peptide prediction",
            "abstract": "Diabetes is a global metabolic disease that urgently calls for the development of new and effective therapeutic agents. Anti-diabetic peptides (ADPs) have emerged as a research hotspot due to their therapeutic potential and natural safety, representing a promising class of functional peptides for diabetic management. However, conventional computational approaches for ADPs prediction mainly rely on manually extracted sequence features. These methods often lack generalizability and perform poorly on short peptides, thereby hindering effective ADPs discovery. In this study, we introduce a fine-tuning strategy of large-scale pre-trained protein language models (PLMs) for ADPs prediction, enabling automated extraction of discriminative semantic representations. We established the most comprehensive ADPs dataset to date, comprising 899 rigorously curated non-redundant ADPs and 67 newly collected potential candidates. Based on three model construction strategies, we developed 11 candidate models. Among them, BertADP (a fine-tuned ProtBert model) demonstrated superior performance in the independent test set, outperforming existing ADPs prediction tools with an overall accuracy of 0.955, sensitivity of 1.000, and specificity of 0.910. Notably, BertADP exhibited remarkable sequence length adaptability, maintaining stable performance across both standard and short peptide sequences. BertADP represents the first PLMs-based intelligent prediction tool for ADPs, whose exceptional identification capability will significantly accelerate anti-diabetic drug development and facilitate personalized therapeutic strategies, thereby enhancing precision diabetes management. Furthermore, the proposed approach provides a generalizable framework that can be extended to other bioactive peptide discovery studies, offering an innovative solution for bioactive peptide mining.",
            "venue": "BMC Biology",
            "paperUrl": "https://www.semanticscholar.org/paper/e8b5544c2d6f942658709030a87b506bc7a5eb29",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1186/s12915-025-02312-w",
            "reason_for_inclusion": "High quality: Published in BMC Biology, a reputable Q1 journal."
        }
    ],
    "databases": [
        {
            "year": "2025.07",
            "title": "GastroNet-5M: A Multicenter Dataset for Developing Foundation Models in Gastrointestinal Endoscopy.",
            "team": "J. Bergman",
            "team website": "",
            "affiliation": "",
            "domain": "Gastrointestinal endoscopy image dataset",
            "abstract": "BACKGROUND & AIMS\nTraining deep learning systems in endoscopy generally requires vast datasets of annotated images, which are often scarce and costly to obtain. Foundation models are pretrained on large, diverse datasets and can be applied across a wide range of tasks with minimal additional fine-tuning. For endoscopy, foundation models require datasets of general endoscopic images. Yet datasets for developing such models remain limited. In this study, we present GastroNet-5M, a dataset comprising 4,820,653 endoscopic images of approximately 500,000 procedures.\n\n\nMETHODS\nGastroNet-5M consists of anonymized general endoscopic images captured in eight Dutch hospitals between 2012 and 2020. Using self-supervised learning, GastroNet-5M was used to develop a foundation model for subsequent downstream endoscopic AI applications. We compared our GastroNet-5M foundation model with publicly available endoscopic foundation models and state-of-the-art non-foundation models across 17 endoscopic AI applications throughout the GI tract. Outcome measures were classification and segmentation accuracy, data efficiency, and robustness to data heterogeneity.\n\n\nRESULTS\nGastroNet-5M-pretrained models outperformed all other models in terms of accuracy for nearly all classification and segmentation tasks. Furthermore, GastroNet-5M-pretrained models required significantly less application-specific training data for satisfactory model performance and displayed more robust performance when models were exposed to data heterogeneity such as imagery from different endoscope manufacturers.\n\n\nCONCLUSION\nThis study presents GastroNet-5M, a dataset of roughly 5 million endoscopic images. Pretraining endoscopic deep learning systems with GastroNet-5M improves diagnostic accuracy, reduces the need for scarce application-specific endoscopic imagery and annotations, and increases their robustness to the inevitable data heterogeneity in clinical practice. This may significantly accelerate development and implementation of endoscopic AI systems. GastroNet-5M is publicly available for scientific use.",
            "venue": "Gastroenterology",
            "paperUrl": "https://www.semanticscholar.org/paper/87e8a2c1d78996458471669cb8e707b8e3de1be7",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1053/j.gastro.2025.07.030",
            "reason_for_inclusion": "High quality: Published in Gastroenterology, a premier medical journal."
        }
    ]
}