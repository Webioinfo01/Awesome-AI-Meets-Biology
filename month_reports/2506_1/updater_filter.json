{
    "ai-agents": [
        {
            "year": "2025.06",
            "title": "Biomni: A General-Purpose Biomedical AI Agent",
            "team": "J. Leskovec",
            "team website": "",
            "affiliation": "Stanford University",
            "domain": "Biomedical AI agent for autonomous research workflows",
            "abstract": "Biomedical research underpins progress in our understanding of human health and disease, drug discovery, and clinical care. However, with the growth of complex lab experiments, large datasets, many analytical tools, and expansive literature, biomedical research is increasingly constrained by repetitive and fragmented workflows that slow discovery and limit innovation, underscoring the need for a fundamentally new way to scale scientific expertise. Here, we introduce Biomni, a general-purpose biomedical AI agent designed to autonomously execute a wide spectrum of research tasks across diverse biomedical subfields. To systematically map the biomedical action space, Biomni first employs an action discovery agent to create the first unified agentic environment \u2013 mining essential tools, databases, and protocols from tens of thousands of publications across 25 biomedical domains. Built on this foundation, Biomni features a generalist agentic architecture that integrates large language model (LLM) reasoning with retrieval-augmented planning and code-based execution, enabling it to dynamically compose and carry out complex biomedical workflows \u2013 entirely without relying on predefined templates or rigid task flows. Systematic benchmarking demonstrates that Biomni achieves strong generalization across heterogeneous biomedical tasks \u2013 including causal gene prioritization, drug repurposing, rare disease diagnosis, micro-biome analysis, and molecular cloning \u2013 without any task-specific prompt tuning. Real-world case studies further showcase Biomni\u2019s ability to interpret complex, multi-modal biomedical datasets and autonomously generate experimentally testable protocols. Biomni envisions a future where virtual AI biologists operate alongside and augment human scientists to dramatically enhance research productivity, clinical insight, and healthcare. Biomni is ready to use at https://biomni.stanford.edu, and we invite scientists to explore its capabilities, stress-test its limits, and co-create the next era of biomedical discoveries.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/7bbe76e09d2aab075f006675355ebaa4020463a2",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.05.30.656746",
            "reason_for_inclusion": "High quality: Pre-print from Stanford University, a world-renowned research institution."
        },
        {
            "year": "2025.06",
            "title": "AI Agent Behavioral Science",
            "team": "Yong Li",
            "team website": "",
            "affiliation": "",
            "domain": "Behavioral science of AI agents",
            "abstract": "Recent advances in large language models (LLMs) have enabled the development of AI agents that exhibit increasingly human-like behaviors, including planning, adaptation, and social dynamics across diverse, interactive, and open-ended scenarios. These behaviors are not solely the product of the internal architectures of the underlying models, but emerge from their integration into agentic systems operating within specific contexts, where environmental factors, social cues, and interaction feedbacks shape behavior over time. This evolution necessitates a new scientific perspective: AI Agent Behavioral Science. Rather than focusing only on internal mechanisms, this perspective emphasizes the systematic observation of behavior, design of interventions to test hypotheses, and theory-guided interpretation of how AI agents act, adapt, and interact over time. We systematize a growing body of research across individual agent, multi-agent, and human-agent interaction settings, and further demonstrate how this perspective informs responsible AI by treating fairness, safety, interpretability, accountability, and privacy as behavioral properties. By unifying recent findings and laying out future directions, we position AI Agent Behavioral Science as a necessary complement to traditional model-centric approaches, providing essential tools for understanding, evaluating, and governing the real-world behavior of increasingly autonomous AI systems.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/e4bcb3f40c952a639c2bd665f8754defd67aad5e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.06366",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "Knowledge-guided Contextual Gene Set Analysis Using Large Language Models",
            "team": "Zhiyong Lu",
            "team website": "",
            "affiliation": "",
            "domain": "Context-aware gene set analysis using large language models",
            "abstract": "Gene set analysis (GSA) is a foundational approach for interpreting genomic data of diseases by linking genes to biological processes. However, conventional GSA methods overlook clinical context of the analyses, often generating long lists of enriched pathways with redundant, nonspecific, or irrelevant results. Interpreting these requires extensive, ad-hoc manual effort, reducing both reliability and reproducibility. To address this limitation, we introduce cGSA, a novel AI-driven framework that enhances GSA by incorporating context-aware pathway prioritization. cGSA integrates gene cluster detection, enrichment analysis, and large language models to identify pathways that are not only statistically significant but also biologically meaningful. Benchmarking on 102 manually curated gene sets across 19 diseases and ten disease-related biological mechanisms shows that cGSA outperforms baseline methods by over 30%, with expert validation confirming its increased precision and interpretability. Two independent case studies in melanoma and breast cancer further demonstrate its potential to uncover context-specific insights and support targeted hypothesis generation.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/7cb3a28963a5ceb201e4092a4e52644c3436a7c7",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.04303",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "DeepSeq: High-Throughput Single-Cell RNA Sequencing Data Labeling via Web Search-Augmented Agentic Generative AI Foundation Models",
            "team": "John R. Williams",
            "team website": "",
            "affiliation": "Department of Civil and Environmental Engineering (CEE), Massachusetts Institute of Technology (MIT), 77 Massachusetts Avenue, Cambridge, MA 02139, United State",
            "domain": "Agentic generative AI for single-cell RNA sequencing data labeling",
            "abstract": "Generative AI foundation models offer transformative potential for processing structured biological data, particularly in single-cell RNA sequencing, where datasets are rapidly scaling toward billions of cells. We propose the use of agentic generative AI foundation models with real-time web search to automate the labeling of experimental data, achieving up to 82.5% accuracy. This addresses a key bottleneck in supervised learning for structured omics data by increasing annotation throughput without manual curation and human error. Our approach enables the development of virtual cell foundation models capable of downstream tasks such as cell-typing and perturbation prediction. As data volume grows, these models may surpass human performance in labeling, paving the way for reliable inference in large-scale perturbation screens. This application demonstrates domain-specific innovation in health monitoring and diagnostics, aligned with efforts like the Human Cell Atlas and Human Tumor Atlas Network.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/4d6ef2e715f81de2ce053c0c48f799c93e4d9309",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.06.17.660107",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.06",
            "title": "Agentomics-ML: Autonomous Machine Learning Experimentation Agent for Genomic and Transcriptomic Data",
            "team": "Panagiotis Alexiou",
            "team website": "",
            "affiliation": "",
            "domain": "Autonomous ML experimentation agent for genomic and transcriptomic data",
            "abstract": "The adoption of machine learning (ML) and deep learning methods has revolutionized molecular medicine by driving breakthroughs in genomics, transcriptomics, drug discovery, and biological systems modeling. The increasing quantity, multimodality, and heterogeneity of biological datasets demand automated methods that can produce generalizable predictive models. Recent developments in large language model-based agents have shown promise for automating end-to-end ML experimentation on structured benchmarks. However, when applied to heterogeneous computational biology datasets, these methods struggle with generalization and success rates. Here, we introduce Agentomics-ML, a fully autonomous agent-based system designed to produce a classification model and the necessary files for reproducible training and inference. Our method follows predefined steps of an ML experimentation process, repeatedly interacting with the file system through Bash to complete individual steps. Once an ML model is produced, training and validation metrics provide scalar feedback to a reflection step to identify issues such as overfitting. This step then creates verbal feedback for future iterations, suggesting adjustments to steps such as data representation, model architecture, and hyperparameter choices. We have evaluated Agentomics-ML on several established genomic and transcriptomic benchmark datasets and show that it outperforms existing state-of-the-art agent-based methods in both generalization and success rates. While state-of-the-art models built by domain experts still lead in absolute performance on the majority of the computational biology datasets used in this work, Agentomics-ML narrows the gap for fully autonomous systems and achieves state-of-the-art performance on one of the used benchmark datasets. The code is available at https://github.com/BioGeMT/Agentomics-ML.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/f8666b034f4ddd25259d76c5c34e9fbb91dfc917",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.05542",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "A User-Friendly Machine Learning Pipeline for Automated Leaf Segmentation in Atriplex lentiformis",
            "team": "Aikseng Ooi",
            "team website": "",
            "affiliation": "",
            "domain": "Machine learning pipeline for automated leaf segmentation in plants",
            "abstract": "Automated leaf segmentation pipelines must balance accuracy, scalability, and usability to be readily adopted in plant research. We present an end-to-end deep learning pipeline designed for practical use in plant phenotyping, which we developed and evaluated during a real-world plant growth experiment using Atriplex lentiformis. The pipeline integrates a fine-tuned Mask Region-based Convolutional Neural Network (Mask R-CNN) segmentation model trained on 176 plant images and achieves high performance despite the small training data set (Dice coefficient\u2009=\u20090.781). We quantitatively compare the fine-tuned Mask R-CNN model to Meta AI\u2019s Segment Anything Model (SAM) and evaluate natural language prompts using Grounded SAM and the Leaf-Only SAM post-processing pipeline for refining segmentation outputs. Our findings highlight that transfer learning on a specialized data set can still outperform a large foundation model in domain-specific tasks. In addition, we integrate QR codes for automated sample identification and benchmark multiple QR code decoding libraries, evaluating their robustness under real-world imaging conditions like distortion and lighting variation. To ensure accessibility, we deploy the pipeline as a user-friendly Streamlit web application, allowing researchers to analyze images without deep learning expertise. By focusing on practical deployment in addition to model performance, this study provides an open-source, scalable framework for plant science applications and addresses real-world challenges in automation and usability by the end-researcher.",
            "venue": "Bioinformatics and Biology Insights",
            "paperUrl": "https://www.semanticscholar.org/paper/50cc21fce97d07dceb5021abb655ce9015a727f6",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1177/11779322251344033",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "Probably Approximately Correct Labels",
            "team": "Tijana Zrnic",
            "team website": "",
            "affiliation": "",
            "domain": "Method for dataset curation via probably approximately correct labels",
            "abstract": "Obtaining high-quality labeled datasets is often costly, requiring either human annotation or expensive experiments. In theory, powerful pre-trained AI models provide an opportunity to automatically label datasets and save costs. Unfortunately, these models come with no guarantees on their accuracy, making wholesale replacement of manual labeling impractical. In this work, we propose a method for leveraging pre-trained AI models to curate cost-effective and high-quality datasets. In particular, our approach results in probably approximately correct labels: with high probability, the overall labeling error is small. Our method is nonasymptotically valid under minimal assumptions on the dataset or the AI model being studied, and thus enables rigorous yet efficient dataset curation using modern AI models. We demonstrate the benefits of the methodology through text annotation with large language models, image labeling with pre-trained vision models, and protein folding analysis with AlphaFold.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/1cb28c5ca1eb9ebc3d29c0cf59fe4ef3fdd48fc6",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.10908",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "KODA: An Agentic Framework for KEGG Orthology-Driven Discovery of Antimicrobial Drug Targets in Gut Microbiome",
            "team": "Mohammad R. K. Mofrad",
            "team website": "",
            "affiliation": "University of California Berkeley",
            "domain": "Agentic framework for antimicrobial drug target discovery in microbiome",
            "abstract": "",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/860d4b613b31bc64e81644015c0164627c67f31e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.05.27.656480",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.06",
            "title": "Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning",
            "team": "Zhiyong Lu",
            "team website": "",
            "affiliation": "",
            "domain": "Training LLMs for batch-level single-cell RNA annotation via RL",
            "abstract": "Cell type annotation is a key task in analyzing the heterogeneity of single-cell RNA sequencing data. Although recent foundation models automate this process, they typically annotate cells independently, without considering batch-level cellular context or providing explanatory reasoning. In contrast, human experts often annotate distinct cell types for different cell clusters based on their domain knowledge. To mimic this workflow, we introduce the CellPuzzles task, where the objective is to assign unique cell types to a batch of cells. This benchmark spans diverse tissues, diseases, and donor conditions, and requires reasoning across the batch-level cellular context to ensure label uniqueness. We find that off-the-shelf large language models (LLMs) struggle on CellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0% batch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trained via supervised fine-tuning on distilled reasoning traces, followed by reinforcement learning with batch-level rewards. Cell-o1 achieves state-of-the-art performance, outperforming o1 by over 73% and generalizing well across contexts. Further analysis of training dynamics and reasoning behaviors provides insights into batch-level annotation performance and emergent expert-like reasoning. Code and data are available at https://github.com/ncbi-nlp/cell-o1.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/5f145bd0636027e192d7c8d0102806166fc30d64",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.02911",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        }
    ],
    "foundation-models": [
        {
            "year": "2025.06",
            "title": "PixCell: A generative foundation model for digital histopathology images",
            "team": "Dimitris Samaras",
            "team website": "",
            "affiliation": "",
            "domain": "Generative foundation model for digital histopathology images",
            "abstract": "The digitization of histology slides has revolutionized pathology, providing massive datasets for cancer diagnosis and research. Contrastive self-supervised and vision-language models have been shown to effectively mine large pathology datasets to learn discriminative representations. On the other hand, generative models, capable of synthesizing realistic and diverse images, present a compelling solution to address unique problems in pathology that involve synthesizing images; overcoming annotated data scarcity, enabling privacy-preserving data sharing, and performing inherently generative tasks, such as virtual staining. We introduce PixCell, the first diffusion-based generative foundation model for histopathology. We train PixCell on PanCan-30M, a vast, diverse dataset derived from 69,184 H&E-stained whole slide images covering various cancer types. We employ a progressive training strategy and a self-supervision-based conditioning that allows us to scale up training without any annotated data. PixCell generates diverse and high-quality images across multiple cancer types, which we find can be used in place of real data to train a self-supervised discriminative model. Synthetic images shared between institutions are subject to fewer regulatory barriers than would be the case with real clinical images. Furthermore, we showcase the ability to precisely control image generation using a small set of annotated images, which can be used for both data augmentation and educational purposes. Testing on a cell segmentation task, a mask-guided PixCell enables targeted data augmentation, improving downstream performance. Finally, we demonstrate PixCell\u2019s ability to use H&E structural staining to infer results from molecular marker studies; we use this capability to infer IHC staining from H&E images. Our trained models are publicly released to accelerate research in computational pathology.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/a4ac7f99debb0c757ba3f0f8291b24a4255d1d03",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.05127",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ],
    "reviews": [
        {
            "year": "2025.06",
            "title": "Contemporary AI foundation models increase biological weapons risk",
            "team": "T. G. McKelvey",
            "team website": "",
            "affiliation": "",
            "domain": "Biosecurity risks posed by AI foundation models",
            "abstract": "The rapid advancement of artificial intelligence has raised concerns about its potential to facilitate biological weapons development. We argue existing safety assessments of contemporary foundation AI models underestimate this risk, largely due to flawed assumptions and inadequate evaluation methods. First, assessments mistakenly assume biological weapons development requires tacit knowledge, or skills gained through hands-on experience that cannot be easily verbalized. Second, they rely on imperfect benchmarks that overlook how AI can uplift both nonexperts and already-skilled individuals. To challenge the tacit knowledge assumption, we examine cases where individuals without formal expertise, including a 2011 Norwegian ultranationalist who synthesized explosives, successfully carried out complex technical tasks. We also review efforts to document pathogen construction processes, highlighting how such tasks can be conveyed in text. We identify\"elements of success\"for biological weapons development that large language models can describe in words, including steps such as acquiring materials and performing technical procedures. Applying this framework, we find that advanced AI models Llama 3.1 405B, ChatGPT-4o, and Claude 3.5 Sonnet can accurately guide users through the recovery of live poliovirus from commercially obtained synthetic DNA, challenging recent claims that current models pose minimal biosecurity risk. We advocate for improved benchmarks, while acknowledging the window for meaningful implementation may have already closed.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/e4854e4c12a3dc1964775c7368b3ee3adb02982e",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.13798",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "Foundation models in plant molecular biology: advances, challenges, and future directions",
            "team": "Jun Yan",
            "team website": "",
            "affiliation": "",
            "domain": "Foundation models in plant molecular biology",
            "abstract": "A foundation model (FM) is a neural network trained on large-scale data using unsupervised or self-supervised learning, capable of adapting to a wide range of downstream tasks. This review provides a comprehensive overview of FMs in plant molecular biology, emphasizing recent advances and future directions. It begins by tracing the evolution of biological FMs across the DNA, RNA, protein, and single-cell levels, from tools inspired by natural language processing (NLP) to transformative models for decoding complex biological sequences. The review then focuses on plant-specific FMs such as GPN, AgroNT, PDLLMs, PlantCaduceus, and PlantRNA-FM, which address challenges that are widespread among plant genomes, including polyploidy, high repetitive sequence content, and environment-responsive regulatory elements, alongside universal FMs like GENERator and Evo 2, which leverage extensive cross-species training data for sequence design and prediction of mutation effects. Key opportunities and challenges in plant molecular biology FM development are further outlined, such as data heterogeneity, biologically informed architectures, cross-species generalization, and computational efficiency. Future research should prioritize improvements in model generalization, multi-modal data integration, and computational optimization to overcome existing limitations and unlock the potential of FMs in plant science. This review serves as an essential resource for plant molecular biologists and offers a clear snapshot of the current state and future potential of FMs in the field.",
            "venue": "Frontiers in Plant Science",
            "paperUrl": "https://www.semanticscholar.org/paper/98b561595f5bf7d47456b83d5f52af31ebf0e9ae",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3389/fpls.2025.1611992",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "Artificial Intelligence-Assisted Breeding for Plant Disease Resistance",
            "team": "Yanyong Cao",
            "team website": "",
            "affiliation": "",
            "domain": "AI-assisted breeding for plant disease resistance",
            "abstract": "Harnessing state-of-the-art technologies to improve disease resistance is a critical objective in modern plant breeding. Artificial intelligence (AI), particularly deep learning and big model (large language model and large multi-modal model), has emerged as a transformative tool to enhance disease detection and omics prediction in plant science. This paper provides a comprehensive review of AI-driven advancements in plant disease detection, highlighting convolutional neural networks and their linked methods and technologies through bibliometric analysis from recent research. We further discuss the groundbreaking potential of large language models and multi-modal models in interpreting complex disease patterns via heterogeneous data. Additionally, we summarize how AI accelerates genomic and phenomic selection by enabling high-throughput analysis of resistance-associated traits, and explore AI\u2019s role in harmonizing multi-omics data to predict plant disease-resistant phenotypes. Finally, we propose some challenges and future directions in terms of data, model, and privacy facets. We also provide our perspectives on integrating federated learning with a large language model for plant disease detection and resistance prediction. This review provides a comprehensive guide for integrating AI into plant breeding programs, facilitating the translation of computational advances into disease-resistant crop breeding.",
            "venue": "International Journal of Molecular Sciences",
            "paperUrl": "https://www.semanticscholar.org/paper/74d45591664632d4150df72d6b5adb2b7b65e267",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3390/ijms26115324",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "Scale-Invariance Drives Convergence in AI and Brain Representations",
            "team": "Quanying Liu",
            "team website": "",
            "affiliation": "",
            "domain": "Scale-invariance in AI and brain representations",
            "abstract": "Despite variations in architecture and pretraining strategies, recent studies indicate that large-scale AI models often converge toward similar internal representations that also align with neural activity. We propose that scale-invariance, a fundamental structural principle in natural systems, is a key driver of this convergence. In this work, we propose a multi-scale analytical framework to quantify two core aspects of scale-invariance in AI representations: dimensional stability and structural similarity across scales. We further investigate whether these properties can predict alignment performance with functional Magnetic Resonance Imaging (fMRI) responses in the visual cortex. Our analysis reveals that embeddings with more consistent dimension and higher structural similarity across scales align better with fMRI data. Furthermore, we find that the manifold structure of fMRI data is more concentrated, with most features dissipating at smaller scales. Embeddings with similar scale patterns align more closely with fMRI data. We also show that larger pretraining datasets and the inclusion of language modalities enhance the scale-invariance properties of embeddings, further improving neural alignment. Our findings indicate that scale-invariance is a fundamental structural principle that bridges artificial and biological representations, providing a new framework for evaluating the structural quality of human-like AI systems.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/3a01165637266c9da59be95a4a0a78f37af2b6dc",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.12117",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.06",
            "title": "Why Traditional Statistical Methods Need to Evolve in the Age of Artificial Intelligence: A Biostatistical Perspective",
            "team": "Deepak Raj Joshi",
            "team website": "",
            "affiliation": "",
            "domain": "Integration of AI and traditional biostatistics",
            "abstract": "Traditional statistical methods, basically the frequentist approach, must evolve to remain relevant in the age of Artificial Intelligence (AI). While Conventional statistical methods work under theoretical assumptions, they struggle to handle the complexities of modern biomedical data, including high dimensionality, non-linearity, and violations of key assumptions\u00a0However, this is not a problem for the newer machine learning models like support vector machines. There are new techniques like regularization (ridge, lasso) to handle many of the assumptions in traditional statistical methods, which can be implemented and automated using software like R and Python. \u00a0Machine learning as a part of AI offers solutions by handling large-scale complex datasets, uncovering hidden patterns, and improving prediction power. They are based on the foundation models where statistics and mathematics meet. So, just talking about the limitations of the statistical methods is half true. The viewpoint tries to explain why to integrate AI with traditional biostatistics, creating hybrid models that combine statistical rigor with AI flexibility. Integration can enhance data analysis, causal inference, and decision-making, ultimately advancing personalized medicine and public health, ethically and transparently.",
            "venue": "Nepal Journal of Public Health",
            "paperUrl": "https://www.semanticscholar.org/paper/0ee50fdccfabf9204c91cf4238e08f3035794adf",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.70280/njph(2025)v2i1.31",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ],
    "benchmarks": [
        {
            "year": "2025.06",
            "title": "Protap: A Benchmark for Protein Modeling on Realistic Downstream Applications",
            "team": "Enyan Dai",
            "team website": "",
            "affiliation": "",
            "domain": "Benchmarking protein modeling architectures and pretraining strategies",
            "abstract": "Recently, extensive deep learning architectures and pretraining strategies have been explored to support downstream protein applications. Additionally, domain-specific models incorporating biological knowledge have been developed to enhance performance in specialized tasks. In this work, we introduce $\\textbf{Protap}$, a comprehensive benchmark that systematically compares backbone architectures, pretraining strategies, and domain-specific models across diverse and realistic downstream protein applications. Specifically, Protap covers five applications: three general tasks and two novel specialized tasks, i.e., enzyme-catalyzed protein cleavage site prediction and targeted protein degradation, which are industrially relevant yet missing from existing benchmarks. For each application, Protap compares various domain-specific models and general architectures under multiple pretraining settings. Our empirical studies imply that: (i) Though large-scale pretraining encoders achieve great results, they often underperform supervised encoders trained on small downstream training sets. (ii) Incorporating structural information during downstream fine-tuning can match or even outperform protein language models pretrained on large-scale sequence corpora. (iii) Domain-specific biological priors can enhance performance on specialized downstream tasks. Code and datasets are publicly available at https://github.com/Trust-App-AI-Lab/protap.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/5f65dfc5038c92492af55364ada876303e247be8",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2506.02052",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ]
}