# Research Paper Report for 2025-08-01 to 2025-08-15

## Overall Summary

Between August 1 and August 15, 2025, researchers showcased the rapid maturation of large language models (LLMs) and multimodal AI across diverse scientific domains. In the **databases** category, three projects [1–3] leverage LLMs to structure and curate domain-specific knowledge. Zhu et al. [1] introduce MDKG, a psychiatric knowledge graph with over 10 million relations and nearly 1 million novel associations, embedding conditionality and demographic metadata to boost predictive modeling on UK Biobank data. Yang et al. [2] tackle the “dark matter” of enzymology by processing 137,892 publications to extract 218,095 kinetic entries, integrating UniProt and PubChem mappings to enhance state-of-the-art kcat predictors. Goljanek-Whysall et al. [3] deliver miRKatDB and a LangGraph-powered multi-agent query interface (miRKatAI) for microRNA target discovery, unifying heterogeneous experimental data under an LLM-driven natural-language layer.

The **AI-agents** category features seven works [4–10] that reposition LLMs from passive assistants to active decision makers. Cheng et al. [4]’s DxDirector-7B drives full-process clinical diagnosis, achieving superior accuracy and reducing clinician workload by repositioning physicians as assistants. Lin et al. [6] demonstrate an LLM-powered digital patient that, in a randomized trial (N = 84), yields a 10.5-point improvement in ophthalmology history-taking scores. Panda et al. [7] benchmark six chatbots for radiology plain-language summaries, while Li et al. [8] embed etiology-aware attention steering into LLM diagnostics, boosting accuracy by 15.6% and reasoning focus by 31.6%. Yoo et al. [9] present a randomized trial of an evidence-based LLM decision-support system, and Jonnagaddala et al. [10] explore deidentification and temporal normalization in EHR notes, reporting macro-F1 > 0.8 for top competition teams and highlighting fine-tuning trade-offs at scales > 6 B parameters.

In **benchmarks**, four studies [11–14] quantify LLM performance against human and traditional methods. Berry et al. [11] validate an LLM-based photologging system on 10,000 meal photos, achieving F1 scores up to 0.88 for food-group retrieval. Karataş [12] uncovers poor inter-rater reliability (ICC < 0) when ChatGPT performs CBCA on child-abuse transcripts, contrasting human-human ICC > 0.75. Marocco [13] compares human experts and LLM embeddings in psychometric content validity, finding complementary strengths across the BFQ and BFI instruments. Charest et al. [14] align scene-caption LLM embeddings with brain responses to natural images, then train compact vision-to-language networks that rival larger models in neuroalignment.

Finally, the **foundation-models** track includes one high-profile paper [15] from Bai et al., proposing a vision-language foundation model for 3D medical imaging published in npj Artificial Intelligence. Although no abstract is provided, its appearance in a top-tier venue underscores the growing emphasis on multimodal AI that fuses volumetric imaging and natural language.

Across categories, common themes emerge: 1) LLMs are no longer confined to text generation but drive structured knowledge construction, pipeline automation, and active decision-making in medicine; 2) methodological advancements span retrieval-augmented frameworks, multi-agent LangGraph systems, attention-steering fine-tuning, and randomized controlled trials; 3) benchmarks highlight both the promise (dietary image analysis, neuro-AI alignment) and the pitfalls (credibility assessment, overfitting in deidentification). Technical depth ranges from processing hundreds of thousands of publications [2] to building multi-million-relation graphs [1], while practical implications cover psychiatric biomarker discovery, enzyme engineering, ophthalmology education, EHR privacy, dietary monitoring, and psychometric test development. Limitations primarily center on proprietary datasets, domain generalization, and the need for hybrid human-AI workflows in tasks demanding nuanced expert judgment.

## Table of Contents

- [Databases](#databases)  
- [AI Agents](#ai-agents)  
- [Benchmarks](#benchmarks)  
- [Foundation Models](#foundation-models)  

## Databases

The **Databases** category unites three large-scale, LLM-powered resources aimed at unifying fragmented biological and clinical evidence. Zhu et al. [1] build the Mental Disorders Knowledge Graph (MDKG), comprising over 10 million relations by ingesting biomedical literature and curated databases through LLM-driven extraction. MDKG’s innovation lies in structural encoding of conditionality, demographics, and comorbid attributes, enabling expert validation workflows that reduce review time by up to 70% and enrich UK Biobank predictive models for multiple psychiatric disorders.

Yang et al. [2] expose the “dark matter” of enzymology via EnzyExtract, an LLM-powered pipeline processing 137,892 full-text documents to collect 218,095 kcat and 167,794 Km values across 3,569 four-digit EC numbers. Benchmarking against BRENDA and manual curation, EnzyExtract achieves high accuracy, yielding 89,544 novel kinetic entries. Sequence and substrate mappings to UniProt and PubChem deliver 92,286 high-confidence, model-ready datasets. Retraining MESI, DLKcat, and TurNuP on EnzyExtractDB demonstrably lowers RMSE and MAE while raising R², highlighting the vast utility of literature-derived data for enzyme engineering.

Goljanek-Whysall et al. [3] introduce the miRKat Suite, featuring miRKatDB—a curated repository of predicted and validated microRNA-target interactions—and miRKatAI, a multi-agent LangGraph interface that leverages LLMs for natural-language querying and grounded information retrieval. By integrating heterogeneous public sources, the suite streamlines exploratory analysis, hypothesis generation, and visualization in miRNA research.

Comparative analysis reveals [1]’s emphasis on contextual semantic enrichment contrasts with [2]’s emphasis on high-throughput data extraction and [3]’s multi-agent query and visualization. While MDKG excels in unifying disease annotations, EnzyExtract focuses on quantitative kinetics, and miRKat balances curated content with AI-driven interfaces. Limitations across these works include domain-specific coverage, reliance on proprietary texts or curation protocols, and the need for community adoption to ensure sustainability.

| Index | Title                                                                                             | Domain                                               | Venue                                                | Team                          | DOI                           | affiliation | paperUrl                                                                                     |
|-------|---------------------------------------------------------------------------------------------------|------------------------------------------------------|------------------------------------------------------|-------------------------------|-------------------------------|-------------|----------------------------------------------------------------------------------------------|
| 1     | Large language model powered knowledge graph construction for mental health exploration           | Knowledge graph construction for mental health       | Nature Communications                                | Hongtu Zhu                    | 10.1038/s41467-025-62781-z    |             | [Link](https://www.semanticscholar.org/paper/cf72cf90a34bbb8715ca2626d4ac6e901afb3457)         |
| 2     | Finding the dark matter: Large language model–based enzyme kinetic data extractor and its validation | LLM-based enzyme kinetic data extraction             | Protein Science : A Publication of the Protein Society | Zhongyue J. Yang              | 10.1002/pro.70251             |             | [Link](https://www.semanticscholar.org/paper/839511d2d7a43d41be05e10fe8448b0ca37112a2)         |
| 3     | miRKatAI: An Integrated Database and Multi-agent AI system for microRNA Research                  | Database and AI system for microRNA research         | ArXiv                                                | Katarzyna Goljanek-Whysall    | 10.48550/arXiv.2508.08331     |             | [Link](https://www.semanticscholar.org/paper/eecf17eee7339225389f95c092fbf8fbda0f9779)         |

## AI Agents

Seven papers [4–10] reposition LLMs from question-answering assistants to central drivers in clinical workflows and health-care data processing. Cheng et al. [4] propose DxDirector-7B, a 7B-parameter LLM orchestrating full-process diagnosis from ambiguous chief complaints. By constructing an accountability framework delineating AI-physician responsibilities, DxDirector-7B surpasses state-of-the-art medical and general-purpose LLMs in diagnostic accuracy and reduces clinician workload significantly across rare and complex case sets.

Zhang et al. [5] (ChatRadio-Valuer) present a radiology-focused chat model fine-tuned on multi-institutional, multi-system imaging data to generate impression summaries, though specific performance metrics are not disclosed in the abstract. Lin et al. [6] detail an LLM-based digital patient (LLMDP) system using a voice-enabled retrieval-augmented framework; in a randomized controlled trial (NCT06229379, N = 84), LLMDP-trained students improved history-taking scores by 10.50 points (p < 0.001) and reported enhanced empathy and confidence.

Panda et al. [7] compare six LLM chatbots (ChatGPT, Claude, Copilot, Gemini, Meta AI, Perplexity) for generating plain-language radiology summaries, evaluating fidelity to original abstracts. Li et al. [8] integrate Clinical Reasoning Scaffolding and an Etiology-Aware Head Identification algorithm into an LLM fine-tuning pipeline. Their Reasoning-Guided PEFT steers attention heads toward etiological cues, boosting diagnostic accuracy by 15.65% and Reasoning Focus Score by 31.6% on internal and external cohorts.

Yoo et al. [9] run a randomized controlled trial of an evidence-based LLM diagnostic decision-support system; details on trial design and outcomes are not provided. Jonnagaddala et al. [10] analyze LLM-based deidentification and temporal normalization in EHR pathology reports, comparing in-context learning and fine-tuning strategies. Top competition teams (SREDH/AI CUP 2023) achieved macro-F1 > 0.8, but performance plateaued or degraded in models > 6 B parameters, underlining the trade-off between model scale, overfitting, and ethical/legal constraints.

Comparatively, [4] and [8] emphasize model-driven clinical reasoning and accountability, [6] and [10] validate LLM utility through randomized trials and competitions, while [5] and [7] address domain-specific summarization tasks. Common limitations include incomplete performance disclosures ([5], [9]), domain-specific training data, and the necessity for rigorous external validation and ethical oversight in high-stakes medical applications.

| Index | Title                                                                                                                                                   | Domain                                                            | Venue                                              | Team                       | DOI                         | affiliation | paperUrl                                                                                             |
|-------|---------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------|----------------------------------------------------|----------------------------|-----------------------------|-------------|------------------------------------------------------------------------------------------------------|
| 4     | Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model                                                     | LLM-driven full-process clinical diagnosis                        | ArXiv                                              | Xueqi Cheng                | 10.48550/arXiv.2508.10492   |             | [Link](https://www.semanticscholar.org/paper/d67afa3cb98b6e5a15966ce06f1aff61cf2ad270)                 |
| 5     | ChatRadio-Valuer: A Chat Large Language Model for Generalizable Radiology Impression Generation on Multi-institution and Multi-system Data.             | LLM for radiology impression generation                          | IEEE transactions on bio-medical engineering      | Tuo Zhang                 | 10.1109/TBME.2025.3597325   |             | [Link](https://www.semanticscholar.org/paper/ecab6c8b4052a09127340a7fcfcc0b1550435b63)                 |
| 6     | A large language model digital patient system enhances ophthalmology history taking skills                                                             | LLM-based digital patient for ophthalmology training              | NPJ Digital Medicine                              | Haotian Lin                | 10.1038/s41746-025-01841-6 |             | [Link](https://www.semanticscholar.org/paper/0688a4ed8971d339ae2f294a299ce0e9b836fb62)                 |
| 7     | Evaluating the Capability of Large Language Model Chatbots for Generating Plain Language Summaries in Radiology                                         | LLM-generated plain language summaries in radiology               | iRADIOLOGY                                        | Swaha Panda                | 10.1002/ird3.70030         |             | [Link](https://www.semanticscholar.org/paper/d1cb625c241b63052cea1da4fbd6b25d5f798790)                 |
| 8     | Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering                                      | Etiology-aware attention steering in LLM diagnosis               | ArXiv                                              | Jingsong Li                | 10.48550/arXiv.2508.00285   |             | [Link](https://www.semanticscholar.org/paper/fb69b0591a8acf0d3f36b47d3df36b1ef481a394)                 |
| 9     | Impact of an Evidence-Based Large Language Model (LLM) Diagnostic Decision Support System: A Randomised Controlled Trial.                              | Evidence-based LLM diagnostic decision support                   | Studies in health technology and informatics      | Junsang Yoo                | 10.3233/SHTI250844          |             | [Link](https://www.semanticscholar.org/paper/b1f35310cb1190f264ffdb07c7ec2fee0335cce4)                 |
| 10    | Leveraging large language models for the deidentification and temporal normalization of sensitive health information in electronic health records      | LLM-based deidentification and temporal normalization in EHR      | NPJ Digital Medicine                              | Jitendra Jonnagaddala      | 10.1038/s41746-025-01921-7 |             | [Link](https://www.semanticscholar.org/paper/5bd7da9ef638f309da5490cc7a2a4dac8fa9c07c)                 |

## Benchmarks

Four benchmark studies [11–14] rigorously evaluate LLM and AI model reliability against human and conventional methods. Berry et al. [11] test a smartphone-based photologging system on 10,000 meals from PREDICT1/2 cohorts, reporting per-group F1 scores up to 0.88 (e.g., tea and coffee), overall precision = 0.72/0.65 (UK/US), recall = 0.75/0.73, and small macronutrient estimation biases (e.g., +139 kcal). They highlight the potential of LLM-driven image analysis for low-burden dietary assessment while noting the limitation of proprietary food-group taxonomies.

Karataş [12] compares ChatGPT (GPT-4o Plus) to a forensic psychologist and social worker on 65 child-abuse interview transcripts using the 19-item CBCA. Human-human ICC > 0.75 on 15 criteria, whereas AI-human ICC often fell below zero (e.g., ICC = –0.106 for “Logical structure”), underscoring a stark gap in nuanced contextual judgment and suggesting LLMs’ current unsuitability for autonomous credibility assessment.

Marocco [13] explores LLM embeddings versus human experts in content validity for the BFQ and BFI psychometric tests. Using the Content Validity Ratio, graduate students formed the baseline while fine-tuned multilingual LLMs predicted item-construct alignments. Results indicate human superiority on rich behavioral items (BFQ) and LLM strength on concise linguistic items (BFI), advocating hybrid validation systems that combine expert judgment with AI scalability.

Charest et al. [14] align LLM scene-caption embeddings with brain activity recorded during natural scene viewing. They demonstrate that caption-based embeddings capture area-specific selectivities, enable caption reconstruction from neural data, and that vision-to-language neural networks trained on less data outperform larger models in neuroalignment tasks. This work bridges cognitive neuroscience and AI, suggesting LLM representations as a viable format for modeling complex visual information in the brain.

Together, these benchmarks reveal both the promise—high-fidelity dietary analysis [11], neuro-AI alignment [14]—and critical limitations—poor credibility judgments [12], domain-specific validation needs [13]. They underscore the necessity of domain-tailored evaluation metrics (F1, ICC, CVR), rigorous human baselines, and hybrid approaches to harness LLM capabilities responsibly.

| Index | Title                                                                                                                                                              | Domain                                                            | Venue                                  | Team                    | DOI                                 | affiliation | paperUrl                                                                                                  |
|-------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------|----------------------------------------|-------------------------|-------------------------------------|-------------|-----------------------------------------------------------------------------------------------------------|
| 11    | Leveraging image-based AI for dietary assessment: evaluating a large language model with real-world meal photos from the ZOE PREDICT cohorts                         | AI-powered dietary assessment from meal images                    | Proceedings of the Nutrition Society   | S. Berry                | 10.1017/S0029665125101572           |             | [Link](https://www.semanticscholar.org/paper/45ca1748e55b6a73096c33cce5d18d9c3781241a)                      |
| 12    | Can a Large Language Model Judge a Child's Statement?: A Comparative Analysis of ChatGPT and Human Experts in Credibility Assessment.                               | LLM reliability in credibility assessment of child statements     | Journal of evidence-based social work | Zeki Karataş            | 10.1080/26408066.2025.2547211        |             | [Link](https://www.semanticscholar.org/paper/3deaeaf3edefbe465c46927eccb65af9f8193937)                      |
| 13    | Human Expertise and Large Language Model Embeddings in the Content Validity Assessment of Personality Tests.                                                       | LLM embeddings for psychometric content validity                  | Educational and psychological measurement | Davide Marocco          | 10.1177/00131644251355485            |             | [Link](https://www.semanticscholar.org/paper/820a8fbfdc7dae76f13041ce27e2070342d0b10f)                      |
| 14    | High-level visual representations in the human brain are aligned with large language models                                                                          | Alignment of brain visual representations with LLM embeddings     | Nature Machine Intelligence           | Ian Charest             | 10.1038/s42256-025-01072-0           |             | [Link](https://www.semanticscholar.org/paper/bc5d6c636c36f5ddc9af61da414511d43373b8e0)                      |

## Foundation Models

The single paper in **Foundation Models** [15] underscores the frontier of multimodal AI by proposing a vision-language foundation model tailored for 3D medical imaging. Published in npj Artificial Intelligence, Bai et al. [15] address the challenge of integrating volumetric scan data with natural-language understanding. Although no abstract is provided, the title suggests an architecture that fuses 3D imaging modalities (e.g., CT, MRI volumes) with language representations, potentially via transformer-based encoders and decoders adapted to handle 3D feature maps. By situating this work in a top-tier venue, the authors signal the importance of scalable foundation models that bridge pixel-level medical data and clinical narratives. The paper likely advances techniques for report generation, diagnostic question-answering, and cross-modal retrieval in volumetric contexts. Key implications include streamlined radiological workflows, improved interpretability of AI outputs, and foundational support for future fine-tuning on specialized tasks (e.g., lesion detection, segmentation). The absence of methodological details in the JSON highlights the need for broader transparency in emerging foundation-model research. Overall, [15] represents a critical step toward unified, multimodal AI systems in medical imaging.

| Index | Title                                                          | Domain                                           | Venue                    | Team              | DOI                               | affiliation | paperUrl                                                                                      |
|-------|----------------------------------------------------------------|--------------------------------------------------|--------------------------|-------------------|-----------------------------------|-------------|-----------------------------------------------------------------------------------------------|
| 15    | Vision-language foundation model for 3D medical imaging        | Vision-language foundation model for 3D medical imaging | npj Artificial Intelligence | Harrison X. Bai  | 10.1038/s44387-025-00015-9        |             | [Link](https://www.semanticscholar.org/paper/669f6dcb66625d549e88f697fdf9a38cd3bcce3f)         |