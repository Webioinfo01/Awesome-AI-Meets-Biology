# Research Paper Report for 2025-10-16 to 2025-10-31

## Overall Summary

From mid-October to the end of October 2025, fifteen studies showcase how large language models (LLMs) and artificial intelligence (AI) frameworks are reshaping diagnostics, materials science, pharmacology, and clinical workflows. A prominent theme is the seamless integration of multimodal sensing and LLM-driven interpretation. For example, Eu-FDA@HOF, a photoresponsive hydrogen-bonded organic framework sensor, provides ultralong phosphorescence (461 ms) for selective detection of metabolic biomarkers, while GPT-4o interprets phosphorescence signals for clinically meaningful olfactory diagnoses of phenylketonuria and renal dysfunction [1]. Similarly, a domain-specific AI agent for white-LED phosphor discovery couples retrieval-augmented generation with a structured knowledge base extracted from over 5,400 publications, mitigating hallucinations and enabling exact parameter lookups [5].

Another major strand is AI-augmented workflows for evidence synthesis and model development. Synthesa AI employs an LLM-based abstract screening pipeline across 270,626 PubMed and Scopus entries, achieving 100% sensitivity and 99.4% specificity, reducing manual review load by 91.7%, and uncovering 32 previously missed studies [2]. In parallel, QSP-Copilot integrates a multi-agent LLM system to automate quantitative systems pharmacology (QSP) model construction, cutting development time by 40% and achieving extraction precision above 99% for biological interactions in two rare disease case studies [4].

In materials discovery, representation clustering guided by LLM-generated embeddings accelerates the identification of metal-organic frameworks as solid-state electrolytes; NOTT-400 exhibits Li⁺ conductivity of 2.23 × 10⁻⁴ S cm⁻¹ and a stability window up to 4.79 V, validating the AI-driven mining approach [3]. Complementing these targeted discoveries, a scalable single-cell foundation model (C2S-Scale) trained on over one billion transcriptomic tokens and fine-tuned with reinforcement learning not only predicts perturbation responses but also uncovers context-conditioned biological insights, such as silmitasertib’s synergistic amplification of antigen presentation [13].

Benchmarking studies reveal the variable strengths of LLM chatbots in clinical contexts: Perplexity excels in reference support in septic arthritis scenarios [6], while GPT-4o leads anatomy education assessments with 92.9% accuracy across USMLE-style questions [7]. Prompt engineering in oral lesion diagnosis shows that chain-of-thought prompts optimize Top-3 recall (82%) and explanation quality (8.49/10), though human experts still outperform LLMs in simpler cases [10]. Reviews of retrieval-augmented generation (RAG) in healthcare highlight shifts from surface-level matching to logic-driven retrieval but note a paucity of causal modeling and ethical oversight [12].

Finally, end-to-end automation of materials databases via LLM embeddings, clustering, and GPT-4 extraction achieves accuracy on par with manual curation for organic photovoltaic donor datasets, demonstrating a path toward scalable, data-rich materials informatics [15]. Collectively, these works illustrate methodological innovations—ranging from interactive iteration text mining and contrastive vision-language learning to multi-agent LLM pipelines—and emphasize the growing practical impact of AI tools in accelerating discovery, enhancing diagnostic accuracy, and streamlining evidence synthesis.

## Table of Contents
- [ai-agents](#ai-agents)  
- [benchmarks](#benchmarks)  
- [reviews](#reviews)  
- [foundation-models](#foundation-models)  
- [databases](#databases)  

## ai-agents

The ai-agents category presents five pioneering AI-driven platforms spanning multimodal diagnostics, evidence synthesis, materials mining, pharmacology modeling, and domain-specific knowledge retrieval. Photoresponsive HOF sensors integrated with GPT-4o [1] illustrate a human-in-the-loop strategy where Eu-FDA@HOF’s room-temperature phosphorescence (461 ms) and characteristic fluorescence enable micromolar detection limits (1.53 μM PPA, 1.18 μM Cr). This work bridges photoluminescent sensing and LLM medical interpretation. Synthesa AI [2] applies prompt-driven LLM screening to 270,626 abstracts across nine pharmacologic domains, yielding perfect sensitivity (100%, 95% CI: 97.7–100%) and 99.4% specificity, slashing manual reviews by 91.7% and expanding evidence yield by 19.6%. Compared to sensor-LLM fusion, Synthesa AI focuses on systematic review automation.

In materials science, an interactive iteration text-mining framework uses LLMs to curate a structural–electrochemical property dataset from 11,393 MOFs, followed by representation clustering to spotlight NOTT-400, which exhibits Li⁺ conductivity of 2.23 × 10⁻⁴ S cm⁻¹ and a stability window of 0–4.79 V, thereby validating the AI-driven materials discovery paradigm [3]. QSP-Copilot [4] leverages a multi-agent LLM system to automate QSP model scoping, structuring, and evaluation. It extracts 179 biological interactions for blood coagulation and 151 for Gaucher disease, retaining 105 and 68 unique mechanisms, respectively, with extraction precision of 99.1% and 100%, while reducing model development time by ~40%.

Finally, a retrieval-augmented knowledge-base agent for white-LED phosphors [5] automatically harvests chemical compositions, crystallographic parameters, excitation–emission wavelengths, and synthesis conditions from over 5,400 papers. By combining retrieval-augmented generation with numerical querying, the system improves recall and precision, offering verifiable references alongside semantic search. Collectively, these works exemplify technical depth via advanced sensing architectures, representation learning, clustering techniques, and multi-agent orchestration, while also addressing limitations such as domain knowledge gaps and manual curation bottlenecks.

| Index | Title                                                                                                                                     | Domain                                                                                  | Venue                                                                                     | Team                  | DOI                             | affiliation       | paperUrl                                                                                                                     |
|-------|-------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|-----------------------|----------------------------------|-------------------|-------------------------------------------------------------------------------------------------------------------------------|
| 1     | Photoresponsive HOF-Based Platforms for Large Language Model-Assisted Multimodal Diagnosis of Metabolic Diseases.                         | Photoresponsive sensor integrated with multimodal LLM for metabolic disease diagnosis   | Analytical chemistry                                                                    | B. Yan                | 10.1021/acs.analchem.5c04807      |                   | [Link](https://www.semanticscholar.org/paper/d17aa5bf14869c5fec4b3563af21910c197c0aeb)                                        |
| 2     | Validation of Synthesa AI, a Large Language Model-Based Screening Tool for Systematic Reviews: Results from Nine Pharmacologic Studies    | LLM-based abstract screening for pharmacologic systematic reviews                      | Journal of Cardiovascular Pharmacology                                                   | Kyiakos Polymenakos   | 10.1097/fjc.0000000000001768       |                   | [Link](https://www.semanticscholar.org/paper/2a75b97593d1b841466707f8a8582932eecfc0fe)                                        |
| 3     | Mining Solid-State Electrolytes from Metal-Organic Framework Databases through Large Language Models and Representation Clustering.      | LLM and clustering approach for mining MOF solid-state electrolytes                    | Journal of the American Chemical Society                                                 | Chunpeng Yang         | 10.1021/jacs.5c12212               |                   | [Link](https://www.semanticscholar.org/paper/a9ce5fb4b09b869e475f27ea4f89cc47a23e3e2b)                                        |
| 4     | QSP–Copilot: An AI–Augmented Platform for Accelerating Quantitative Systems Pharmacology Model Development                               | QSP-Copilot: AI-augmented platform for QSP model development                           | CPT: Pharmacometrics & Systems Pharmacology                                              | A. Farnoud            | 10.1002/psp4.70127                 |                   | [Link](https://www.semanticscholar.org/paper/c65e1ee2971a29babd541a601d3777b20dca25ac)                                        |
| 5     | Construction of an artificial-intelligence agent for the discovery of next-generation white-LED phosphors.                               | AI agent with retrieval-augmented knowledge base for phosphor materials discovery      | Physical chemistry chemical physics : PCCP                                               | Yi-Yang Sun           | 10.1039/d5cp03582a                 |                   | [Link](https://www.semanticscholar.org/paper/05f3a7aa54c4fc44a92d2d00927a5efd524e5ece)                                        |

## benchmarks

The benchmarks category includes five evaluations of LLM performance in clinical and educational contexts, highlighting variable strengths in accuracy, content depth, reference support, and prompt strategies. Bayrak et al. [6] conduct a comparative evaluation of ChatGPT (GPT-4), Claude 2, and Perplexity AI in a septic arthritis scenario using 24 SANJO-guided clinical questions. Each model’s output is rated on six domains via 5-point Likert scales. All three achieve perfect accuracy scores, but Perplexity leads in reference support and overall total score (P < .001), while ChatGPT and Claude excel in content depth.

Mavrych et al. [7] assess GPT-4o, Claude, Copilot, and Gemini on 325 USMLE-style anatomy MCQs, comparing results to historical GPT-3.5 and random guessing. GPT-4o attains 92.9% ± 2.5% accuracy, significantly surpassing GPT-3.5’s 44.4% ± 8.5% (χ² tests, p < 0.001). Performance varies by topic, with Head & Neck (79.5%) highest and Upper Limb (72.9%) lowest. This study underscores rapid improvements in LLM educational reliability.

Sun et al. [8] benchmark compliance and factuality of LLMs in clinical research document generation but lack quantitative abstract data, indicating a need for standardized metrics. Fuellen et al. [9] extend BioChatter to evaluate personalized biomarker-based health intervention recommendations over 56,000 responses across 1,000 test cases, finding proprietary models outperform open-source ones in comprehensiveness but all struggle with prompt stability and age-related biases.

Abou-Bakr et al. [10] analyze prompting strategies (Direct, Chain-of-Thought, Self-Reflection) for multimodal LLM oral diagnosis (Gemini Pro 2.5) on 300 histopathology-verified cases. Chain-of-Thought yields the highest Top-3 accuracy (82%), best explanation quality (8.49/10), and optimal calibration (Brier score 0.238), though human experts still lead in straightforward diagnoses. These benchmarks collectively advance understanding of model selection, prompt design, and domain-specific trade-offs in clinical AI applications.

| Index | Title                                                                                                                                                            | Domain                                                                                | Venue                                                                                                | Team                            | DOI                                  | affiliation | paperUrl                                                                                                                         |
|-------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|---------------------------------|---------------------------------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------|
| 6     | Comparative evaluation of large language model–based chatbots in a septic arthritis scenario: ChatGPT, Claude, and Perplexity                                  | Comparative evaluation of LLM chatbots in septic arthritis scenarios                  | Acta Orthopaedica et Traumatologica Turcica                                                          | Özlem Bayrak                    | 10.5152/j.aott.2025.25428             |             | [Link](https://www.semanticscholar.org/paper/9b089d091cbba4c292c025d4903001a08ab326c0)                                              |
| 7     | Evolution of AI in anatomy education study based on comparison of current large language models against historical ChatGPT performance                           | Comparative performance of current versus historical LLMs in anatomy education       | Scientific Reports                                                                                   | Volodymyr Mavrych               | 10.1038/s41598-025-22437-w           |             | [Link](https://www.semanticscholar.org/paper/c7971a60f6f5d72b3ddc29767eb9905d0a01dbe5)                                              |
| 8     | Compliance and factuality of large language models for clinical research document generation.                                                                    | Evaluation of compliance and factuality in clinical research document generation      | Journal of the American Medical Informatics Association : JAMIA                                    | Jimeng Sun                      | 10.1093/jamia/ocaf174                 |             | [Link](https://www.semanticscholar.org/paper/a4c43e72d1311ea886405e9bdc942f49d5357046)                                              |
| 9     | Benchmarking large language models for personalized, biomarker-based health intervention recommendations                                                         | Benchmarking LLMs for personalized biomarker-based health recommendations             | NPJ Digital Medicine                                                                                | Georg Fuellen                   | 10.1038/s41746-025-01996-2           |             | [Link](https://www.semanticscholar.org/paper/56739c6a235efbc01afbb0fb198538219fefb181)                                              |
| 10    | Prompt-dependent performance of multimodal AI model in oral diagnosis: a comprehensive analysis of accuracy, narrative quality, calibration, and latency versus human experts | Prompt strategy effects on multimodal AI oral diagnosis performance                  | Scientific Reports                                                                                   | Asmaa Abou-Bakr                 | 10.1038/s41598-025-22979-z           |             | [Link](https://www.semanticscholar.org/paper/3ee4da3d68df74aaef3fc69df14dea76d32223a8)                                              |

## reviews

The reviews section comprises two scoping reviews that map the landscape of LLM usage in patient education and retrieval-augmented reasoning within healthcare. Bhojani et al. [11] perform a scoping review of LLM chatbots for patient education in kidney stones. Although the abstract is unavailable, the review likely surveys usability, patient comprehension, and content accuracy across multiple chatbot platforms, identifying gaps in educational equity, language support, and evidence citation.

Wu et al. [12] analyze 67 RAG studies (917 retrieved) in medical and nursing domains following PRISMA-ScR guidelines. They categorize frameworks into text-based (54%), knowledge-graph-enhanced (25%), agentic (9%), multimodal (3%), and plug-and-play (9%) models. The authors dissect the RAG workflow across intent recognition, knowledge retrieval, integration, and generation stages, finding only 26 studies with explicit reasoning support and 12 addressing ethical considerations. They highlight four key developmental shifts: from surface matching to contextual intent recognition, from vague semantics to logic-driven dynamic retrieval, from passive to active knowledge retrieval, and from simple aggregation to coherent context construction. However, most RAG systems lack causal modeling and real-world clinical workflow alignment, underscoring the necessity for integrating causal mechanisms and ethical guardrails for more robust, domain-relevant reasoning in healthcare applications.

| Index | Title                                                                                                                                     | Domain                                                                                               | Venue                                        | Team       | DOI                          | affiliation | paperUrl                                                                                                                  |
|-------|-------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|----------------------------------------------|------------|------------------------------|-------------|----------------------------------------------------------------------------------------------------------------------------|
| 11    | Large language model chatbots for patient education in kidney stones: a scoping review                                                     | Scoping review of LLM chatbots for patient education in kidney stones                                | World Journal of Urology                     | N. Bhojani | 10.1007/s00345-025-06019-z   |             | [Link](https://www.semanticscholar.org/paper/b6078700f6315eff5ce13121caa8e06d3d2e0f88)                                     |
| 12    | Improving Large Language Model Applications in the Medical and Nursing Domains With Retrieval-Augmented Generation: Scoping Review       | Scoping review of retrieval-augmented generation in medical and nursing domains                       | Journal of Medical Internet Research         | Ying Wu    | 10.2196/80557                |             | [Link](https://www.semanticscholar.org/paper/7215c7382de7800c038787235fa4305e2e6af4ad)                                     |

## foundation-models

Foundation-models papers explore scaling and domain adaptation of LLMs and vision-language models for biological and materials analyses. van Dijk et al. [13] extend the Cell2Sentence (C2S) framework by training a 27 billion-parameter LLM on over one billion tokens of single-cell transcriptomic data, biological text, and metadata. Fine-tuning with reinforcement learning yields improvements in perturbation response prediction, natural language explanations, and reasoning across multi-cellular contexts. Notably, C2S-Scale uncovers a context-split mechanism for silmitasertib (CX-4945) as an interferon-conditional amplifier of antigen presentation, validated experimentally in human cell models unseen during training.

Wang et al. [14] develop SEM-VLM, a contrastive vision-language model tailored for nanomaterial SEM image annotation. Trained on SEM image–text pairs via contrastive learning, SEM-VLM surpasses general-domain CLIP in Recall@10 and Recall@50 benchmarks and achieves high zero-shot classification accuracy. In few-shot settings (2.1% labels), it outperforms fully supervised graph-net models (EMCNet). Activation mapping reveals precise localization of nanoscale features, providing interpretable insights. These works illustrate how large-scale pretraining and domain adaptation enable LLMs and VLMs to bridge data scarcity and accelerate discovery in cell biology and nanomaterials, respectively.

| Index | Title                                                                                                      | Domain                                                          | Venue      | Team           | DOI                            | affiliation     | paperUrl                                                                                                             |
|-------|------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------|------------|----------------|--------------------------------|-----------------|-----------------------------------------------------------------------------------------------------------------------|
| 13    | Scaling Large Language Models for Next-Generation Single-Cell Analysis                                     | Scaled LLM pretraining for next-generation single-cell analysis | bioRxiv    | David van Dijk | 10.1101/2025.04.14.648850       | Yale University | [Link](https://www.semanticscholar.org/paper/fdb0acc2938c6d058d1bce9414dad649c869c25a)                               |
| 14    | A visual language model enabling intelligent nanomaterial scanning electron micrograph annotation.         | Domain-adapted vision-language model for nanomaterial SEM annotation | Nanoscale | Hong Wang      | 10.1039/d5nr03027g              |                 | [Link](https://www.semanticscholar.org/paper/60ff987179dd2874300a3180bc8a37995b20035a)                               |

## databases

Huang et al. [15] present an end-to-end AI-powered workflow to construct organic materials databases from literature. For publication retrieval, they compare ML methods and identify an optimal combination of LLM-based embeddings, clustering, and direct LLM queries. During data extraction, GPT-4 achieves accuracy on par with manual curation for materials and properties. The workflow also integrates AI/ML methods for automatic SMILES generation from chemical structure images, broadening applicability to organic materials. Validation against a manually curated dataset of 503 organic photovoltaic donor papers demonstrates both efficiency gains and high data fidelity. This study highlights how embedding-based search, LLM extraction, and image-to-SMILES pipelines can collectively overcome traditional bottlenecks in materials informatics and enable scalable database development.

| Index | Title                                                                                                  | Domain                                               | Venue     | Team          | DOI                             | affiliation | paperUrl                                                                                                                 |
|-------|--------------------------------------------------------------------------------------------------------|------------------------------------------------------|-----------|---------------|---------------------------------|-------------|---------------------------------------------------------------------------------------------------------------------------|
| 15    | AI-Powered Workflow for Constructing Organic Materials Databases from the Literature: Integrating Large Language Models | Automated materials science database construction via LLMs | ACS Omega | Yue Huang     | 10.1021/acsomega.5c03612        |             | [Link](https://www.semanticscholar.org/paper/4f2dc57404b117f11dae7e704c9a360440a02d27)                                  |