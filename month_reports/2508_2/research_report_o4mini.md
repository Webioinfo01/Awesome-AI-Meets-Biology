# Research Paper Report for 2025-08-16 to 2025-08-31

## Overall Summary

Between August 16 and 31, 2025, research leveraging large language models (LLMs) and their multimodal extensions has advanced across clinical, biomedical, autonomous systems, and foundational methodology domains. A clear trend is the deployment of **multi-agent architectures** to tackle complex, domain-specific tasks. In clinical settings, CARE-AD [1] and a voice-based MRI control system [2] both employ specialized LLM agents collaborating to improve diagnostic and procedural workflows, demonstrating marked gains in predictive accuracy (0.53 vs. 0.26–0.45 in Alzheimer’s risk forecasting [1]) and task completion (93.3% across 18 MRI control tasks [2]). Similarly, the PRINCE engine [5] illustrates how Retrieval-Augmented Generation and Text-to-SQL within a multi-agent LLM framework can transform unstructured preclinical safety reports into actionable insights, emphasizing transparency and human-in-the-loop governance.

Simultaneously, **foundation-model research** has pushed the envelope on domain adaptation and interpretability. Discovery of new CRISPR-Cas12a clades via an evolutionary scale language model [7] leverages deep protein embeddings and cryo-EM validation to uncover seven novel subtypes, broadening the toolkit for gene editing. DrugReasoner [9] introduces reasoning-augmented fine-tuning on LLaMA with GRPO, achieving validation/test AUCs of 0.732/0.725 and F1 scores of 0.729/0.718, outperforming classical baselines and offering step-by-step rationales. scELMo [10] applies LLM-derived embeddings under zero- and few-shot paradigms for single-cell clustering, batch correction, and annotation, surpassing scGPT and Geneformer without retraining.

**Benchmarking efforts** reveal both promise and caution. The o1 reasoning model [11] shows reduced cognitive bias relative to GPT-4 yet retains vulnerability in certain vignettes, while bioinformatics task evaluations [12] highlight that GPT-3.5 attains 58% accuracy on 104 Rosalind questions, mirroring human performance. A study comparing single vs. orchestrated multi-agent deployments [13] underscores that lightweight orchestration sustains 90.6% accuracy under heavy load, whereas monolithic agents drop to 16.6%.

A **comprehensive review** in gastroenterology and hepatology [14] synthesizes LLM integration strategies for decision support, discussing challenges in data privacy, model drift, and clinician acceptance. Finally, database tool MicroLLM [15] combines fine-tuned LLMs with BERT-based NER to convert microbiology text into structured JSON, streamlining knowledge base creation. Collectively, these works highlight an interdisciplinary convergence on multi-agent orchestration, domain-tailored fine-tuning, rigorous benchmarking, and structured data extraction—paving the way for robust, transparent, and efficient AI systems across healthcare and life sciences.

## Table of Contents
- [ai-agents](#ai-agents)  
- [foundation-models](#foundation-models)  
- [benchmarks](#benchmarks)  
- [reviews](#reviews)  
- [databases](#databases)  

## ai-agents

The ai-agents category [1–5] showcases **multi-agent and multimodal LLM frameworks** designed for specialized clinical and autonomous workflows. CARE-AD [1] employs a **collaborative diagnostic process** in which agents extract longitudinal EHR signs, achieving an AD risk prediction accuracy of 0.53 compared to single-model baselines (0.26–0.45). Likewise, the MRI control system [2] integrates voice-activated LLM agents to manage sequence execution, parameter adjustments, and table positioning, demonstrating a 93.3% task completion rate (95% CI 86.2–96.9%) with 5–10.5 s response latency on CPU-only hardware. In parallel, a clinical note summarization system [3] uses GPT-4 to generate discharge summaries, validated via an online survey and human benchmarks that approach human-level accuracy in diagnosis interpretation. These efforts underscore the strength of LLMs in handling **unstructured medical text** and collaborating with users.

Beyond healthcare, Wankai Li’s VLM-based pedestrian crossing perception system [4] adopts **standardized prompts** derived from international autonomous driving guidelines to produce JSON-formatted scenario checklists. It delivers 93.05% perception accuracy, 85.91% risk prediction consistency, and 87.72% decision rule consistency by integrating visual perception with reasoning. Finally, PRINCE [5] illustrates iterative development of a multi-agent knowledge engine using **Retrieval-Augmented Generation** and **Text-to-SQL**, evolving from keyword search to generating regulatory documents under a human-in-the-loop paradigm. This category emphasizes **collaborative agent orchestration**, domain-specific prompt engineering, rigorous user feedback loops, and transparent decision-making. Limitations across studies include latency in real-time settings [2], reliance on retrospective data [1], and the need for further prospective validation in clinical deployments [3].

| Index | Title                                                                                                                                                                                        | Domain                                                            | Venue                         | Team                   | DOI                                    | affiliation      | paperUrl                                 |
|-------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------|-------------------------------|------------------------|----------------------------------------|------------------|------------------------------------------|
| 1     | CARE-AD: a multi-agent large language model framework for Alzheimer’s disease prediction using longitudinal clinical notes                                                                  | Clinical prediction using multi-agent LLM                         | NPJ Digital Medicine           | Hong Yu                | 10.1038/s41746-025-01940-4             |                  | [Link](https://www.semanticscholar.org/paper/ded9da3e1cbf8f8c142383ed4650d626445b6d18) |
| 2     | Proof of concept for voice based MRI scanner control using large language models in real time guided interventions                                                                           | Voice-based MRI control with multi-agent LLM                      | Scientific Reports             | M. Gutberlet           | 10.1038/s41598-025-11290-6             |                  | [Link](https://www.semanticscholar.org/paper/3ee22eef0bf4442fcb0422d5754cec0d2b8d0209) |
| 3     | Development and evaluation of a clinical note summarization system using large language models                                                                                              | LLM system for clinical note summarization                        | Communications Medicine        | Rodrigo F. Nogueira    | 10.1038/s43856-025-01091-3             |                  | [Link](https://www.semanticscholar.org/paper/13ce985163af039fe40e1f4bab9fa4880339202c) |
| 4     | Improving intelligent perception and decision optimization of pedestrian crossing scenarios in autonomous driving environments through large visual language models                          | Pedestrian crossing perception in autonomous driving with VLM     | Scientific Reports             | Wankai Li              | 10.1038/s41598-025-14827-x             |                  | [Link](https://www.semanticscholar.org/paper/a3c793693929fe1b7830a4e63d8eab8b6e8bc30e) |
| 5     | From data silos to insights: the PRINCE multi-agent knowledge engine for preclinical drug development                                                                                        | Preclinical drug development multi-agent knowledge engine         | Frontiers in Artificial Intelligence | Annika Kreuchwig      | 10.3389/frai.2025.1636809             |                  | [Link](https://www.semanticscholar.org/paper/add5d50f1309b5064453b48eae56d626e291f154) |

## foundation-models

In the foundation-models category [6–10], research highlights **fine-tuning, embedding strategies**, and **reasoning augmentation** across diverse biomedical domains. Guha et al. introduce an AI-driven LLM system for **cardio-oncology decision support** [6], though details on model architecture and validation remain to be disclosed. Ma et al. apply an **evolutionary scale language model (ESM)** trained on CRISPR-Cas data to detect Cas proteins without sequence alignment, revealing seven novel Cas12a subtypes, eight Cas1/Cas2/Cas4 variants, and unique 3D-fold and PAM specificities validated via cryo-EM [7]. Kvedar’s Woollie model [8] demonstrates rigorous **fine-tuning** on radiology impressions with strategies to prevent catastrophic forgetting and external validation on UCSF datasets, establishing a scalable oncology decision-support foundation.

DrugReasoner [9] leverages the **LLaMA architecture** with **group relative policy optimization (GRPO)** to integrate molecular descriptors and comparator reasoning, achieving an AUC of 0.732 (validation) and 0.728 (external), and F1 scores up to 0.774, thus outperforming baseline ML models and delivering interpretable rationales. Zhao’s scELMo [10] proposes a **zero-shot embedding** of metadata descriptions via LLMs, combined with raw single-cell data under fine-tuning frameworks for clustering, batch correction, and in-silico perturbation analysis. scELMo outperforms scGPT, Geneformer, GenePT, and GPTCelltype, offering a lighter, resource-efficient foundation model for single-cell tasks. Collectively, these papers underline the shift toward **domain-specific adaptation**, **interpretability**, and **model efficiency**, while future work must address **data privacy**, **prospective clinical trials**, and **scalability across heterogeneous datasets**.

| Index | Title                                                                                                                                                                | Domain                                                        | Venue                        | Team                  | DOI                                   | affiliation    | paperUrl                                 |
|-------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------|------------------------------|-----------------------|---------------------------------------|----------------|------------------------------------------|
| 6     | Transforming Cardio-Oncology Care Through AI-Driven Large Language Model Systems                                                                                     | Cardio-oncology decision support with LLM systems             | JACC: Advances               | Avirup Guha           | 10.1016/j.jacadv.2025.102117          |                | [Link](https://www.semanticscholar.org/paper/47a6ff604cb8beee19e44353346c6cc404e968bc) |
| 7     | Discovery of CRISPR-Cas12a clades using a large language model                                                                                                        | CRISPR-Cas protein discovery via evolutionary LLM             | Nature Communications        | Peixiang Ma           | 10.1038/s41467-025-63160-4            |                | [Link](https://www.semanticscholar.org/paper/f3b2b073deb1bb49f4ba089a4cafa6c578aececd) |
| 8     | Incorporating large language models as clinical decision support in oncology: the Woollie model                                                                         | Oncology clinical decision support LLM                        | NPJ Digital Medicine          | Joseph C. Kvedar      | 10.1038/s41746-025-01941-3            |                | [Link](https://www.semanticscholar.org/paper/30bf408ed7ceb1a7aee914ebe6ccf125ace58cc4) |
| 9     | DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model                                                                         | LLM for small-molecule drug approval prediction               | ArXiv                         | Y. Gheisari           | 10.48550/arXiv.2508.18579             |                | [Link](https://www.semanticscholar.org/paper/d77d18b9f67a0891cf665e22c26d22b59ba58b14) |
| 10    | scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis                                                                               | LLM embeddings for single-cell data analysis                  | bioRxiv                       | Hongyu Zhao           | 10.1101/2023.12.07.569910             | Yale University | [Link](https://www.semanticscholar.org/paper/a9f7761b740c85444b86f581801a471340007a0d) |

## benchmarks

The benchmarks category [11–13] rigorously assesses LLM reasoning, domain knowledge, and system architecture under realistic conditions. Einav et al. evaluate the o1 reasoning model for **cognitive bias** using ten paired clinical vignettes [11]. The model exhibited no bias in seven scenarios, reduced bias relative to GPT-4 in most cases, but showed vulnerability under Occam’s razor cues, with intra-scenario agreement > 94%. Siwo et al. benchmark **bioinformatics question-answering** by comparing GPT-3.5, Llama-3-70B, and GPT-4o on 104 Rosalind tasks [12]. GPT-3.5 achieved the highest accuracy (58%), mirroring human performance patterns across DNA analysis, alignment, and assembly tasks. Nadkarni et al. contrast **single-agent vs. orchestrated multi-agent** systems at scale [13], revealing that multi-agent orchestration preserves accuracy (90.6%→65.3%) and reduces token usage by up to 65× under batch sizes of 5 to 80, whereas single-agent approaches degrade sharply (73.1%→16.6%; p < 0.01). These benchmarks highlight strengths in reasoning augmentation, emergent knowledge retrieval, and the necessity of **lightweight orchestration** for operational clinical workloads.

| Index | Title                                                                                                                       | Domain                                                         | Venue      | Team                     | DOI                              | affiliation                         | paperUrl                                 |
|-------|-----------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------|------------|--------------------------|----------------------------------|-------------------------------------|------------------------------------------|
| 11    | Evaluating the o1 reasoning large language model for cognitive bias: a vignette study                                       | Evaluation of cognitive bias in medical decision LLMs          | Critical Care | Sharon Einav            | 10.1186/s13054-025-05591-5       |                                     | [Link](https://www.semanticscholar.org/paper/dfbb9645b5580d4b08e4a1d5e3a21b2998c08531) |
| 12    | Out-of-the-box bioinformatics capabilities of large language models (LLMs)                                                 | Benchmarking LLMs on bioinformatics educational tasks           | bioRxiv    | Geoffrey H. Siwo         | 10.1101/2025.08.22.671610        | University of Michigan Medical School | [Link](https://www.semanticscholar.org/paper/6fa80e4e9537bc8ec43df53f9d57373d79144dbb) |
| 13    | Orchestrated multi agents sustain accuracy under clinical-scale workloads compared to a single agent                        | LLM agent orchestration under clinical workloads               | medRxiv    | Girish N. Nadkarni       | 10.1101/2025.08.22.25334049      | Icahn School of Medicine             | [Link](https://www.semanticscholar.org/paper/14c622901f2e893ae54ceb2f98178b14b1623c3f) |

## reviews

The reviews category [14] provides a **comprehensive overview** of LLM applications in gastroenterology and hepatology. Kather’s review in Nature Reviews Gastroenterology & Hepatology synthesizes current LLM-driven decision support pipelines, discussing **data curation**, **model validation**, and **regulatory considerations**. Emphasis is placed on prompt design for endoscopic image interpretation, automated report generation, and integration with electronic health records. Challenges identified include maintaining data privacy, addressing model drift in clinical deployments, and ensuring transparency for clinician trust. The review calls for **prospective clinical trials**, standardized evaluation metrics, and interdisciplinary collaboration between AI researchers, gastroenterologists, and healthcare IT specialists to fully realize LLM potential in digestive diseases.

| Index | Title                                                                                                      | Domain                                   | Venue                                               | Team      | DOI                        | affiliation | paperUrl                                 |
|-------|------------------------------------------------------------------------------------------------------------|------------------------------------------|-----------------------------------------------------|-----------|----------------------------|-------------|------------------------------------------|
| 14    | Large language models for clinical decision support in gastroenterology and hepatology                      | Gastroenterology decision support with LLM | Nature Reviews Gastroenterology & Hepatology        | J. Kather | 10.1038/s41575-025-01108-1 |             | [Link](https://www.semanticscholar.org/paper/5b813012fba35e20e1892f6b01f1dd323a1e1c3d) |

## databases

The databases category [15] focuses on **structured information extraction** in microbiology. The MicroLLM tool integrates **fine-tuned LLMs** with BERT-based NER to convert unstructured microbiology text into structured JSON objects. By capturing complex, multirelational phenotypic data, MicroLLM addresses the scarcity of annotated datasets and accelerates knowledge base construction. Its bidirectional Transformer architecture enhances the extraction of multi-entity relationships, laying groundwork for large-scale, automated microbial ecosystem analysis.

| Index | Title                                                                                                                                             | Domain                                              | Venue                       | Team        | DOI                    | affiliation | paperUrl                                 |
|-------|---------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------|-----------------------------|-------------|------------------------|-------------|------------------------------------------|
| 15    | Microllm: a structured information extraction tool using large language models and named entity recognition in microbiology                        | Microbial information extraction with LLM and NER   | Briefings in Bioinformatics | Lianyi Han  | 10.1093/bib/bbaf534     |             | [Link](https://www.semanticscholar.org/paper/116963587ce2c4b76918c5820d4d4d068fe80fbc) |

