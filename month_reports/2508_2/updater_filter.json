{
    "ai-agents": [
        {
            "year": "2025.08",
            "title": "CARE-AD: a multi-agent large language model framework for Alzheimer\u2019s disease prediction using longitudinal clinical notes",
            "team": "Hong Yu",
            "team website": "",
            "affiliation": "",
            "domain": "Clinical prediction using multi-agent LLM",
            "abstract": "Large language models (LLMs) have shown promising capabilities across diverse domains, yet their application to complex clinical prediction tasks remains limited. In this study, we present CARE-AD (Collaborative Analysis and Risk Evaluation for Alzheimer\u2019s Disease), a multi-agent LLM-based framework for forecasting Alzheimer\u2019s disease (AD) onset by analyzing longitudinal electronic health record (EHR) notes. CARE-AD assigns specialized LLM agents to extract signs and symptoms relevant to AD and conduct domain-specific evaluations\u2014emulating a collaborative diagnostic process. In a retrospective evaluation, CARE-AD achieved higher accuracy (0.53 vs. 0.26\u20130.45) than baseline single-model approaches in predicting AD risk 10 years prior to the first recorded diagnosis code. These findings highlight the feasibility of using multi-agent LLM systems to support early risk assessment for AD and motivate further research on their integration into clinical decision support workflows.",
            "venue": "NPJ Digital Medicine",
            "paperUrl": "https://www.semanticscholar.org/paper/ded9da3e1cbf8f8c142383ed4650d626445b6d18",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41746-025-01940-4",
            "reason_for_inclusion": "High quality: Published in NPJ Digital Medicine, a top-tier journal."
        },
        {
            "year": "2025.08",
            "title": "Development and evaluation of a clinical note summarization system using large language models",
            "team": "Rodrigo F. Nogueira",
            "team website": "",
            "affiliation": "",
            "domain": "LLM system for clinical note summarization",
            "abstract": "Clinical notes are a vital and detailed source of information about patient hospitalizations. However, the sheer volume and complexity of these notes make evaluation and summarization challenging. Nonetheless, summarizing clinical notes is essential for accurate and efficient clinical decision-making in patient care. Generative language models, particularly large language models such as GPT-4, offer a promising solution by creating coherent, contextually relevant text based on patterns learned from large datasets. This study describes the development of a discharge summary system using large language models. By conducting an online survey and interviews, we gather feedback from end users, including physicians and patients, to ensure the system meets their practical needs and fits their experiences. Additionally, we develop a rating system to evaluate prompt effectiveness by comparing model-generated outputs with human assessments, which serve as benchmarks to evaluate the performance of the automated model. Here we show that the model\u2019s ability to interpret diagnoses borders on humanlevel accuracy, demonstrating its potential to assist healthcare professionals in routine tasks such as generating discharge summaries. This advancement underscores the potential of large language models in clinical settings and opens up possibilities for broader applications in healthcare documentation and decision-making support. This study developed a system to support physicians in writing hospital discharge summaries. Clinical notes often include essential patient information, but their length and complexity can make it challenging to summarize them efficiently. To address this, we applied artificial intelligence (AI) techniques to help generate clear and organized summaries based on patient data. We collected input from both physicians and patients through surveys and interviews to ensure the system aligned with their needs. We also evaluated the summaries created by the system by comparing them to those written by healthcare professionals. The results showed that the AI-generated summaries were comparable in accuracy to human-written versions. This suggests that such a system could assist physicians in their documentation tasks and contribute to clearer communication during care transitions. Future applications may include other types of clinical documentation. Damasio et al. develop a discharge summary system based on large language models using feedback from both physicians and patients. The results show that the AI-generated model can accurately support the generation of summaries from clinical notes demonstrating its potential to assist healthcare professionals in routine tasks.",
            "venue": "Communications Medicine",
            "paperUrl": "https://www.semanticscholar.org/paper/13ce985163af039fe40e1f4bab9fa4880339202c",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s43856-025-01091-3",
            "reason_for_inclusion": "High quality: Published in Communications Medicine, a top-tier journal."
        },
        {
            "year": "2025.08",
            "title": "From data silos to insights: the PRINCE multi-agent knowledge engine for preclinical drug development",
            "team": "Annika Kreuchwig",
            "team website": "",
            "affiliation": "",
            "domain": "Preclinical drug development multi-agent knowledge engine",
            "abstract": "The pharmaceutical industry faces pressure to improve the drug development process while reducing costs in an evolving regulatory landscape. This paper presents the Preclinical Information Center (PRINCE), a cloud-hosted data integration platform developed by Bayer AG in collaboration with Thoughtworks. PRINCE integrates decades of structured and unstructured safety study reports, leveraging a multi-agent architecture based on Large Language Models (LLMs) and advanced data retrieval methodologies, such as Retrieval-Augmented Generation and Text-to-SQL. In this paper, we describe the three-step evolution of PRINCE from a data search tool based on keyword matching to a resourceful research assistant capable of answering complex questions and drafting regulatory-critical documents. We highlight the iterative development process, guided by user feedback, that ensures alignment with evolving research needs and maximizes utility. Finally, we discuss the importance of building trust-based solutions and how transparency and explainability have been integrated into PRINCE. In particular, the integration of a human-in-the-loop approach enhances the accuracy and retains human accountability. We believe that the development and deployment of the PRINCE chatbot demonstrate the transformative potential of AI in the pharmaceutical industry, significantly improving data accessibility and research efficiency, while prioritizing data governance and compliance.",
            "venue": "Frontiers in Artificial Intelligence",
            "paperUrl": "https://www.semanticscholar.org/paper/add5d50f1309b5064453b48eae56d626e291f154",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3389/frai.2025.1636809",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        }
    ],
    "foundation-models": [
        {
            "year": "2025.08",
            "title": "Transforming Cardio-Oncology Care Through AI-Driven Large Language Model Systems",
            "team": "Avirup Guha",
            "team website": "",
            "affiliation": "",
            "domain": "Cardio-oncology decision support with LLM systems",
            "abstract": "",
            "venue": "JACC: Advances",
            "paperUrl": "https://www.semanticscholar.org/paper/47a6ff604cb8beee19e44353346c6cc404e968bc",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1016/j.jacadv.2025.102117",
            "reason_for_inclusion": "High quality: Published in JACC: Advances, a top-tier journal."
        },
        {
            "year": "2025.08",
            "title": "Discovery of CRISPR-Cas12a clades using a large language model",
            "team": "Peixiang Ma",
            "team website": "",
            "affiliation": "",
            "domain": "CRISPR-Cas protein discovery via evolutionary LLM",
            "abstract": "CRISPR-Cas systems revolutionize life science. Metagenomes contain millions of unknown Cas proteins. Traditional mining relies on protein sequence alignments. In this work, we employ an evolutionary scale language model (ESM) to learn the information beyond sequences. Trained with CRISPR-Cas data, ESM accurately identifies Cas proteins without alignment. Limited experimental data restricts feature prediction, but integrating with machine learning enables trans-cleavage activity prediction of uncharacterized Cas12a. We discover 7 undocumented Cas12a subtypes with unique CRISPR loci. Structural analyses reveal 8 subtypes of Cas1, Cas2, and Cas4. Cas12a subtypes display distinct 3D-folds. CryoEM analyses unveil unique RNA interactions with the uncharacterized Cas12a. These proteins show distinct double-strand and single-strand DNA cleavage preferences and broad PAM recognition. Finally, we establish a specific detection strategy for the oncogene SNP without traditional Cas12a PAM. This study highlights the potential of language models in exploring undocumented Cas protein function via gene cluster classification. Novel Cas protein discovery is vital in CRISPR-Cas technology. Here, authors develop AIL-Scan, an AI-assisted Cas detection strategy using the ESM model, and discover seven unreported Cas12a subtypes with distinct DNA cleavage and PAM recognition, enabling SNP detection and precise gene editing.",
            "venue": "Nature Communications",
            "paperUrl": "https://www.semanticscholar.org/paper/f3b2b073deb1bb49f4ba089a4cafa6c578aececd",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41467-025-63160-4",
            "reason_for_inclusion": "High quality: Published in Nature Communications, a top-tier journal."
        },
        {
            "year": "2025.08",
            "title": "Incorporating large language models as clinical decision support in oncology: the Woollie model",
            "team": "Joseph C. Kvedar",
            "team website": "",
            "affiliation": "",
            "domain": "Oncology clinical decision support LLM",
            "abstract": "Integrating large language models (LLMs) into oncology holds promise for clinical decision support. Woollie is an LLM recently developed by Zhu et al., fine-tuned using radiology impression notes from Memorial Sloan Kettering Cancer Center and externally validated on UCSF oncology datasets. This methodology prioritizes data accuracy, preempts catastrophic forgetting, and demonstrates unparalleled rigor in predicting the progression of various cancer types. This work establishes a foundation for reliable, scalable, and equitable applications of LLMs in oncology.",
            "venue": "NPJ Digital Medicine",
            "paperUrl": "https://www.semanticscholar.org/paper/30bf408ed7ceb1a7aee914ebe6ccf125ace58cc4",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41746-025-01941-3",
            "reason_for_inclusion": "High quality: Published in NPJ Digital Medicine, a top-tier journal."
        },
        {
            "year": "2025.08",
            "title": "DrugReasoner: Interpretable Drug Approval Prediction with a Reasoning-augmented Language Model",
            "team": "Y. Gheisari",
            "team website": "",
            "affiliation": "",
            "domain": "LLM for small-molecule drug approval prediction",
            "abstract": "Drug discovery is a complex and resource-intensive process, making early prediction of approval outcomes critical for optimizing research investments. While classical machine learning and deep learning methods have shown promise in drug approval prediction, their limited interpretability constraints their impact. Here, we present DrugReasoner, a reasoning-based large language model (LLM) built on the LLaMA architecture and fine-tuned with group relative policy optimization (GRPO) to predict the likelihood of small-molecule approval. DrugReasoner integrates molecular descriptors with comparative reasoning against structurally similar approved and unapproved compounds, generating predictions alongside step-by-step rationales and confidence scores. DrugReasoner achieved robust performance with an AUC of 0.732 and an F1 score of 0.729 on the validation set and 0.725 and 0.718 on the test set, respectively. These results outperformed conventional baselines, including logistic regression, support vector machine, and k-nearest neighbors and had competitive performance relative to XGBoost. On an external independent dataset, DrugReasoner outperformed both baseline and the recently developed ChemAP model, achieving an AUC of 0.728 and an F1-score of 0.774, while maintaining high precision and balanced sensitivity, demonstrating robustness in real-world scenarios. These findings demonstrate that DrugReasoner not only delivers competitive predictive accuracy but also enhances transparency through its reasoning outputs, thereby addressing a key bottleneck in AI-assisted drug discovery. This study highlights the potential of reasoning-augmented LLMs as interpretable and effective tools for pharmaceutical decision-making.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/d77d18b9f67a0891cf665e22c26d22b59ba58b14",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2508.18579",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.08",
            "title": "scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis",
            "team": "Hongyu Zhao",
            "team website": "",
            "affiliation": "Yale University",
            "domain": "LLM embeddings for single-cell data analysis",
            "abstract": "Various Foundation Models (FMs) have been built based on the pre-training and fine-tuning framework to analyze single-cell data with different degrees of success. In this manuscript, we propose a method named scELMo (Single-cell Embedding from Language Models), to analyze single-cell data that utilizes Large Language Models (LLMs) as a generator for both the description of metadata information and the embeddings for such descriptions. We combine the embeddings from LLMs with the raw data under the zero-shot learning framework to further extend its function by using the fine-tuning framework to handle different tasks. We demonstrate that scELMo is capable of cell clustering, batch effect correction, and cell-type annotation without training a new model. Moreover, the fine-tuning framework of scELMo can help with more challenging tasks including in-silico treatment analysis or modeling perturbation. scELMo has a lighter structure and lower requirements for resources. Our method also outperforms recent large-scale FMs (such as scGPT [1], Geneformer [2]) and other LLM-based single-cell data analysis pipelines (such as GenePT [3] and GPTCelltype [4]) based on our evaluations, suggesting a promising path for developing domain-specific FMs.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/a9f7761b740c85444b86f581801a471340007a0d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2023.12.07.569910",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        }
    ],
    "benchmarks": [
        {
            "year": "2025.08",
            "title": "Evaluating the o1 reasoning large language model for cognitive bias: a vignette study",
            "team": "Sharon Einav",
            "team website": "",
            "affiliation": "",
            "domain": "Evaluation of cognitive bias in medical decision LLMs",
            "abstract": "Cognitive biases, systematic deviations from logical judgment, are well documented in clinical decision-making, particularly in clinical settings characterized by high decision load, limited time, and diagnostic uncertainty-such as critical care. Prior work demonstrated that large language models, particularly GPT-4, reproduce many of these biases, sometimes to a greater extent than human clinicians. We tested whether the o1 model (o1-2024\u201312-17), a newly released AI system with enhanced reasoning capabilities, is susceptible to cognitive biases that commonly affect medical decision-making. Following the methodology established by Wang and Redelmeier [15], we used ten pairs of clinical scenarios, each designed to test a specific cognitive bias known to influence clinicians. Each scenario had two versions, differed by subtle modifications designed to trigger the bias (such as presenting mortality rates versus survival rates). The o1 model generated 90 independent clinical recommendations for each scenario version, totalling 1,800 responses. We measured cognitive bias as systematic differences in recommendation rates between the paired scenarios, which should not occur with unbiased reasoning. The o1 model's performance was compared against previously published results from both the GPT-4 model and historical human clinician studies. The o1 model showed no measurable cognitive bias in seven of the ten vignettes. In two vignettes, the o1 model showed significant bias, but its absolute magnitude was lower than values previously reported for GPT-4 and human clinicians. In a single vignette, Occam\u2019s razor, the o1 model exhibited consistent bias. Therefore, although overall bias appears less frequent overall with the reasoning model than with GPT-4, it was worse in one vignette. The model was more prone to bias in vignettes that included a gap-closing cue, seemingly resolving the clinical uncertainty. Across eight vignette versions, intra\u2011scenario agreement exceeded 94%, indicating lower decision variability than previously described with GPT\u20114 and human clinicians. Reasoning models may reduce cognitive bias and random variation in judgment (i.e., \u201cnoise\u201d). However, our findings caution that reasoning models are still not entirely immune to cognitive bias. These findings suggest that reasoning models may impart some benefits as decision-support tools in medicine, but they also imply a need to explore further the circumstances in which these tools may fail.",
            "venue": "Critical Care",
            "paperUrl": "https://www.semanticscholar.org/paper/dfbb9645b5580d4b08e4a1d5e3a21b2998c08531",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1186/s13054-025-05591-5",
            "reason_for_inclusion": "High quality: Published in Critical Care, a top-tier journal."
        },
        {
            "year": "2025.08",
            "title": "Out-of-the-box bioinformatics capabilities of large language models (LLMs)",
            "team": "Geoffrey H. Siwo",
            "team website": "",
            "affiliation": "University of Michigan Medical School",
            "domain": "Benchmarking LLMs on bioinformatics educational tasks",
            "abstract": "Large Language Models (LLMs), AI agents and co-scientists promise to accelerate scientific discovery across fields ranging from chemistry to biology. Bioinformatics- the analysis of DNA, RNA and protein sequences plays a crucial role in biological research and is especially amenable to AI-driven automation given its computational nature. Here, we assess the bioinformatics capabilities of three popular general-purpose LLMs on a set of tasks covering basic analytical questions that include code writing and multi-step reasoning in the domain. Utilizing questions from Rosalind, a bioinformatics educational platform, we compare the performance of the LLMs vs. humans on 104 questions undertaken by 110 to 68,760 individuals globally. GPT-3.5 provided correct answers for 59/104 (58%) questions, while Llama-3-70B and GPT-4o answered 49/104 (47%) correctly. GPT-3.5 was the best performing in most categories, followed by Llama-3-70B and then GPT-4o. 71% of the questions were correctly answered by at least one LLM. The best performing categories included DNA analysis, while the worst performing were sequence alignment/comparative genomics and genome assembly. Overall, LLMs performance mirrored that of humans with lower performance in tasks in which humans had low performance and vice versa. However, LLMs also failed in some instances where most humans were correct and, in a few cases, LLMs excelled where most humans failed. To the best of our knowledge, this presents the first assessment of general purpose LLMs on basic bioinformatics tasks in distinct areas relative to the performance of hundreds to thousands of humans. LLMs provide correct answers to several questions that require use of biological knowledge, reasoning, statistical analysis and computer code.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/6fa80e4e9537bc8ec43df53f9d57373d79144dbb",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.08.22.671610",
            "reason_for_inclusion": "High quality: Preprint from University of Michigan Medical School."
        },
        {
            "year": "2025.08",
            "title": "Orchestrated multi agents sustain accuracy under clinical-scale workloads compared to a single agent",
            "team": "Girish N. Nadkarni",
            "team website": "",
            "affiliation": "Icahn School of Medicine",
            "domain": "LLM agent orchestration under clinical workloads",
            "abstract": "We tested state-of-the-art large language models (LLMs) in two configurations for clinical-scale workloads: a single agent handling heterogeneous tasks versus an orchestrated multi-agent system assigning each task to a dedicated worker. Across retrieval, extraction, and dosing calculations, we varied batch sizes from 5 to 80 to simulate clinical traffic. Multi-agent runs maintained high accuracy under load (pooled accuracy 90.6% at 5 tasks, 65.3% at 80) while single-agent accuracy fell sharply (73.1% to 16.6%), with significant differences beyond 10 tasks (FDR-adjusted p < 0.01). Multi-agent execution reduced token usage up to 65-fold and limited latency growth compared with single-agent runs. The designs isolation of tasks prevented context interference and preserved performance across four diverse LLM checkpoints. This is the first evaluation of LLM agent architectures under sustained, mixed-task clinical workloads, showing that lightweight orchestration can deliver accuracy, efficiency, and auditability at operational scale.",
            "venue": "medRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/14c622901f2e893ae54ceb2f98178b14b1623c3f",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.08.22.25334049",
            "reason_for_inclusion": "High quality: Preprint from Icahn School of Medicine."
        }
    ],
    "reviews": [
        {
            "year": "2025.08",
            "title": "Large language models for clinical decision support in gastroenterology and hepatology",
            "team": "J. Kather",
            "team website": "",
            "affiliation": "",
            "domain": "Gastroenterology decision support with LLM",
            "abstract": "",
            "venue": "Nature Reviews Gastroenterology & Hepatology",
            "paperUrl": "https://www.semanticscholar.org/paper/5b813012fba35e20e1892f6b01f1dd323a1e1c3d",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41575-025-01108-1",
            "reason_for_inclusion": "High quality: Published in Nature Reviews Gastroenterology & Hepatology, a top-tier journal."
        }
    ],
}
