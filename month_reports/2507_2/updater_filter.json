{
    "ai-agents": [
        {
            "year": "2025.07",
            "title": "Facilitating analysis of open neurophysiology data on the DANDI Archive using large language model tools",
            "team": "Benjamin Dichter",
            "team website": "",
            "affiliation": "Flatiron Institute",
            "domain": "Neurophysiology data exploration and reanalysis",
            "abstract": "The DANDI Archive has become a key resource for open neurophysiology data, now hosting over 400 datasets in the Neurodata Without Borders (NWB) format. While these datasets hold tremendous potential for reanalysis and discovery, many researchers face barriers to reuse, including unfamiliarity with data access methods and difficulty identifying relevant content. To address these challenges, we introduce an AI-powered, agentic chat assistant and a semi-automated notebook generation pipeline. The chat assistant serves as an interactive tool for exploring and understanding neurophysiology datasets in the DANDI Archive. It leverages large language models (LLMs) and integrates with agentic tools to guide users through data access, visualization, and preliminary analysis. The notebook generator autonomously analyzes the internal structure of a dataset with minimal human supervision, executing inspection scripts and generating visualizations. Based on this exploration, a second LLM agent then produces an introductory instructional Python notebook tailored to the dataset. We applied this system to 12 recently published datasets. Review by neurophysiology and data science specialists found that the generated notebooks were generally accurate and well-structured, with most notebooks rated as \u201cvery helpful.\u201d This work illustrates how AI can reduce barriers to scientific data reuse and foster broader engagement with complex neurophysiology datasets.",
            "venue": "bioRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/57d843f6a604da36480c76aa4da44928b77adb43",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.07.17.663965",
            "reason_for_inclusion": "High quality: Pre-print from Flatiron Institute, a world-renowned research institution."
        },
        {
            "year": "2025.07",
            "title": "Validation of Synthesa AI, a Large Language Model-Based Screening Tool for Systematic Reviews: Results from Nine Studies",
            "team": "Kyiakos Polymenakos",
            "team website": "",
            "affiliation": "",
            "domain": "LLM-based screening tool for systematic reviews",
            "abstract": "",
            "venue": "",
            "paperUrl": "https://www.semanticscholar.org/paper/eb38a1e2b9598ebfed6f7a6c08dfe300dea412f3",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.07.16.25331632",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.07",
            "title": "Accelerating primer design for amplicon sequencing using large language model-powered agents.",
            "team": "Mengcheng Yang",
            "team website": "",
            "affiliation": "",
            "domain": "LLM-powered primer design for amplicon sequencing",
            "abstract": "",
            "venue": "Nature biomedical engineering",
            "paperUrl": "https://www.semanticscholar.org/paper/284b42743a6b4316b0e0ab0ad69a01c76a8487f7",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41551-025-01455-z",
            "reason_for_inclusion": "High quality: Published in Nature Biomedical Engineering, a top-tier journal."
        },
        {
            "year": "2025.07",
            "title": "GeneAgent: self-verification language agent for gene-set analysis using domain databases",
            "team": "Zhiyong Lu",
            "team website": "",
            "affiliation": "",
            "domain": "LLM agent for gene-set functional analysis with verification",
            "abstract": "Gene-set analysis seeks to identify the biological mechanisms underlying groups of genes with shared functions. Large language models (LLMs) have recently shown promise in generating functional descriptions for input gene sets but may produce factually incorrect statements, commonly referred to as hallucinations in LLMs. Here we present GeneAgent, an LLM-based AI agent for gene-set analysis that reduces hallucinations by autonomously interacting with biological databases to verify its own output. Evaluation of 1,106 gene sets collected from different sources demonstrates that GeneAgent is consistently more accurate than GPT-4 by a significant margin. We further applied GeneAgent to seven novel gene sets derived from mouse B2905 melanoma cell lines. Expert review confirmed that GeneAgent produces more relevant and comprehensive functional descriptions than GPT-4, providing valuable insights into gene functions and expediting knowledge discovery. GeneAgent is a language agent using large language models and self-verification to improve gene-set function annotation.",
            "venue": "Nature Methods",
            "paperUrl": "https://www.semanticscholar.org/paper/5f781329fb77a7711404361597490a4f2cd18c6a",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41592-025-02748-6",
            "reason_for_inclusion": "High quality: Published in Nature Methods, a top-tier journal."
        },
        {
            "year": "2025.07",
            "title": "The Virtual Lab of AI agents designs new SARS-CoV-2 nanobodies",
            "team": "James Y. Zou",
            "team website": "",
            "affiliation": "",
            "domain": "AI agentic design of SARS-CoV-2 nanobodies",
            "abstract": "",
            "venue": "Nature",
            "paperUrl": "https://www.semanticscholar.org/paper/d24e37aafcf48c76aca30430670bad9a61cd0fca",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41586-025-09442-9",
            "reason_for_inclusion": "High quality: Published in Nature, a top-tier journal."
        },
        {
            "year": "2025.07",
            "title": "SciToolAgent: a knowledge-graph-driven scientific agent for multitool integration",
            "team": "Huajun Chen",
            "team website": "",
            "affiliation": "",
            "domain": "Knowledge-graph-driven LLM agent for scientific tool orchestration",
            "abstract": "Scientific research increasingly relies on specialized computational tools, yet effectively utilizing these tools requires substantial domain expertise. While large language models show promise in tool automation, they struggle to seamlessly integrate and orchestrate multiple tools for complex scientific workflows. Here we present SciToolAgent, a large language model-powered agent that automates hundreds of scientific tools across biology, chemistry and materials science. At its core, SciToolAgent leverages a scientific tool knowledge graph that enables intelligent tool selection and execution through graph-based retrieval-augmented generation. The agent also incorporates a comprehensive safety-checking module to ensure responsible and ethical tool usage. Extensive evaluations on a curated benchmark demonstrate that SciToolAgent outperforms existing approaches. Case studies in protein engineering, chemical reactivity prediction, chemical synthesis and metal\u2013organic framework screening further demonstrate SciToolAgent\u2019s capability to automate complex scientific workflows, making advanced research tools accessible to both experts and nonexperts. This study presents SciToolAgent, a large language model-based agent that orchestrates scientific tools via a knowledge graph, enabling automated and effective execution of scientific research workflows.",
            "venue": "Nature Computational Science",
            "paperUrl": "https://www.semanticscholar.org/paper/804b5775524552b27d5ffd6a3ab82d0f5c5f1011",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s43588-025-00849-y",
            "reason_for_inclusion": "High quality: Published in Nature Computational Science, a top-tier journal."
        }
    ],
    "foundation-models": [
        {
            "year": "2025.07",
            "title": "Doctor Sun: A Bilingual Multimodal Large Language Model for Biomedical AI",
            "team": "Zhongheng Zhang",
            "team website": "",
            "affiliation": "",
            "domain": "Biomedical multimodal large language model development",
            "abstract": "Large multimodal models (LMMs) have demonstrated significant potential in providing innovative solutions for various biomedical tasks, including pathology analysis, radiology report generation, and biomedical assistance. However, the existing multimodal biomedical AI is typically based on foundation LLMs, thus hindering the understanding of intricate medical concepts with limited medical training data. Moreover, recent LLaVA-induced medical LMMs struggle to effectively capture the intricate relationship between the texts and the images. Therefore, we introduce Doctor Sun, a large multimodal generative model specialized in medicine, developed to encode, integrate, and interpret diverse biomedical data modalities such as text and images. In particular, Doctor Sun integrates a pre-trained vision encoder with a medical LLM and conducts two-stage training on various medical datasets, focusing on feature alignment and instruction tuning. Moreover, we release SunMed-VL, a wide-range bilingual medical multimodal dataset, along with all associated models, code, and resources, to freely support the advancement of biomedical multimodal research.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/0823d41ac69e564813c75057b160d7fba5aa6646",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2508.08270",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.07",
            "title": "SAM-Med3D: A Vision Foundation Model for General-Purpose Segmentation on Volumetric Medical Images",
            "team": "Junjun He",
            "team website": "",
            "affiliation": "",
            "domain": "Vision foundation model for general-purpose 3D medical segmentation",
            "abstract": "Existing volumetric medical image segmentation models are typically task-specific, excelling at specific targets but struggling to generalize across anatomical structures or modalities. This limitation restricts their broader clinical use. In this article, we introduce segment anything model (SAM)-Med3D, a vision foundation model (VFM) for general-purpose segmentation on volumetric medical images. Given only a few 3-D prompt points, SAM-Med3D can accurately segment diverse anatomical structures and lesions across various modalities. To achieve this, we gather and preprocess a large-scale 3-D medical image segmentation dataset, SA-Med3D-140K, from 70 public datasets and 8K licensed private cases from hospitals. This dataset includes 22K 3-D images and 143K corresponding masks. SAM-Med3D, a promptable segmentation model characterized by its fully learnable 3-D structure, is trained on this dataset using a two-stage procedure and exhibits impressive performance on both seen and unseen segmentation targets. We comprehensively evaluate SAM-Med3D on 16 datasets covering diverse medical scenarios, including different anatomical structures, modalities, targets, and zero-shot transferability to new/unseen tasks. The evaluation demonstrates the efficiency and efficacy of SAM-Med3D, as well as its promising application to diverse downstream tasks as a pretrained model. Our approach illustrates that substantial medical resources can be harnessed to develop a general-purpose medical AI for various potential applications. Our dataset, code, and models are available at: https://github.com/uni-medical/SAM-Med3D",
            "venue": "IEEE Transactions on Neural Networks and Learning Systems",
            "paperUrl": "https://www.semanticscholar.org/paper/08d4d1b9ff0154293916b66d43cae18182c6e3b7",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1109/TNNLS.2025.3586694",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ],
    "benchmarks": [
        {
            "year": "2025.07",
            "title": "Ophthalmological Question Answering and Reasoning Using OpenAI o1 vs Other Large Language Models.",
            "team": "Y. Tham",
            "team website": "",
            "affiliation": "",
            "domain": "Benchmark LLMs on ophthalmological question answering",
            "abstract": "Importance\nOpenAI's recent large language model (LLM) o1 has dedicated reasoning capabilities, but it remains untested in specialized medical fields like ophthalmology. Evaluating o1 in ophthalmology is crucial to determine whether its general reasoning can meet specialized needs or if domain-specific LLMs are warranted.\n\n\nObjective\nTo assess the performance and reasoning ability of OpenAI's o1 compared with other LLMs on ophthalmological questions.\n\n\nDesign, Setting, and Participants\nIn September through October 2024, the LLMs o1, GPT-4o (OpenAI), GPT-4 (OpenAI), GPT-3.5 (OpenAI), Llama 3-8B (Meta), and Gemini 1.5 Pro (Google) were evaluated on 6990 standardized ophthalmology questions from the Medical Multiple-Choice Question Answering (MedMCQA) dataset. The study did not analyze human participants.\n\n\nMain Outcomes and Measures\nModels were evaluated on performance (accuracy and macro F1 score) and reasoning abilities (text-generation metrics: Recall-Oriented Understudy for Gisting Evaluation [ROUGE-L], BERTScore, BARTScore, AlignScore, and Metric for Evaluation of Translation With Explicit Ordering [METEOR]). Mean scores are reported for o1, while mean differences (\u0394) from o1's scores are reported for other models. Expert qualitative evaluation of o1 and GPT-4o responses assessed usefulness, organization, and comprehensibility using 5-point Likert scales.\n\n\nResults\nThe LLM o1 achieved the highest accuracy (mean, 0.877; 95% CI, 0.870 to 0.885) and macro F1 score (mean, 0.877; 95% CI, 0.869 to 0.884) (P\u2009<\u2009.001). In BERTScore, GPT-4o (\u0394\u2009=\u20090.012; 95% CI, 0.012 to 0.013) and GPT-4 (\u0394\u2009=\u20090.014; 95% CI, 0.014 to 0.015) outperformed o1 (P\u2009<\u2009.001). Similarly, in AlignScore, GPT-4o (\u0394\u2009=\u20090.019; 95% CI, 0.016 to 0.021) and GPT-4 (\u0394\u2009=\u20090.024; 95% CI, 0.021 to 0.026) again performed better (P\u2009<\u2009.001). In ROUGE-L, GPT-4o (\u0394\u2009=\u20090.018; 95% CI, 0.017 to 0.019), GPT-4 (\u0394\u2009=\u20090.026; 95% CI, 0.025 to 0.027), and GPT-3.5 (\u0394\u2009=\u20090.008; 95% CI, 0.007 to 0.009) all outperformed o1 (P\u2009<\u2009.001). Conversely, o1 led in BARTScore (mean, -4.787; 95% CI, -4.813 to -4.762; P\u2009<\u2009.001) and METEOR (mean, 0.221; 95% CI, 0.218 to 0.223; P\u2009<\u2009.001 except GPT-4o). Also, o1 outperformed GPT-4o in usefulness (o1: mean, 4.81; 95% CI, 4.73 to 4.89; GPT-4o: mean, 4.53; 95% CI, 4.40 to 4.65; P\u2009<\u2009.001) and organization (o1: mean, 4.83; 95% CI, 4.75 to 4.90; GPT-4o: mean, 4.63; 95% CI, 4.51 to 4.74; P\u2009=\u2009.003).\n\n\nConclusions and Relevance\nThis study found that o1 excelled in accuracy but showed inconsistencies in text-generation metrics, trailing GPT-4o and GPT-4; expert reviews found o1's responses to be more clinically useful and better organized than GPT-4o. While o1 demonstrated promise, its performance in addressing ophthalmology-specific challenges is not fully optimal, underscoring the potential need for domain-specialized LLMs and targeted evaluations.",
            "venue": "JAMA ophthalmology",
            "paperUrl": "https://www.semanticscholar.org/paper/b6fab798086d638085a6cc589376999fae0614ce",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1001/jamaophthalmol.2025.2413",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.07",
            "title": "Benchmarking large language models for replication of guideline-based PGx recommendations",
            "team": "Allan Gobbs",
            "team website": "",
            "affiliation": "",
            "domain": "Benchmarking LLMs for PGx recommendations replication",
            "abstract": "",
            "venue": "The Pharmacogenomics Journal",
            "paperUrl": "https://www.semanticscholar.org/paper/033444fd24632d1c33c0db64273af4d0f31253e5",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41397-025-00383-0",
            "reason_for_inclusion": "High relevance: Directly matches user's research interests."
        },
        {
            "year": "2025.07",
            "title": "HIVMedQA: Benchmarking large language models for HIV medical decision support",
            "team": "Diane Duroux",
            "team website": "",
            "affiliation": "",
            "domain": "Benchmarking LLMs for HIV medical question answering",
            "abstract": "Large language models (LLMs) are emerging as valuable tools to support clinicians in routine decision-making. HIV management is a compelling use case due to its complexity, including diverse treatment options, comorbidities, and adherence challenges. However, integrating LLMs into clinical practice raises concerns about accuracy, potential harm, and clinician acceptance. Despite their promise, AI applications in HIV care remain underexplored, and LLM benchmarking studies are scarce. This study evaluates the current capabilities of LLMs in HIV management, highlighting their strengths and limitations. We introduce HIVMedQA, a benchmark designed to assess open-ended medical question answering in HIV care. The dataset consists of curated, clinically relevant questions developed with input from an infectious disease physician. We evaluated seven general-purpose and three medically specialized LLMs, applying prompt engineering to enhance performance. Our evaluation framework incorporates both lexical similarity and an LLM-as-a-judge approach, extended to better reflect clinical relevance. We assessed performance across key dimensions: question comprehension, reasoning, knowledge recall, bias, potential harm, and factual accuracy. Results show that Gemini 2.5 Pro consistently outperformed other models across most dimensions. Notably, two of the top three models were proprietary. Performance declined as question complexity increased. Medically fine-tuned models did not always outperform general-purpose ones, and larger model size was not a reliable predictor of performance. Reasoning and comprehension were more challenging than factual recall, and cognitive biases such as recency and status quo were observed. These findings underscore the need for targeted development and evaluation to ensure safe, effective LLM integration in clinical care.",
            "venue": "ArXiv",
            "paperUrl": "https://www.semanticscholar.org/paper/14cc521817abf23142822f880c9569498ccf129a",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.48550/arXiv.2507.18143",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ],
    "reviews": [
        {
            "year": "2025.07",
            "title": "Pitfalls of large language models in medical ethics reasoning",
            "team": "Eyal Klang",
            "team website": "",
            "affiliation": "",
            "domain": "Medical ethics reasoning pitfalls of LLMs",
            "abstract": "Large language models (LLMs), such as ChatGPT-o1, display subtle blind spots in complex reasoning tasks. We illustrate these pitfalls with lateral thinking puzzles and medical ethics scenarios. Our observations indicate that patterns in training data may contribute to cognitive biases, limiting the models\u2019 ability to navigate nuanced ethical situations. Recognizing these tendencies is crucial for responsible AI deployment in clinical contexts.",
            "venue": "NPJ Digital Medicine",
            "paperUrl": "https://www.semanticscholar.org/paper/30d8956ed5be789a59d9d6c8812c386b03cda723",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1038/s41746-025-01792-y",
            "reason_for_inclusion": "Included to meet target filter limit."
        },
        {
            "year": "2025.07",
            "title": "A typology of physician input approaches to using AI chatbots for clinical decision-making: a mixed methods study",
            "team": "Laura M Holdsworth",
            "team website": "",
            "affiliation": "Stanford University School of Medicine",
            "domain": "Typology of physician input strategies to LLM chatbots",
            "abstract": "Background: Large language model (LLM) chatbots demonstrate high degrees of accuracy, yet recent studies found that physicians using these same chatbots may score no better to worse on clinical reasoning tests compared to the chatbot performing alone with researcher-curated prompts. It is unknown how physicians approach inputting information into chatbots. Objective: This study aimed to identify how physicians interacted with LLM chatbots on clinical reasoning tasks to create a typology of input approaches, exploring whether input approach type was associated with improved clinical reasoning performance. Methods: We carried out a mixed methods study in three steps. First, we conducted semi-structured interviews with U.S. physicians on experiences using an LLM chatbot and analyzed transcripts using the Framework Method to develop a typology based on input patterns. Next, we analyzed the chat logs of physicians who used a chatbot while solving clinical cases, categorizing each case to an input approach type. Lastly, we used a linear mixed-effects model to compare each input approach type with performance on the clinical cases. Results: We identified four input approach types based on patterns of content amount: copy-paster (entire case), selective copy-paster (pieces of a case), summarizer (user-generated case summary), and searcher (short queries). Copy-pasting and searching were utilized most. No single type was associated with scoring higher on clinical cases. Discussion: This study adds to our understanding of how physicians approach using chatbots and identifies ways in which physicians intuitively interact with chatbots. Conclusions: Purposeful training and support is needed to help physicians effectively use emerging AI technologies and realize their potential for supporting safe and effective medical decision-making in practice.",
            "venue": "medRxiv",
            "paperUrl": "https://www.semanticscholar.org/paper/3d551b3bc13e128b59acef3dd5101a2ad42f572b",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.1101/2025.07.23.25332002",
            "reason_for_inclusion": "High quality: Pre-print from Stanford University School of Medicine, a world-renowned research institution."
        }
    ],
    "databases": [
        {
            "year": "2025.07",
            "title": "On the construction of a large-scale database of AI-assisted annotating lung ventilation-perfusion scintigraphy for pulmonary embolism (VQ4PEDB)",
            "team": "Ran Klein",
            "team website": "",
            "affiliation": "",
            "domain": "V/Q scintigraphy database for pulmonary embolism AI",
            "abstract": "Introduction Ventilation-perfusion (V/Q) nuclear scintigraphy remains a vital diagnostic tool for assessing pulmonary embolism (PE) and other lung conditions. Interpretation of these images requires specific expertise which may benefit from recent advances in artificial intelligence (AI) to improve diagnostic accuracy and confidence in reporting. Our study aims to develop a multi-center dataset combining imaging and clinical reports to aid in creating AI models for PE diagnosis. Methods We established a comprehensive imaging registry encompassing patient-level V/Q image data along with relevant clinical reports, CTPA images, DVT ultrasound impressions, D-dimer lab tests, and thrombosis unit records. Data extraction was performed at two hospitals in Canada and at multiple sites in the United States, followed by a rigorous de-identification process. We utilized the V7 Darwin platform for crowdsourced annotation of V/Q images including segmentation of V/Q mismatched vascular defects. The annotated data was then ingested into Deep Lake, a SQL-based database, for AI model training. Quality assurance involved manual inspections and algorithmic validation. Results A query of The Ottawa Hospital's data warehouse followed by initial data screening yielded 2,137 V/Q studies with 2,238 successfully retrieved as DICOM studies. Additional contributions included 600 studies from University Health Toronto, and 385 studies by private company Segmed Inc. resulting in a total of 3,122 V/Q planar and SPECT images. The majority of studies were acquired using Siemens, Philips, and GE scanners, adhering to standardized local imaging protocols. After annotating 1,500 studies from The Ottawa Hospital, the analysis identified 138 high-probability, 168 intermediate-probability, 266 low-probability, 244 very low-probability, and 669 normal, and 15 normal perfusion with reversed mismatched ventilation defect studies. In 1,500 patients were 3,511 segmented vascular perfusion defects. Conclusion The VQ4PEDB comprised 8 unique ventilation agents and 11 unique scanners. The VQ4PEDB database is unique in its depth and breadth in the domain of V/Q nuclear scintigraphy for PE, comprising clinical reports, imaging studies, and annotations. We share our experience in addressing challenges associated with data retrieval, de-identification, and annotation. VQ4PEDB will be a valuable resource to development and validate AI models for diagnosing PE and other pulmonary diseases.",
            "venue": "Frontiers in Nuclear Medicine",
            "paperUrl": "https://www.semanticscholar.org/paper/5ee2937fd924a03fbcfdfa00e33893a7b154a961",
            "codeUrl": "",
            "githubStars": "",
            "doi": "10.3389/fnume.2025.1632112",
            "reason_for_inclusion": "Included to meet target filter limit."
        }
    ]
}